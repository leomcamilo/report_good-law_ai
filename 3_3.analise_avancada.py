#!/usr/bin/env python3
"""
An√°lise Avan√ßada de Clusters para Projetos Lei do Bem
=====================================================

Este script implementa m√∫ltiplas abordagens de clusteriza√ß√£o para identificar
padr√µes de decis√£o nos projetos, incluindo K-Means e an√°lise por analista.
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
from datetime import datetime
import warnings
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
import io

warnings.filterwarnings('ignore')

class AnalisadorClusterAvancado:
    """Classe para an√°lise avan√ßada de clusters com foco em padr√µes de decis√£o"""
    
    def __init__(self):
        self.df = None
        self.embeddings = None
        self.clusters_kmeans = None
        self.clusters_hierarquico = None
        self.model_embedding = None
        self.scaler = StandardScaler()
        self.resultados_analise = {}
        
    def carregar_dados(self, caminho_csv: str) -> pd.DataFrame:
        """Carrega os dados do CSV"""
        print("üìÇ Carregando dados...")
        self.df = pd.read_csv(caminho_csv, sep=';', encoding='utf-8')
        print(f"‚úÖ {len(self.df)} projetos carregados")
        
        # Extrair informa√ß√µes estruturadas
        self._extrair_campos_estruturados()
        
        return self.df
    
    def _extrair_campos_estruturados(self):
        """Extrai e renomeia campos estruturados das colunas do CSV."""
        print("üîç Mapeando campos estruturados...")

        # Mapeamento de nomes de colunas do CSV para nomes de campos internos
        mapeamento_campos = {
            'daproj_noprojeto': 'nome_projeto',
            'daproj_dsprojeto': 'descricao_projeto',
            'daproj_tppbpade': 'tipo_projeto',
            'daproj_dsareaprojeto': 'area_projeto',
            'daproj_dselementotecnologico': 'elemento_tecnologico',
            'daproj_dsdesafiotecnologico': 'desafio_tecnologico',
            'daproj_dsmetodologiautilizada': 'metodologia',
            'lst_norazaosocial': 'razao_social',
            'lst_noatividadeeconomica': 'atividade_economica',
            'lst_notipoportepessoajuridica': 'porte_empresa'
        }

        # Renomear colunas para os nomes de campos esperados pelo resto do script
        colunas_para_renomear = {k: v for k, v in mapeamento_campos.items() if k in self.df.columns}
        self.df.rename(columns=colunas_para_renomear, inplace=True)

        # Verificar se as colunas renomeadas agora existem
        for campo_novo in mapeamento_campos.values():
            if campo_novo not in self.df.columns:
                print(f"‚ö†Ô∏è Campo esperado '{campo_novo}' n√£o encontrado ap√≥s o mapeamento.")

        # Campos num√©ricos e categ√≥ricos que j√° devem existir com o nome correto
        campos_relevantes = [
            'do_saat_idunicopessoaanalise',  # ID do analista
            'do_taaproj_notipoavaliacaoanalise',  # Resultado da avalia√ß√£o
            'do_aat_vltotaldeclarado',  # Valor declarado
            'do_nd1_dsnotadimensao_invocao',  # Nota inova√ß√£o
            'do_nd2_dsnotadimensao_resultado',  # Nota resultado
            'do_nd3_dsnotadimensao_final'  # Nota final
        ]

        # Verificar quais campos relevantes existem
        for campo in campos_relevantes:
            if campo not in self.df.columns:
                print(f"‚ö†Ô∏è Campo relevante '{campo}' n√£o encontrado no CSV.")

        print("‚úÖ Mapeamento de campos conclu√≠do.")
    
    def criar_embeddings_multimodais(self):
        """Cria embeddings considerando m√∫ltiplas dimens√µes do projeto"""
        print("ü§ñ Criando embeddings multimodais...")
        
        if self.model_embedding is None:
            self.model_embedding = SentenceTransformer(
                "PORTULAN/serafim-335m-portuguese-pt-sentence-encoder-ir"
            )
        
        # Criar texto combinado com pesos diferentes para cada componente
        def criar_texto_ponderado(row):
            componentes = []
            
            # Alta prioridade (peso 3)
            if pd.notna(row.get('descricao_projeto')):
                componentes.extend([str(row['descricao_projeto'])] * 3)
            
            # M√©dia prioridade (peso 2)
            for campo in ['elemento_tecnologico', 'desafio_tecnologico']:
                if pd.notna(row.get(campo)):
                    componentes.extend([str(row[campo])] * 2)
            
            # Baixa prioridade (peso 1)
            for campo in ['area_projeto', 'tipo_projeto', 'atividade_economica']:
                if pd.notna(row.get(campo)):
                    componentes.append(str(row[campo]))
            
            return ' '.join(componentes)
        
        # Gerar textos ponderados
        textos_ponderados = self.df.apply(criar_texto_ponderado, axis=1).tolist()
        
        # Criar embeddings
        self.embeddings = self.model_embedding.encode(
            textos_ponderados, 
            show_progress_bar=True,
            batch_size=32
        )
        
        print(f"‚úÖ Embeddings criados: {self.embeddings.shape}")
        
        return self.embeddings
    
    def analisar_kmeans_otimizado(self, max_k: int = 30):
        """Aplica K-Means com sele√ß√£o otimizada de K"""
        print("üéØ Analisando K-Means otimizado...")
        
        # Normalizar embeddings
        embeddings_norm = self.scaler.fit_transform(self.embeddings)
        
        # Testar diferentes valores de K
        inertias = []
        silhouettes = []
        calinski_scores = []
        k_values = range(2, min(max_k + 1, len(self.df) // 10))
        
        for k in k_values:
            print(f"  Testando K={k}...")
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(embeddings_norm)
            
            inertias.append(kmeans.inertia_)
            silhouettes.append(silhouette_score(embeddings_norm, clusters))
            calinski_scores.append(calinski_harabasz_score(embeddings_norm, clusters))
        
        # Encontrar K √≥timo usando m√©todo do cotovelo + silhouette
        # Calcular segunda derivada da in√©rcia
        if len(inertias) > 2:
            second_derivative = np.diff(np.diff(inertias))
            elbow_idx = np.argmax(second_derivative) + 2  # +2 por causa dos diffs
            k_elbow = list(k_values)[elbow_idx]
        else:
            k_elbow = 10
        
        # K com melhor silhouette
        k_silhouette = list(k_values)[np.argmax(silhouettes)]
        
        # K final: m√©dia entre elbow e silhouette
        k_optimal = (k_elbow + k_silhouette) // 2
        
        print(f"üìä K √≥timo encontrado: {k_optimal}")
        print(f"   K (cotovelo): {k_elbow}")
        print(f"   K (silhouette): {k_silhouette}")
        
        # Aplicar K-Means com K √≥timo
        self.kmeans_final = KMeans(n_clusters=k_optimal, random_state=42, n_init=20)
        self.clusters_kmeans = self.kmeans_final.fit_predict(embeddings_norm)
        
        # Salvar m√©tricas
        self.resultados_analise['kmeans'] = {
            'k_optimal': k_optimal,
            'k_elbow': k_elbow,
            'k_silhouette': k_silhouette,
            'inertias': inertias,
            'silhouettes': silhouettes,
            'k_values': list(k_values)
        }
        
        return self.clusters_kmeans
    
    def analisar_padroes_decisao(self):
        """Analisa padr√µes de decis√£o por cluster e analista"""
        print("üìä Analisando padr√µes de decis√£o...")
        
        # Adicionar clusters ao dataframe
        self.df['cluster_kmeans'] = self.clusters_kmeans
        
        # An√°lise por cluster
        padroes_cluster = []
        
        for cluster_id in sorted(self.df['cluster_kmeans'].unique()):
            cluster_data = self.df[self.df['cluster_kmeans'] == cluster_id]
            
            # Estat√≠sticas do cluster
            padrao = {
                'cluster_id': cluster_id,
                'tamanho': len(cluster_data),
                'percentual_total': len(cluster_data) / len(self.df) * 100,
                
                # An√°lise de aprova√ß√£o (se houver campo de resultado)
                'taxa_recomendado': 0,
                'taxa_nao_recomendado': 0,
                
                # Caracter√≠sticas dominantes
                'area_principal': cluster_data['area_projeto'].mode().iloc[0] if not cluster_data['area_projeto'].mode().empty else 'N/A',
                'tipo_projeto_principal': cluster_data['tipo_projeto'].mode().iloc[0] if not cluster_data['tipo_projeto'].mode().empty else 'N/A',
                'porte_empresa_principal': cluster_data['porte_empresa'].mode().iloc[0] if not cluster_data['porte_empresa'].mode().empty else 'N/A',
                
                # An√°lise de analistas
                'num_analistas': cluster_data['do_saat_idunicopessoaanalise'].nunique() if 'do_saat_idunicopessoaanalise' in cluster_data.columns else 0,
                'analista_principal': None,
                'concentracao_analista': 0
            }
            
            # An√°lise de resultados se campo existir
            if 'do_taaproj_notipoavaliacaoanalise' in cluster_data.columns:
                resultados = cluster_data['do_taaproj_notipoavaliacaoanalise'].value_counts(normalize=True)
                if 'Recomendado' in resultados:
                    padrao['taxa_recomendado'] = resultados['Recomendado'] * 100
                if 'N√£o Recomendado' in resultados:
                    padrao['taxa_nao_recomendado'] = resultados['N√£o Recomendado'] * 100
            
            # An√°lise de concentra√ß√£o por analista
            if 'do_saat_idunicopessoaanalise' in cluster_data.columns:
                analistas = cluster_data['do_saat_idunicopessoaanalise'].value_counts()
                if not analistas.empty:
                    padrao['analista_principal'] = analistas.index[0]
                    padrao['concentracao_analista'] = (analistas.iloc[0] / len(cluster_data)) * 100
            
            padroes_cluster.append(padrao)
        
        self.resultados_analise['padroes_cluster'] = pd.DataFrame(padroes_cluster)
        
        # An√°lise por analista
        if 'do_saat_idunicopessoaanalise' in self.df.columns:
            padroes_analista = []
            
            for analista_id in self.df['do_saat_idunicopessoaanalise'].unique():
                if pd.notna(analista_id):
                    projetos_analista = self.df[self.df['do_saat_idunicopessoaanalise'] == analista_id]
                    
                    padrao_analista = {
                        'analista_id': analista_id,
                        'num_projetos': len(projetos_analista),
                        'clusters_atendidos': projetos_analista['cluster_kmeans'].nunique(),
                        'area_especializada': projetos_analista['area_projeto'].mode().iloc[0] if not projetos_analista['area_projeto'].mode().empty else 'N/A',
                        'taxa_aprovacao': 0
                    }
                    
                    # Taxa de aprova√ß√£o se dispon√≠vel
                    if 'do_taaproj_notipoavaliacaoanalise' in projetos_analista.columns:
                        aprovados = projetos_analista['do_taaproj_notipoavaliacaoanalise'].str.contains('Recomendado', na=False).sum()
                        padrao_analista['taxa_aprovacao'] = (aprovados / len(projetos_analista)) * 100
                    
                    padroes_analista.append(padrao_analista)
            
            self.resultados_analise['padroes_analista'] = pd.DataFrame(padroes_analista)
        
        return self.resultados_analise
    
    def criar_visualizacoes(self):
        """Cria visualiza√ß√µes dos clusters e padr√µes"""
        print("üìà Criando visualiza√ß√µes...")
        
        # Configurar estilo
        plt.style.use('seaborn-v0_8-darkgrid')
        fig_paths = []
        
        # 1. Visualiza√ß√£o do m√©todo do cotovelo
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        k_values = self.resultados_analise['kmeans']['k_values']
        inertias = self.resultados_analise['kmeans']['inertias']
        silhouettes = self.resultados_analise['kmeans']['silhouettes']
        
        # Cotovelo
        ax1.plot(k_values, inertias, 'b-o', linewidth=2, markersize=8)
        ax1.axvline(x=self.resultados_analise['kmeans']['k_optimal'], color='r', linestyle='--', 
                   label=f'K √≥timo = {self.resultados_analise["kmeans"]["k_optimal"]}')
        ax1.set_xlabel('N√∫mero de Clusters (K)', fontsize=12)
        ax1.set_ylabel('In√©rcia', fontsize=12)
        ax1.set_title('M√©todo do Cotovelo', fontsize=14, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Silhouette
        ax2.plot(k_values, silhouettes, 'g-o', linewidth=2, markersize=8)
        ax2.axvline(x=self.resultados_analise['kmeans']['k_silhouette'], color='r', linestyle='--',
                   label=f'K melhor silhouette = {self.resultados_analise["kmeans"]["k_silhouette"]}')
        ax2.set_xlabel('N√∫mero de Clusters (K)', fontsize=12)
        ax2.set_ylabel('Silhouette Score', fontsize=12)
        ax2.set_title('An√°lise de Silhouette', fontsize=14, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        fig_path = 'kmeans_otimizacao.png'
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        fig_paths.append(fig_path)
        plt.close()
        
        # 2. Distribui√ß√£o dos clusters
        fig, ax = plt.subplots(figsize=(12, 8))
        
        cluster_counts = self.df['cluster_kmeans'].value_counts().sort_index()
        colors_palette = sns.color_palette('husl', len(cluster_counts))
        
        bars = ax.bar(cluster_counts.index, cluster_counts.values, color=colors_palette, edgecolor='black', linewidth=1)
        
        # Adicionar valores nas barras
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 10,
                   f'{int(height)}\n({height/len(self.df)*100:.1f}%)',
                   ha='center', va='bottom', fontsize=10)
        
        ax.set_xlabel('Cluster ID', fontsize=12)
        ax.set_ylabel('N√∫mero de Projetos', fontsize=12)
        ax.set_title('Distribui√ß√£o de Projetos por Cluster (K-Means)', fontsize=14, fontweight='bold')
        ax.grid(True, axis='y', alpha=0.3)
        
        plt.tight_layout()
        fig_path = 'distribuicao_clusters.png'
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        fig_paths.append(fig_path)
        plt.close()
        
        # 3. PCA dos embeddings colorido por cluster
        print("  Aplicando PCA para visualiza√ß√£o...")
        pca = PCA(n_components=2, random_state=42)
        embeddings_2d = pca.fit_transform(self.embeddings)
        
        fig, ax = plt.subplots(figsize=(14, 10))
        
        scatter = ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], 
                           c=self.clusters_kmeans, 
                           cmap='tab20', 
                           alpha=0.6, 
                           edgecolors='black',
                           linewidth=0.5,
                           s=50)
        
        # Adicionar centroides
        for cluster_id in np.unique(self.clusters_kmeans):
            cluster_points = embeddings_2d[self.clusters_kmeans == cluster_id]
            centroid = cluster_points.mean(axis=0)
            ax.scatter(centroid[0], centroid[1], 
                      marker='*', 
                      s=500, 
                      c='red', 
                      edgecolors='black',
                      linewidth=2,
                      label=f'Centroide {cluster_id}' if cluster_id == 0 else '')
            ax.text(centroid[0], centroid[1], str(cluster_id), 
                   fontsize=12, fontweight='bold', ha='center', va='center')
        
        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} vari√¢ncia)', fontsize=12)
        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} vari√¢ncia)', fontsize=12)
        ax.set_title('Visualiza√ß√£o dos Clusters em 2D (PCA)', fontsize=14, fontweight='bold')
        
        # Legenda apenas para centroide
        handles, labels = ax.get_legend_handles_labels()
        if handles:
            ax.legend(handles[:1], ['Centroides'], loc='upper right')
        
        plt.tight_layout()
        fig_path = 'pca_clusters.png'
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        fig_paths.append(fig_path)
        plt.close()
        
        # 4. Heatmap de caracter√≠sticas por cluster
        if 'padroes_cluster' in self.resultados_analise:
            fig, ax = plt.subplots(figsize=(12, 8))
            
            # Preparar dados para heatmap
            df_padroes = self.resultados_analise['padroes_cluster']
            heatmap_data = df_padroes[['taxa_recomendado', 'taxa_nao_recomendado', 
                                      'concentracao_analista', 'percentual_total']].fillna(0)
            
            sns.heatmap(heatmap_data.T, 
                       xticklabels=[f'C{i}' for i in df_padroes['cluster_id']],
                       yticklabels=['Taxa Recomendado (%)', 'Taxa N√£o Recomendado (%)', 
                                   'Concentra√ß√£o Analista (%)', 'Tamanho (%)'],
                       annot=True, 
                       fmt='.1f',
                       cmap='YlOrRd',
                       cbar_kws={'label': 'Percentual (%)'},
                       linewidths=0.5,
                       linecolor='gray')
            
            ax.set_xlabel('Cluster ID', fontsize=12)
            ax.set_title('Caracter√≠sticas dos Clusters', fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            fig_path = 'heatmap_caracteristicas.png'
            plt.savefig(fig_path, dpi=300, bbox_inches='tight')
            fig_paths.append(fig_path)
            plt.close()
        
        self.fig_paths = fig_paths
        return fig_paths
    
    def gerar_relatorio_pdf(self, nome_arquivo='relatorio_clusters_lei_bem.pdf'):
        """Gera relat√≥rio em PDF com an√°lises e visualiza√ß√µes"""
        print("üìÑ Gerando relat√≥rio PDF...")
        
        doc = SimpleDocTemplate(nome_arquivo, pagesize=A4)
        story = []
        styles = getSampleStyleSheet()
        
        # Estilos customizados
        titulo_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#1f4788'),
            spaceAfter=30,
            alignment=1  # Centro
        )
        
        subtitulo_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#2e5090'),
            spaceBefore=20,
            spaceAfter=15
        )
        
        # T√≠tulo
        story.append(Paragraph("An√°lise de Clusters - Projetos Lei do Bem", titulo_style))
        story.append(Spacer(1, 0.2*inch))
        
        # Data e estat√≠sticas gerais
        data_atual = datetime.now().strftime("%d/%m/%Y %H:%M")
        story.append(Paragraph(f"<b>Data da An√°lise:</b> {data_atual}", styles['Normal']))
        story.append(Paragraph(f"<b>Total de Projetos:</b> {len(self.df):,}", styles['Normal']))
        story.append(Paragraph(f"<b>N√∫mero de Clusters (K-Means):</b> {self.resultados_analise['kmeans']['k_optimal']}", styles['Normal']))
        story.append(Spacer(1, 0.3*inch))
        
        # 1. Metodologia
        story.append(Paragraph("1. Metodologia de An√°lise", subtitulo_style))
        metodologia_text = """
        A an√°lise foi realizada utilizando t√©cnicas avan√ßadas de Machine Learning para identificar 
        padr√µes nos projetos submetidos √† Lei do Bem:
        
        ‚Ä¢ <b>Embeddings Sem√¢nticos:</b> Utilizando o modelo SERAFIM (portugu√™s), foram criadas 
        representa√ß√µes vetoriais dos projetos considerando descri√ß√£o, elemento tecnol√≥gico, 
        desafio e metodologia.
        
        ‚Ä¢ <b>K-Means Otimizado:</b> Aplica√ß√£o do algoritmo K-Means com sele√ß√£o autom√°tica do 
        n√∫mero √≥timo de clusters usando m√©todo do cotovelo e an√°lise de silhouette.
        
        ‚Ä¢ <b>An√°lise Multidimensional:</b> Considera√ß√£o de m√∫ltiplas dimens√µes incluindo √°rea 
        tecnol√≥gica, tipo de projeto, porte da empresa e padr√µes de decis√£o dos analistas.
        """
        story.append(Paragraph(metodologia_text, styles['Normal']))
        story.append(Spacer(1, 0.2*inch))
        
        # Adicionar gr√°fico de otimiza√ß√£o
        if hasattr(self, 'fig_paths') and len(self.fig_paths) > 0:
            img = Image(self.fig_paths[0], width=6*inch, height=2.5*inch)
            story.append(img)
        
        story.append(PageBreak())
        
        # 2. Resultados da Clusteriza√ß√£o
        story.append(Paragraph("2. Resultados da Clusteriza√ß√£o", subtitulo_style))
        
        # Tabela de clusters principais
        if 'padroes_cluster' in self.resultados_analise:
            df_padroes = self.resultados_analise['padroes_cluster'].head(10)
            
            # Preparar dados da tabela
            data_table = [['Cluster', 'Projetos', '% Total', '√Årea Principal', 'Taxa Recom. (%)']]
            for _, row in df_padroes.iterrows():
                data_table.append([
                    str(int(row['cluster_id'])),
                    str(int(row['tamanho'])),
                    f"{row['percentual_total']:.1f}%",
                    row['area_principal'][:30] + '...' if len(str(row['area_principal'])) > 30 else row['area_principal'],
                    f"{row['taxa_recomendado']:.1f}%" if row['taxa_recomendado'] > 0 else 'N/A'
                ])
            
            # Criar tabela
            t = Table(data_table, colWidths=[0.8*inch, 1*inch, 0.8*inch, 2.5*inch, 1.2*inch])
            t.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.lightgrey])
            ]))
            
            story.append(Paragraph("<b>Top 10 Clusters por Tamanho:</b>", styles['Normal']))
            story.append(Spacer(1, 0.1*inch))
            story.append(t)
        
        # Adicionar gr√°fico de distribui√ß√£o
        if hasattr(self, 'fig_paths') and len(self.fig_paths) > 1:
            story.append(Spacer(1, 0.3*inch))
            img = Image(self.fig_paths[1], width=5*inch, height=3.5*inch)
            story.append(img)
        
        story.append(PageBreak())
        
        # 3. An√°lise de Padr√µes de Decis√£o
        story.append(Paragraph("3. Padr√µes de Decis√£o Identificados", subtitulo_style))
        
        padroes_text = """
        A an√°lise revelou os seguintes padr√µes principais nos clusters formados:
        """
        story.append(Paragraph(padroes_text, styles['Normal']))
        
        # Insights dos clusters
        if 'padroes_cluster' in self.resultados_analise:
            df_padroes = self.resultados_analise['padroes_cluster']
            
            # Clusters com alta taxa de aprova√ß√£o
            clusters_alta_aprovacao = df_padroes[df_padroes['taxa_recomendado'] > 70]
            if not clusters_alta_aprovacao.empty:
                story.append(Paragraph("<b>‚Ä¢ Clusters com Alta Taxa de Aprova√ß√£o (>70%):</b>", styles['Normal']))
                for _, cluster in clusters_alta_aprovacao.iterrows():
                    texto = f"  - Cluster {int(cluster['cluster_id'])}: {cluster['area_principal']} " \
                           f"({cluster['taxa_recomendado']:.1f}% aprova√ß√£o)"
                    story.append(Paragraph(texto, styles['Normal']))
                story.append(Spacer(1, 0.1*inch))
            
            # Clusters com alta concentra√ß√£o de analista
            clusters_concentrados = df_padroes[df_padroes['concentracao_analista'] > 50]
            if not clusters_concentrados.empty:
                story.append(Paragraph("<b>‚Ä¢ Clusters com Alta Concentra√ß√£o de Analista (>50%):</b>", styles['Normal']))
                for _, cluster in clusters_concentrados.iterrows():
                    texto = f"  - Cluster {int(cluster['cluster_id'])}: {cluster['concentracao_analista']:.1f}% " \
                           f"dos projetos analisados pelo mesmo analista"
                    story.append(Paragraph(texto, styles['Normal']))
                story.append(Spacer(1, 0.1*inch))
        
        # Visualiza√ß√£o PCA
        if hasattr(self, 'fig_paths') and len(self.fig_paths) > 2:
            story.append(Spacer(1, 0.2*inch))
            img = Image(self.fig_paths[2], width=5.5*inch, height=4*inch)
            story.append(img)
        
        story.append(PageBreak())
        
        # 4. An√°lise por Analista
        story.append(Paragraph("4. An√°lise de Performance por Analista", subtitulo_style))
        
        if 'padroes_analista' in self.resultados_analise:
            df_analistas = self.resultados_analise['padroes_analista'].head(10)
            
            # Tabela de analistas
            data_table = [['ID Analista', 'Projetos', 'Clusters', '√Årea Espec.', 'Taxa Aprov.']]
            for _, row in df_analistas.iterrows():
                data_table.append([
                    str(int(row['analista_id'])),
                    str(int(row['num_projetos'])),
                    str(int(row['clusters_atendidos'])),
                    row['area_especializada'][:25] + '...' if len(str(row['area_especializada'])) > 25 else row['area_especializada'],
                    f"{row['taxa_aprovacao']:.1f}%"
                ])
            
            t = Table(data_table, colWidths=[1.2*inch, 0.8*inch, 0.8*inch, 2.2*inch, 1*inch])
            t.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2e5090')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 11),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.lightblue),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.lightgrey])
            ]))
            
            story.append(Paragraph("<b>Top 10 Analistas por Volume de Projetos:</b>", styles['Normal']))
            story.append(Spacer(1, 0.1*inch))
            story.append(t)
        
        # Heatmap de caracter√≠sticas
        if hasattr(self, 'fig_paths') and len(self.fig_paths) > 3:
            story.append(Spacer(1, 0.3*inch))
            img = Image(self.fig_paths[3], width=5.5*inch, height=3.5*inch)
            story.append(img)
        
        story.append(PageBreak())
        
        # 5. Recomenda√ß√µes
        story.append(Paragraph("5. Recomenda√ß√µes para Otimiza√ß√£o do Processo", subtitulo_style))
        
        recomendacoes = self._gerar_recomendacoes()
        for i, rec in enumerate(recomendacoes, 1):
            story.append(Paragraph(f"<b>{i}. {rec['titulo']}</b>", styles['Normal']))
            story.append(Paragraph(rec['descricao'], styles['Normal']))
            story.append(Spacer(1, 0.1*inch))
        
        # 6. Conclus√µes
        story.append(Paragraph("6. Conclus√µes", subtitulo_style))
        
        conclusoes_text = f"""
        A an√°lise identificou {self.resultados_analise['kmeans']['k_optimal']} clusters distintos 
        nos projetos da Lei do Bem, revelando padr√µes importantes de agrupamento baseados em 
        similaridade sem√¢ntica e caracter√≠sticas estruturais. 
        
        Os principais achados incluem:
        
        ‚Ä¢ <b>Especializa√ß√£o por √°rea:</b> Clusters tendem a agrupar projetos de √°reas tecnol√≥gicas 
        similares, sugerindo a possibilidade de especializa√ß√£o de analistas.
        
        ‚Ä¢ <b>Padr√µes de decis√£o:</b> Identificados clusters com taxas de aprova√ß√£o significativamente 
        diferentes, indicando poss√≠veis vieses ou crit√©rios n√£o uniformes.
        
        ‚Ä¢ <b>Distribui√ß√£o de carga:</b> Alguns analistas concentram an√°lises em clusters espec√≠ficos, 
        o que pode indicar especializa√ß√£o informal ou desbalanceamento.
        
        A implementa√ß√£o das recomenda√ß√µes propostas pode levar a uma melhoria significativa na 
        efici√™ncia e consist√™ncia do processo de avalia√ß√£o.
        """
        story.append(Paragraph(conclusoes_text, styles['Normal']))
        
        # Construir PDF
        doc.build(story)
        print(f"‚úÖ Relat√≥rio PDF gerado: {nome_arquivo}")
    
    def _gerar_recomendacoes(self) -> list[dict[str, str]]:
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recomendacoes = []
        
        if 'padroes_cluster' in self.resultados_analise:
            df_padroes = self.resultados_analise['padroes_cluster']
            
            # 1. Balanceamento de carga
            if df_padroes['concentracao_analista'].max() > 60:
                recomendacoes.append({
                    'titulo': 'Implementar Balanceamento Autom√°tico de Carga',
                    'descricao': 'Alguns clusters t√™m mais de 60% dos projetos analisados pelo mesmo '
                               'analista. Recomenda-se implementar um sistema de distribui√ß√£o autom√°tica '
                               'que considere a carga atual e a especializa√ß√£o dos analistas.'
                })
            
            # 2. Especializa√ß√£o formal
            areas_concentradas = df_padroes.groupby('area_principal')['tamanho'].sum()
            if len(areas_concentradas) > 5:
                recomendacoes.append({
                    'titulo': 'Formalizar Especializa√ß√£o por √Årea Tecnol√≥gica',
                    'descricao': f'Foram identificadas {len(areas_concentradas)} √°reas tecnol√≥gicas '
                               'principais. Criar grupos de analistas especializados em cada √°rea '
                               'pode aumentar a qualidade e velocidade das an√°lises.'
                })
            
            # 3. Padroniza√ß√£o de crit√©rios
            variacao_aprovacao = df_padroes['taxa_recomendado'].std()
            if variacao_aprovacao > 20:
                recomendacoes.append({
                    'titulo': 'Padronizar Crit√©rios de Avalia√ß√£o',
                    'descricao': f'A varia√ß√£o na taxa de aprova√ß√£o entre clusters √© de '
                               f'{variacao_aprovacao:.1f}%. Desenvolver crit√©rios objetivos e '
                               'checklists padronizados pode reduzir essa disparidade.'
                })
            
            # 4. Sistema de triagem
            if self.resultados_analise['kmeans']['k_optimal'] > 15:
                recomendacoes.append({
                    'titulo': 'Implementar Sistema de Triagem Automatizada',
                    'descricao': 'Com o grande n√∫mero de clusters identificados, um sistema de '
                               'pr√©-classifica√ß√£o usando IA pode agilizar o direcionamento dos '
                               'projetos para os analistas mais adequados.'
                })
        
        # 5. Monitoramento cont√≠nuo
        recomendacoes.append({
            'titulo': 'Estabelecer Monitoramento Cont√≠nuo de Padr√µes',
            'descricao': 'Implementar dashboards em tempo real para acompanhar m√©tricas de '
                       'distribui√ß√£o, tempo de an√°lise e taxas de aprova√ß√£o por cluster e analista.'
        })
        
        return recomendacoes
    
    def exportar_resultados_detalhados(self, prefixo='lei_bem'):
        """Exporta todos os resultados detalhados"""
        print("üíæ Exportando resultados detalhados...")
        
        # 1. DataFrame com clusters
        self.df.to_csv(f'{prefixo}_projetos_clusters.csv', index=False, sep=';', encoding='utf-8')
        
        # 2. An√°lise de clusters
        if 'padroes_cluster' in self.resultados_analise:
            self.resultados_analise['padroes_cluster'].to_csv(
                f'{prefixo}_analise_clusters.csv', index=False, sep=';', encoding='utf-8'
            )
        
        # 3. An√°lise de analistas
        if 'padroes_analista' in self.resultados_analise:
            self.resultados_analise['padroes_analista'].to_csv(
                f'{prefixo}_analise_analistas.csv', index=False, sep=';', encoding='utf-8'
            )
        
        # 4. M√©tricas de otimiza√ß√£o
        import json
        metricas = {
            'k_optimal': self.resultados_analise['kmeans']['k_optimal'],
            'k_elbow': self.resultados_analise['kmeans']['k_elbow'],
            'k_silhouette': self.resultados_analise['kmeans']['k_silhouette'],
            'total_projetos': len(self.df),
            'total_clusters': self.resultados_analise['kmeans']['k_optimal']
        }
        
        with open(f'{prefixo}_metricas.json', 'w', encoding='utf-8') as f:
            json.dump(metricas, f, indent=2, ensure_ascii=False)
        
        print("‚úÖ Todos os resultados exportados")


def main():
    """Fun√ß√£o principal para executar an√°lise completa"""
    print("üöÄ An√°lise Avan√ßada de Clusters - Lei do Bem")
    print("=" * 60)
    
    # Inicializar analisador
    analisador = AnalisadorClusterAvancado()
    
    # Encontrar arquivo CSV
    pasta_tabelas = Path("csv_longo")
    arquivos_csv = list(pasta_tabelas.glob("*.csv"))
    
    if not arquivos_csv:
        print("‚ùå Nenhum arquivo CSV encontrado")
        return
    
    print(f"üìÅ Usando arquivo: {arquivos_csv[0].name}")
    
    # Pipeline de an√°lise
    # 1. Carregar dados
    analisador.carregar_dados(str(arquivos_csv[0]))
    
    # 2. Criar embeddings multimodais
    analisador.criar_embeddings_multimodais()
    
    # 3. Aplicar K-Means otimizado
    analisador.analisar_kmeans_otimizado(max_k=30)
    
    # 4. Analisar padr√µes de decis√£o
    analisador.analisar_padroes_decisao()
    
    # 5. Criar visualiza√ß√µes
    analisador.criar_visualizacoes()
    
    # 6. Gerar relat√≥rio PDF
    analisador.gerar_relatorio_pdf()
    
    # 7. Exportar resultados detalhados
    analisador.exportar_resultados_detalhados()
    
    print("\n‚úÖ An√°lise completa!")
    print("üìä Arquivos gerados:")
    print("   - relatorio_clusters_lei_bem.pdf (Relat√≥rio completo)")
    print("   - lei_bem_projetos_clusters.csv (Projetos com clusters)")
    print("   - lei_bem_analise_clusters.csv (Caracter√≠sticas dos clusters)")
    print("   - lei_bem_analise_analistas.csv (An√°lise por analista)")
    print("   - Visualiza√ß√µes em PNG")
    
    return analisador


if __name__ == "__main__":
    analisador = main()