{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e901ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o dataset...\n",
      "‚úì Dados carregados\n",
      "\n",
      "================================================================================\n",
      "DADOS CARREGADOS COM SUCESSO\n",
      "================================================================================\n",
      "Total de registros: 74,502\n",
      "Total de colunas: 26\n",
      "\n",
      "================================================================================\n",
      "APLICANDO FILTRO CR√çTICO - REMOVENDO 2023\n",
      "================================================================================\n",
      "Registros por ano ANTES do filtro:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "2023    12814\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Removidos 12,814 registros de 2023 (17.2%)\n",
      "‚úì Dataset filtrado: 61,688 registros (2018-2022)\n",
      "\n",
      "Registros por ano AP√ìS filtro:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "Name: count, dtype: int64\n",
      "================================================================================\n",
      "‚úì Todas as colunas esperadas encontradas\n",
      "\n",
      "Empresas √∫nicas: 4,885\n",
      "Anos dispon√≠veis: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022)]\n",
      "\n",
      "Projetos multianuais: 46,238 (75.0%)\n",
      "\n",
      "Distribui√ß√£o por setor:\n",
      "setor_analise\n",
      "TIC                          16272\n",
      "Qu√≠mica e Farm√°cia           11708\n",
      "Mec√¢nica e Transporte         7990\n",
      "Agroind√∫stria e Alimentos     7499\n",
      "Transversal                   7090\n",
      "Eletroeletr√¥nica              6438\n",
      "Metalurgia e Minera√ß√£o        4656\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Projetos por ano:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "INFORMA√á√ïES DO DATASET\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 61688 entries, 0 to 61687\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   id_empresa_ano            61688 non-null  int64 \n",
      " 1   ano_referencia            61688 non-null  int64 \n",
      " 2   empresa_razao_social      61688 non-null  object\n",
      " 3   cnpj                      61688 non-null  int64 \n",
      " 4   atividade_economica       61688 non-null  object\n",
      " 5   codigo_atividade_ibge     61688 non-null  object\n",
      " 6   porte_empresa             61688 non-null  object\n",
      " 7   numero_projeto            61688 non-null  int64 \n",
      " 8   id_projeto                61688 non-null  int64 \n",
      " 9   nome_projeto              61686 non-null  object\n",
      " 10  descricao_projeto         61619 non-null  object\n",
      " 11  tipo_projeto              61688 non-null  object\n",
      " 12  area_projeto              50786 non-null  object\n",
      " 13  palavras_chave            43514 non-null  object\n",
      " 14  natureza                  61687 non-null  object\n",
      " 15  elemento_tecnologico      61687 non-null  object\n",
      " 16  desafio_tecnologico       61686 non-null  object\n",
      " 17  metodologia               61677 non-null  object\n",
      " 18  informacao_complementar   33805 non-null  object\n",
      " 19  resultado_economico       9716 non-null   object\n",
      " 20  resultado_inovacao        9768 non-null   object\n",
      " 21  descricao_rh              9134 non-null   object\n",
      " 22  descricao_materiais       5946 non-null   object\n",
      " 23  ciclo_maior_1_ano         61652 non-null  object\n",
      " 24  atividade_pdi_continuada  0 non-null      object\n",
      " 25  setor_analise             61653 non-null  object\n",
      " 26  projeto_multianual        61688 non-null  bool  \n",
      " 27  projeto_chave             61688 non-null  object\n",
      "dtypes: bool(1), int64(5), object(22)\n",
      "memory usage: 13.2+ MB\n",
      "None\n",
      "\n",
      "Primeiras 3 linhas do dataset:\n",
      "   id_empresa_ano  ano_referencia                empresa_razao_social  \\\n",
      "0               1            2018  ABBOTT LABORATORIOS DO BRASIL LTDA   \n",
      "1               1            2018  ABBOTT LABORATORIOS DO BRASIL LTDA   \n",
      "2               2            2018  ACHE LABORATORIOS FARMACEUTICOS SA   \n",
      "\n",
      "             cnpj                                atividade_economica  \\\n",
      "0  56998701000116  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "1  56998701000116  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "2  60659463000191  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "\n",
      "  codigo_atividade_ibge porte_empresa  numero_projeto  id_projeto  \\\n",
      "0          C.21.21-1/01        Demais               1        7911   \n",
      "1          C.21.21-1/01        Demais               2        7912   \n",
      "2          C.21.21-1/01        Demais               1        5796   \n",
      "\n",
      "                                        nome_projeto  ...  \\\n",
      "0  Desenvolvimento de uma nova linha de medicamen...  ...   \n",
      "1  Melhorias em produtos farmac√™uticos e novas me...  ...   \n",
      "2  Estudos, s√≠nteses, descoberta e aplica√ß√µes de ...  ...   \n",
      "\n",
      "  informacao_complementar resultado_economico resultado_inovacao descricao_rh  \\\n",
      "0                     NaN                 NaN                NaN          NaN   \n",
      "1                     NaN                 NaN                NaN          NaN   \n",
      "2                     NaN                 NaN                NaN          NaN   \n",
      "\n",
      "  descricao_materiais ciclo_maior_1_ano atividade_pdi_continuada  \\\n",
      "0                 NaN               Sim                      NaN   \n",
      "1                 NaN               Sim                      NaN   \n",
      "2                 NaN               Sim                      NaN   \n",
      "\n",
      "        setor_analise projeto_multianual  \\\n",
      "0  Qu√≠mica e Farm√°cia               True   \n",
      "1  Qu√≠mica e Farm√°cia               True   \n",
      "2  Qu√≠mica e Farm√°cia               True   \n",
      "\n",
      "                                       projeto_chave  \n",
      "0  56998701000116_Desenvolvimento de uma nova lin...  \n",
      "1  56998701000116_Melhorias em produtos farmac√™ut...  \n",
      "2  60659463000191_Estudos, s√≠nteses, descoberta e...  \n",
      "\n",
      "[3 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tentar diferentes abordagens para carregar o CSV problem√°tico\n",
    "print(\"Tentando carregar o dataset...\")\n",
    "\n",
    "# M√©todo 1: Tentar com error_bad_lines para pular linhas problem√°ticas\n",
    "try:\n",
    "    df = pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv', \n",
    "                     encoding='UTF-8', \n",
    "                     low_memory=False,\n",
    "                     sep=';',  # Garantir que est√° usando v√≠rgula\n",
    "                     quotechar='\"')  # Tratar aspas\n",
    "    print(\"‚úì Dados carregados\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no m√©todo 1: {e}\")\n",
    "    \n",
    "    # M√©todo 2: Ler linha por linha para identificar o problema\n",
    "    try:\n",
    "        # Primeiro, descobrir quantas colunas deveria ter\n",
    "        with open('csv_longo/projetos_resultados_pessoas_valores.csv', 'r', encoding='latin-1') as f:\n",
    "            header = f.readline()\n",
    "            n_cols = len(header.split(','))\n",
    "            print(f\"N√∫mero esperado de colunas: {n_cols}\")\n",
    "        \n",
    "        # Carregar pulando linhas ruins\n",
    "        df = pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv',\n",
    "                        encoding='latin-1',\n",
    "                        low_memory=False,\n",
    "                        on_bad_lines='warn',\n",
    "                        engine='python',\n",
    "                        sep=',',\n",
    "                        quotechar='\"',\n",
    "                        escapechar='\\\\')\n",
    "        print(\"‚úì Dados carregados com engine='python'\")\n",
    "    except:\n",
    "        # M√©todo 3: √öltima tentativa - ler em chunks\n",
    "        chunks = []\n",
    "        chunk_size = 10000\n",
    "        problematic_lines = []\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv',\n",
    "                                             encoding='latin-1',\n",
    "                                             low_memory=False,\n",
    "                                             on_bad_lines='skip',\n",
    "                                             chunksize=chunk_size)):\n",
    "            chunks.append(chunk)\n",
    "            print(f\"  Chunk {i+1} carregado ({len(chunk)} linhas)\")\n",
    "            \n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        print(\"‚úì Dados carregados em chunks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DADOS CARREGADOS COM SUCESSO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total de registros: {len(df):,}\")\n",
    "print(f\"Total de colunas: {df.shape[1]}\")\n",
    "\n",
    "# ============================================================\n",
    "# FILTRO CR√çTICO: REMOVER DADOS DE 2023 (DADOS INCOMPLETOS)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APLICANDO FILTRO CR√çTICO - REMOVENDO 2023\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar distribui√ß√£o antes do filtro\n",
    "if 'ano_referencia' in df.columns:\n",
    "    print(f\"Registros por ano ANTES do filtro:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "    \n",
    "    # Contagem antes\n",
    "    total_antes = len(df)\n",
    "    registros_2023 = (df['ano_referencia'] == 2023).sum()\n",
    "    \n",
    "    # APLICAR FILTRO - REMOVER 2023\n",
    "    df = df[df['ano_referencia'] != 2023].copy()\n",
    "    \n",
    "    print(f\"\\n‚úì Removidos {registros_2023:,} registros de 2023 ({registros_2023/total_antes*100:.1f}%)\")\n",
    "    print(f\"‚úì Dataset filtrado: {len(df):,} registros (2018-2022)\")\n",
    "    \n",
    "    print(f\"\\nRegistros por ano AP√ìS filtro:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Coluna 'ano_referencia' n√£o encontrada - verificar estrutura dos dados\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar colunas esperadas\n",
    "colunas_esperadas = ['id_projeto', 'ano_referencia', 'empresa_razao_social', 'cnpj', \n",
    "                     'nome_projeto', 'descricao_projeto', 'tipo_projeto', 'natureza',\n",
    "                     'elemento_tecnologico', 'desafio_tecnologico', 'metodologia',\n",
    "                     'setor_analise', 'ciclo_maior_1_ano']\n",
    "\n",
    "colunas_faltando = [col for col in colunas_esperadas if col not in df.columns]\n",
    "if colunas_faltando:\n",
    "    print(f\"\\n‚ö†Ô∏è Colunas faltando: {colunas_faltando}\")\n",
    "    print(\"Colunas dispon√≠veis:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:3d}. {col}\")\n",
    "else:\n",
    "    print(\"‚úì Todas as colunas esperadas encontradas\")\n",
    "\n",
    "# Continuar com a an√°lise se temos as colunas principais\n",
    "if all(col in df.columns for col in ['cnpj', 'ano_referencia', 'nome_projeto']):\n",
    "    print(f\"\\nEmpresas √∫nicas: {df['cnpj'].nunique():,}\")\n",
    "    print(f\"Anos dispon√≠veis: {sorted(df['ano_referencia'].dropna().unique())}\")\n",
    "    \n",
    "    # An√°lise de projetos multianuais\n",
    "    if 'ciclo_maior_1_ano' in df.columns:\n",
    "        df['projeto_multianual'] = df['ciclo_maior_1_ano'] == 'Sim'\n",
    "        print(f\"\\nProjetos multianuais: {df['projeto_multianual'].sum():,} ({df['projeto_multianual'].mean()*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Coluna 'ciclo_maior_1_ano' n√£o encontrada\")\n",
    "    \n",
    "    # Criar identificador √∫nico para rastrear projetos entre anos\n",
    "    df['projeto_chave'] = df['cnpj'].astype(str) + '_' + df['nome_projeto'].fillna('').astype(str).str[:50]\n",
    "    \n",
    "    # Distribui√ß√£o por setor\n",
    "    if 'setor_analise' in df.columns:\n",
    "        print(\"\\nDistribui√ß√£o por setor:\")\n",
    "        print(df['setor_analise'].value_counts())\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Coluna 'setor_analise' n√£o encontrada\")\n",
    "    \n",
    "    # Verificar anos com dados\n",
    "    print(\"\\nProjetos por ano:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n‚ùå Colunas essenciais n√£o encontradas. Verifique o arquivo CSV.\")\n",
    "\n",
    "# Mostrar informa√ß√µes sobre o dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INFORMA√á√ïES DO DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(df.info())\n",
    "\n",
    "# Verificar primeiras linhas\n",
    "print(\"\\nPrimeiras 3 linhas do dataset:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fcb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 11:07:04.020789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISE DE SIMILARIDADE COM GRANITE IBM - THRESHOLD 0.85\n",
      "================================================================================\n",
      "\n",
      "Filtrando dados de Eletroeletr√¥nica - 2021 - Processo...\n",
      "‚úì Projetos filtrados: 366\n",
      "\n",
      "================================================================================\n",
      "PREPARA√á√ÉO DOS DADOS\n",
      "================================================================================\n",
      "\n",
      "Estat√≠sticas dos textos:\n",
      "  - Total de projetos: 366\n",
      "  - Comprimento m√©dio: 8058 caracteres\n",
      "  - Comprimento m√≠nimo: 1077 caracteres\n",
      "  - Comprimento m√°ximo: 16166 caracteres\n",
      "\n",
      "================================================================================\n",
      "GERANDO EMBEDDINGS COM GRANITE IBM\n",
      "================================================================================\n",
      "Carregando modelo ibm-granite/granite-embedding-278m-multilingual...\n",
      "‚úì Modelo Granite carregado com sucesso\n",
      "\n",
      "Gerando embeddings para 366 projetos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e9e35498cc494f8e5894ff497ce89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embeddings gerados: shape (366, 768)\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO SIMILARIDADES\n",
      "================================================================================\n",
      "Calculando matriz de similaridade...\n",
      "\n",
      "‚úì Matriz calculada: (366, 366)\n",
      "  - Total de compara√ß√µes √∫nicas: 66,795\n",
      "\n",
      "Estat√≠sticas de similaridade:\n",
      "  - M√©dia: 0.6096\n",
      "  - Desvio padr√£o: 0.0578\n",
      "  - M√≠nima: 0.4090\n",
      "  - M√°xima: 1.0000\n",
      "  - Mediana: 0.6069\n",
      "\n",
      "Percentis:\n",
      "  - 75%: 0.6459\n",
      "  - 80%: 0.6556\n",
      "  - 85%: 0.6678\n",
      "  - 90%: 0.6831\n",
      "  - 95%: 0.7071\n",
      "  - 99%: 0.7563\n",
      "\n",
      "================================================================================\n",
      "IDENTIFICANDO PARES SIMILARES (THRESHOLD >= 0.85)\n",
      "================================================================================\n",
      "Procurando pares com similaridade >= 0.85...\n",
      "\n",
      "‚úì Pares encontrados: 70\n",
      "\n",
      "Estat√≠sticas dos pares similares:\n",
      "  - Similaridade m√°xima: 1.0000\n",
      "  - Similaridade m√©dia: 0.9478\n",
      "  - Similaridade m√≠nima: 0.8500\n",
      "\n",
      "Distribui√ß√£o por faixas:\n",
      "  - [0.98, 1.00): 33 pares (47.1%)\n",
      "  - [0.95, 0.98): 10 pares (14.3%)\n",
      "  - [0.90, 0.95): 8 pares (11.4%)\n",
      "  - [0.85, 0.90): 19 pares (27.1%)\n",
      "\n",
      "Top 10 pares mais similares:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68931] Torre M√≥vel - Desenvolvimento de Torre de Emerg√™nc...\n",
      "  Projeto 2: [68967] Torre M√≥vel - Desenvolvimento de Torre de Emerg√™nc...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68304] Desenvolvimento experimental de estrat√©gias para c...\n",
      "  Projeto 2: [68315] Desenvolvimento experimental de estrat√©gias para c...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68305] Desenvolvimento de solu√ß√µes para a eletromobilidad...\n",
      "  Projeto 2: [68316] Desenvolvimento de solu√ß√µes para a eletromobilidad...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68824] Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, ...\n",
      "  Projeto 2: [68828] Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, ...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [62849] Desenvolvimento experimental de solu√ß√µes tecnol√≥gi...\n",
      "  Projeto 2: [62887] Desenvolvimento experimental de solu√ß√µes tecnol√≥gi...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [60401] Desenvolvimento experimental de solu√ß√µes para apri...\n",
      "  Projeto 2: [60905] Desenvolvimento experimental de solu√ß√µes para apri...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [63136] Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "  Projeto 2: [63366] Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68310] Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnol...\n",
      "  Projeto 2: [68319] Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnol...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68927] Limpeza de Isoladores - Sistema inteligente de pla...\n",
      "  Projeto 2: [68963] Limpeza de Isoladores - Sistema inteligente de pla...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68929] Manuten√ß√£o preditiva - Sistema inteligente de manu...\n",
      "  Projeto 2: [68965] Manuten√ß√£o preditiva - Sistema inteligente de manu...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE POR TIPO DE PAR\n",
      "================================================================================\n",
      "  - Pares da mesma empresa: 11 (15.7%)\n",
      "  - Pares entre empresas diferentes: 59 (84.3%)\n",
      "\n",
      "Empresas com mais projetos similares:\n",
      "  - ITUMBIARA TRANSMISSORA DE ENERGIA S/A: 11 apari√ß√µes em pares similares\n",
      "  - EXPANSION TRANSMISSAO DE ENERGIA ELETRICA S/A: 9 apari√ß√µes em pares similares\n",
      "  - SERRA DA MESA TRANSMISSORA DE ENERGIA S. A.: 9 apari√ß√µes em pares similares\n",
      "  - WEG EQUIPAMENTOS ELETRICOS S/A: 8 apari√ß√µes em pares similares\n",
      "  - SCHWEITZER ENGINEERING LABORATORIES COMERCIAL LTDA: 7 apari√ß√µes em pares similares\n",
      "\n",
      "================================================================================\n",
      "SALVANDO RESULTADOS\n",
      "================================================================================\n",
      "‚úì Dataset filtrado salvo: eletr_2021_proc.csv\n",
      "  - Total de projetos: 366\n",
      "  - Total de colunas: 28\n",
      "\n",
      "‚úì Pares similares salvos: eletr_2021_proc_similar.csv\n",
      "  - Total de pares: 70\n",
      "  - Colunas inclu√≠das: IdProjeto_1, NomeProjeto_1, IdProjeto_2, NomeProjeto_2, Similaridade_score, Empresa_1, Empresa_2, Mesma_Empresa, CNPJ_1, CNPJ_2\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE CONCLU√çDA COM SUCESSO\n",
      "================================================================================\n",
      "\n",
      "üìä RESUMO EXECUTIVO:\n",
      "  ‚Ä¢ Modelo utilizado: Granite IBM Multilingual\n",
      "  ‚Ä¢ Projetos analisados: 366\n",
      "  ‚Ä¢ Threshold aplicado: 0.85\n",
      "  ‚Ä¢ Pares similares identificados: 70\n",
      "  ‚Ä¢ Taxa de pares similares: 0.105%\n",
      "\n",
      "üìÅ Arquivos gerados:\n",
      "  1. eletr_2021_proc.csv - Base completa filtrada\n",
      "  2. eletr_2021_proc_similar.csv - Pares com similaridade >= 0.85\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHUNK 2: AN√ÅLISE DEFINITIVA COM GRANITE - THRESHOLD 0.85\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISE DE SIMILARIDADE COM GRANITE IBM - THRESHOLD 0.85\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar dados\n",
    "print(\"\\nFiltrando dados de Eletroeletr√¥nica - 2021 - Processo...\")\n",
    "filtro = (\n",
    "    (df['setor_analise'] == 'Eletroeletr√¥nica') & \n",
    "    (df['ano_referencia'] == 2021) & \n",
    "    (df['natureza'] == 'Processo')\n",
    ")\n",
    "\n",
    "eletr_2021_proc = df[filtro].copy()\n",
    "print(f\"‚úì Projetos filtrados: {len(eletr_2021_proc)}\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARA√á√ÉO DOS TEXTOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARA√á√ÉO DOS DADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Campos de texto principais\n",
    "campos_texto = ['nome_projeto', 'elemento_tecnologico', 'desafio_tecnologico', \n",
    "                'metodologia', 'descricao_projeto']\n",
    "\n",
    "# Limpar valores nulos\n",
    "for campo in campos_texto:\n",
    "    if campo in eletr_2021_proc.columns:\n",
    "        eletr_2021_proc[campo] = eletr_2021_proc[campo].fillna('').astype(str)\n",
    "\n",
    "# Criar texto completo sem truncamento\n",
    "def criar_texto_completo(row):\n",
    "    \"\"\"Concatena todos os campos dispon√≠veis\"\"\"\n",
    "    partes = []\n",
    "    for campo in campos_texto:\n",
    "        if campo in row and row[campo] and str(row[campo]).strip():\n",
    "            partes.append(str(row[campo]).strip())\n",
    "    return \" \".join(partes)\n",
    "\n",
    "eletr_2021_proc['texto_completo'] = eletr_2021_proc.apply(criar_texto_completo, axis=1)\n",
    "\n",
    "# Estat√≠sticas dos textos\n",
    "comprimentos = eletr_2021_proc['texto_completo'].str.len()\n",
    "print(f\"\\nEstat√≠sticas dos textos:\")\n",
    "print(f\"  - Total de projetos: {len(eletr_2021_proc)}\")\n",
    "print(f\"  - Comprimento m√©dio: {comprimentos.mean():.0f} caracteres\")\n",
    "print(f\"  - Comprimento m√≠nimo: {comprimentos.min():.0f} caracteres\")\n",
    "print(f\"  - Comprimento m√°ximo: {comprimentos.max():.0f} caracteres\")\n",
    "\n",
    "# Verificar e remover textos vazios\n",
    "textos_vazios = (comprimentos == 0).sum()\n",
    "if textos_vazios > 0:\n",
    "    print(f\"  ‚ö†Ô∏è Removendo {textos_vazios} projetos sem texto\")\n",
    "    eletr_2021_proc = eletr_2021_proc[comprimentos > 0].copy()\n",
    "\n",
    "# ============================================================\n",
    "# GERAR EMBEDDINGS COM GRANITE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO EMBEDDINGS COM GRANITE IBM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Carregar modelo Granite\n",
    "print(\"Carregando modelo ibm-granite/granite-embedding-278m-multilingual...\")\n",
    "try:\n",
    "    model = SentenceTransformer('ibm-granite/granite-embedding-278m-multilingual')\n",
    "    print(\"‚úì Modelo Granite carregado com sucesso\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Usando modelo alternativo multil√≠ngue...\")\n",
    "    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    print(\"‚úì Modelo alternativo carregado\")\n",
    "\n",
    "# Preparar textos\n",
    "textos = eletr_2021_proc['texto_completo'].tolist()\n",
    "ids_projetos = eletr_2021_proc['id_projeto'].tolist() if 'id_projeto' in eletr_2021_proc.columns else eletr_2021_proc.index.tolist()\n",
    "nomes_projetos = eletr_2021_proc['nome_projeto'].tolist()\n",
    "\n",
    "print(f\"\\nGerando embeddings para {len(textos)} projetos...\")\n",
    "\n",
    "# Gerar embeddings\n",
    "embeddings = model.encode(\n",
    "    textos,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Embeddings gerados: shape {embeddings.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# CALCULAR MATRIZ DE SIMILARIDADE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULANDO SIMILARIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular matriz de similaridade\n",
    "print(\"Calculando matriz de similaridade...\")\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "upper_triangle = np.triu(similarity_matrix, k=1)\n",
    "all_similarities = upper_triangle[upper_triangle > 0]\n",
    "\n",
    "print(f\"\\n‚úì Matriz calculada: {similarity_matrix.shape}\")\n",
    "print(f\"  - Total de compara√ß√µes √∫nicas: {len(all_similarities):,}\")\n",
    "print(f\"\\nEstat√≠sticas de similaridade:\")\n",
    "print(f\"  - M√©dia: {all_similarities.mean():.4f}\")\n",
    "print(f\"  - Desvio padr√£o: {all_similarities.std():.4f}\")\n",
    "print(f\"  - M√≠nima: {all_similarities.min():.4f}\")\n",
    "print(f\"  - M√°xima: {all_similarities.max():.4f}\")\n",
    "print(f\"  - Mediana: {np.median(all_similarities):.4f}\")\n",
    "\n",
    "# Percentis importantes\n",
    "percentis = [75, 80, 85, 90, 95, 99]\n",
    "print(f\"\\nPercentis:\")\n",
    "for p in percentis:\n",
    "    valor = np.percentile(all_similarities, p)\n",
    "    print(f\"  - {p}%: {valor:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# IDENTIFICAR PARES SIMILARES (>= 0.85)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IDENTIFICANDO PARES SIMILARES (THRESHOLD >= 0.85)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "threshold = 0.85\n",
    "pares_similares = []\n",
    "\n",
    "# Iterar sobre triangular superior para evitar duplicatas\n",
    "print(\"Procurando pares com similaridade >= 0.85...\")\n",
    "for i in range(len(ids_projetos)):\n",
    "    for j in range(i + 1, len(ids_projetos)):\n",
    "        similaridade = similarity_matrix[i, j]\n",
    "        \n",
    "        if similaridade >= threshold:\n",
    "            # Coletar informa√ß√µes adicionais se dispon√≠veis\n",
    "            registro = {\n",
    "                'IdProjeto_1': ids_projetos[i],\n",
    "                'NomeProjeto_1': nomes_projetos[i],\n",
    "                'IdProjeto_2': ids_projetos[j],\n",
    "                'NomeProjeto_2': nomes_projetos[j],\n",
    "                'Similaridade_score': float(similaridade)\n",
    "            }\n",
    "            \n",
    "            # Adicionar informa√ß√µes de empresa se dispon√≠veis\n",
    "            if 'empresa_razao_social' in eletr_2021_proc.columns:\n",
    "                registro['Empresa_1'] = eletr_2021_proc.iloc[i]['empresa_razao_social']\n",
    "                registro['Empresa_2'] = eletr_2021_proc.iloc[j]['empresa_razao_social']\n",
    "                registro['Mesma_Empresa'] = registro['Empresa_1'] == registro['Empresa_2']\n",
    "            \n",
    "            if 'cnpj' in eletr_2021_proc.columns:\n",
    "                registro['CNPJ_1'] = eletr_2021_proc.iloc[i]['cnpj']\n",
    "                registro['CNPJ_2'] = eletr_2021_proc.iloc[j]['cnpj']\n",
    "            \n",
    "            pares_similares.append(registro)\n",
    "\n",
    "# Criar DataFrame com pares similares\n",
    "eletr_2021_proc_similar = pd.DataFrame(pares_similares)\n",
    "\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    # Ordenar por similaridade\n",
    "    eletr_2021_proc_similar = eletr_2021_proc_similar.sort_values('Similaridade_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\n‚úì Pares encontrados: {len(eletr_2021_proc_similar)}\")\n",
    "    \n",
    "    # Estat√≠sticas dos pares\n",
    "    print(f\"\\nEstat√≠sticas dos pares similares:\")\n",
    "    print(f\"  - Similaridade m√°xima: {eletr_2021_proc_similar['Similaridade_score'].max():.4f}\")\n",
    "    print(f\"  - Similaridade m√©dia: {eletr_2021_proc_similar['Similaridade_score'].mean():.4f}\")\n",
    "    print(f\"  - Similaridade m√≠nima: {eletr_2021_proc_similar['Similaridade_score'].min():.4f}\")\n",
    "    \n",
    "    # An√°lise por faixas\n",
    "    print(f\"\\nDistribui√ß√£o por faixas:\")\n",
    "    faixas = [(0.98, 1.00), (0.95, 0.98), (0.90, 0.95), (0.85, 0.90)]\n",
    "    for min_val, max_val in faixas:\n",
    "        if max_val == 1.00:\n",
    "            count = (eletr_2021_proc_similar['Similaridade_score'] >= min_val).sum()\n",
    "        else:\n",
    "            count = ((eletr_2021_proc_similar['Similaridade_score'] >= min_val) & \n",
    "                    (eletr_2021_proc_similar['Similaridade_score'] < max_val)).sum()\n",
    "        pct = count / len(eletr_2021_proc_similar) * 100 if len(eletr_2021_proc_similar) > 0 else 0\n",
    "        print(f\"  - [{min_val:.2f}, {max_val:.2f}): {count} pares ({pct:.1f}%)\")\n",
    "    \n",
    "    # Top 10 pares mais similares\n",
    "    print(f\"\\nTop 10 pares mais similares:\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx, row in eletr_2021_proc_similar.head(10).iterrows():\n",
    "        print(f\"\\nSimilaridade: {row['Similaridade_score']:.4f}\")\n",
    "        print(f\"  Projeto 1: [{row['IdProjeto_1']}] {row['NomeProjeto_1'][:50]}...\")\n",
    "        print(f\"  Projeto 2: [{row['IdProjeto_2']}] {row['NomeProjeto_2'][:50]}...\")\n",
    "        if 'Mesma_Empresa' in row:\n",
    "            tipo = \"MESMA EMPRESA\" if row['Mesma_Empresa'] else \"EMPRESAS DIFERENTES\"\n",
    "            print(f\"  Tipo: {tipo}\")\n",
    "    \n",
    "    # An√°lise por empresa se dispon√≠vel\n",
    "    if 'Mesma_Empresa' in eletr_2021_proc_similar.columns:\n",
    "        mesma_empresa = eletr_2021_proc_similar['Mesma_Empresa'].sum()\n",
    "        diferentes = len(eletr_2021_proc_similar) - mesma_empresa\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"AN√ÅLISE POR TIPO DE PAR\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"  - Pares da mesma empresa: {mesma_empresa} ({mesma_empresa/len(eletr_2021_proc_similar)*100:.1f}%)\")\n",
    "        print(f\"  - Pares entre empresas diferentes: {diferentes} ({diferentes/len(eletr_2021_proc_similar)*100:.1f}%)\")\n",
    "        \n",
    "        # Empresas com mais pares similares\n",
    "        if 'Empresa_1' in eletr_2021_proc_similar.columns:\n",
    "            print(f\"\\nEmpresas com mais projetos similares:\")\n",
    "            todas_empresas = pd.concat([\n",
    "                eletr_2021_proc_similar['Empresa_1'],\n",
    "                eletr_2021_proc_similar['Empresa_2']\n",
    "            ])\n",
    "            top_empresas = todas_empresas.value_counts().head(5)\n",
    "            for empresa, count in top_empresas.items():\n",
    "                print(f\"  - {empresa[:50]}: {count} apari√ß√µes em pares similares\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Nenhum par encontrado com similaridade >= {threshold}\")\n",
    "\n",
    "# ============================================================\n",
    "# SALVAR RESULTADOS EM CSV\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SALVANDO RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Remover coluna tempor√°ria antes de salvar\n",
    "if 'texto_completo' in eletr_2021_proc.columns:\n",
    "    eletr_2021_proc_export = eletr_2021_proc.drop(columns=['texto_completo'])\n",
    "else:\n",
    "    eletr_2021_proc_export = eletr_2021_proc.copy()\n",
    "\n",
    "# Salvar dataset filtrado\n",
    "arquivo_projetos = 'eletr_2021_proc.csv'\n",
    "eletr_2021_proc_export.to_csv(arquivo_projetos, index=False, encoding='utf-8-sig', sep=';')\n",
    "print(f\"‚úì Dataset filtrado salvo: {arquivo_projetos}\")\n",
    "print(f\"  - Total de projetos: {len(eletr_2021_proc_export)}\")\n",
    "print(f\"  - Total de colunas: {eletr_2021_proc_export.shape[1]}\")\n",
    "\n",
    "# Salvar pares similares\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    # Selecionar colunas essenciais para o CSV\n",
    "    colunas_essenciais = ['IdProjeto_1', 'NomeProjeto_1', 'IdProjeto_2', 'NomeProjeto_2', 'Similaridade_score']\n",
    "    colunas_extras = ['Empresa_1', 'Empresa_2', 'Mesma_Empresa', 'CNPJ_1', 'CNPJ_2']\n",
    "    \n",
    "    # Adicionar colunas extras se existirem\n",
    "    colunas_export = colunas_essenciais + [col for col in colunas_extras if col in eletr_2021_proc_similar.columns]\n",
    "    eletr_2021_proc_similar_export = eletr_2021_proc_similar[colunas_export]\n",
    "    \n",
    "    arquivo_similares = 'eletr_2021_proc_similar.csv'\n",
    "    eletr_2021_proc_similar_export.to_csv(arquivo_similares, index=False, encoding='utf-8-sig', sep=';')\n",
    "    print(f\"\\n‚úì Pares similares salvos: {arquivo_similares}\")\n",
    "    print(f\"  - Total de pares: {len(eletr_2021_proc_similar_export)}\")\n",
    "    print(f\"  - Colunas inclu√≠das: {', '.join(colunas_export)}\")\n",
    "else:\n",
    "    # Criar arquivo vazio com estrutura b√°sica\n",
    "    df_vazio = pd.DataFrame(columns=['IdProjeto_1', 'NomeProjeto_1', 'IdProjeto_2', 'NomeProjeto_2', 'Similaridade_score'])\n",
    "    df_vazio.to_csv('eletr_2021_proc_similar.csv', index=False, encoding='utf-8-sig', sep=';')\n",
    "    print(f\"\\n‚úì Arquivo de pares similares criado (vazio - nenhum par acima do threshold)\")\n",
    "\n",
    "# ============================================================\n",
    "# RESUMO FINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE CONCLU√çDA COM SUCESSO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä RESUMO EXECUTIVO:\")\n",
    "print(f\"  ‚Ä¢ Modelo utilizado: Granite IBM Multilingual\")\n",
    "print(f\"  ‚Ä¢ Projetos analisados: {len(eletr_2021_proc)}\")\n",
    "print(f\"  ‚Ä¢ Threshold aplicado: {threshold}\")\n",
    "print(f\"  ‚Ä¢ Pares similares identificados: {len(eletr_2021_proc_similar)}\")\n",
    "\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    taxa = len(eletr_2021_proc_similar) / (len(eletr_2021_proc) * (len(eletr_2021_proc) - 1) / 2) * 100\n",
    "    print(f\"  ‚Ä¢ Taxa de pares similares: {taxa:.3f}%\")\n",
    "\n",
    "print(f\"\\nüìÅ Arquivos gerados:\")\n",
    "print(f\"  1. eletr_2021_proc.csv - Base completa filtrada\")\n",
    "print(f\"  2. eletr_2021_proc_similar.csv - Pares com similaridade >= 0.85\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18592e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Encontrados 490 documentos\n",
      "   Processados 2/490...\n",
      "   Processados 4/490...\n",
      "   Processados 6/490...\n",
      "   Processados 8/490...\n",
      "   Processados 10/490...\n",
      "   Processados 12/490...\n",
      "   Processados 14/490...\n",
      "   Processados 16/490...\n",
      "   Processados 18/490...\n",
      "   Processados 20/490...\n",
      "   Processados 22/490...\n",
      "   Processados 24/490...\n",
      "   Processados 26/490...\n",
      "   Processados 28/490...\n",
      "   Processados 30/490...\n",
      "   Processados 32/490...\n",
      "   Processados 34/490...\n",
      "   Processados 36/490...\n",
      "   Processados 38/490...\n",
      "   Processados 40/490...\n",
      "   Processados 42/490...\n",
      "   Processados 44/490...\n",
      "   Processados 46/490...\n",
      "   Processados 48/490...\n",
      "   Processados 50/490...\n",
      "   Processados 52/490...\n",
      "   Processados 54/490...\n",
      "   Processados 56/490...\n",
      "   Processados 58/490...\n",
      "   Processados 60/490...\n",
      "   Processados 62/490...\n",
      "   Processados 64/490...\n",
      "   Processados 66/490...\n",
      "   Processados 68/490...\n",
      "   Processados 70/490...\n",
      "   Processados 72/490...\n",
      "   Processados 74/490...\n",
      "   Processados 76/490...\n",
      "   Processados 78/490...\n",
      "   Processados 80/490...\n",
      "   Processados 82/490...\n",
      "   Processados 84/490...\n",
      "   Processados 86/490...\n",
      "   Processados 88/490...\n",
      "   Processados 90/490...\n",
      "   Processados 92/490...\n",
      "   Processados 94/490...\n",
      "   Processados 96/490...\n",
      "   Processados 98/490...\n",
      "   Processados 100/490...\n",
      "   Processados 102/490...\n",
      "   Processados 104/490...\n",
      "   Processados 106/490...\n",
      "   Processados 108/490...\n",
      "   Processados 110/490...\n",
      "   Processados 112/490...\n",
      "   Processados 114/490...\n",
      "   Processados 116/490...\n",
      "   Processados 118/490...\n",
      "   Processados 120/490...\n",
      "   Processados 122/490...\n",
      "   Processados 124/490...\n",
      "   Processados 126/490...\n",
      "   Processados 128/490...\n",
      "   Processados 130/490...\n",
      "   Processados 132/490...\n",
      "   Processados 134/490...\n",
      "   Processados 136/490...\n",
      "   Processados 138/490...\n",
      "   Processados 140/490...\n",
      "   Processados 142/490...\n",
      "   Processados 144/490...\n",
      "   Processados 146/490...\n",
      "   Processados 148/490...\n",
      "   Processados 150/490...\n",
      "   Processados 152/490...\n",
      "   Processados 154/490...\n",
      "   Processados 156/490...\n",
      "   Processados 158/490...\n",
      "   Processados 160/490...\n",
      "   Processados 162/490...\n",
      "   Processados 164/490...\n",
      "   Processados 166/490...\n",
      "   Processados 168/490...\n",
      "   Processados 170/490...\n",
      "   Processados 172/490...\n",
      "   Processados 174/490...\n",
      "   Processados 176/490...\n",
      "   Processados 178/490...\n",
      "   Processados 180/490...\n",
      "   Processados 182/490...\n",
      "   Processados 184/490...\n",
      "   Processados 186/490...\n",
      "   Processados 188/490...\n",
      "   Processados 190/490...\n",
      "   Processados 192/490...\n",
      "   Processados 194/490...\n",
      "   Processados 196/490...\n",
      "   Processados 198/490...\n",
      "   Processados 200/490...\n",
      "   Processados 202/490...\n",
      "   Processados 204/490...\n",
      "   Processados 206/490...\n",
      "   Processados 208/490...\n",
      "   Processados 210/490...\n",
      "   Processados 212/490...\n",
      "   Processados 214/490...\n",
      "   Processados 216/490...\n",
      "   Processados 218/490...\n",
      "   Processados 220/490...\n",
      "   Processados 222/490...\n",
      "   Processados 224/490...\n",
      "   Processados 226/490...\n",
      "   Processados 228/490...\n",
      "   Processados 230/490...\n",
      "   Processados 232/490...\n",
      "   Processados 234/490...\n",
      "   Processados 236/490...\n",
      "   Processados 238/490...\n",
      "   Processados 240/490...\n",
      "   Processados 242/490...\n",
      "   Processados 244/490...\n",
      "   Processados 246/490...\n",
      "   Processados 248/490...\n",
      "   Processados 250/490...\n",
      "   Processados 252/490...\n",
      "   Processados 254/490...\n",
      "   Processados 256/490...\n",
      "   Processados 258/490...\n",
      "   Processados 260/490...\n",
      "   Processados 262/490...\n",
      "   Processados 264/490...\n",
      "   Processados 266/490...\n",
      "   Processados 268/490...\n",
      "   Processados 270/490...\n",
      "   Processados 272/490...\n",
      "   Processados 274/490...\n",
      "   Processados 276/490...\n",
      "   Processados 278/490...\n",
      "   Processados 280/490...\n",
      "   Processados 282/490...\n",
      "   Processados 284/490...\n",
      "   Processados 286/490...\n",
      "   Processados 288/490...\n",
      "   Processados 290/490...\n",
      "   Processados 292/490...\n",
      "   Processados 294/490...\n",
      "   Processados 296/490...\n",
      "   Processados 298/490...\n",
      "   Processados 300/490...\n",
      "   Processados 302/490...\n",
      "   Processados 304/490...\n",
      "   Processados 306/490...\n",
      "   Processados 308/490...\n",
      "   Processados 310/490...\n",
      "   Processados 312/490...\n",
      "   Processados 314/490...\n",
      "   Processados 316/490...\n",
      "   Processados 318/490...\n",
      "   Processados 320/490...\n",
      "   Processados 322/490...\n",
      "   Processados 324/490...\n",
      "   Processados 326/490...\n",
      "   Processados 328/490...\n",
      "   Processados 330/490...\n",
      "   Processados 332/490...\n",
      "   Processados 334/490...\n",
      "   Processados 336/490...\n",
      "   Processados 338/490...\n",
      "   Processados 340/490...\n",
      "   Processados 342/490...\n",
      "   Processados 344/490...\n",
      "   Processados 346/490...\n",
      "   Processados 348/490...\n",
      "   Processados 350/490...\n",
      "   Processados 352/490...\n",
      "   Processados 354/490...\n",
      "   Processados 356/490...\n",
      "   Processados 358/490...\n",
      "   Processados 360/490...\n",
      "   Processados 362/490...\n",
      "   Processados 364/490...\n",
      "   Processados 366/490...\n",
      "   Processados 368/490...\n",
      "   Processados 370/490...\n",
      "   Processados 372/490...\n",
      "   Processados 374/490...\n",
      "   Processados 376/490...\n",
      "   Processados 378/490...\n",
      "   Processados 380/490...\n",
      "   Processados 382/490...\n",
      "   Processados 384/490...\n",
      "   Processados 386/490...\n",
      "   Processados 388/490...\n",
      "   Processados 390/490...\n",
      "   Processados 392/490...\n",
      "   Processados 394/490...\n",
      "   Processados 396/490...\n",
      "   Processados 398/490...\n",
      "   Processados 400/490...\n",
      "   Processados 402/490...\n",
      "   Processados 404/490...\n",
      "   Processados 406/490...\n",
      "   Processados 408/490...\n",
      "   Processados 410/490...\n",
      "   Processados 412/490...\n",
      "   Processados 414/490...\n",
      "   Processados 416/490...\n",
      "   Processados 418/490...\n",
      "   Processados 420/490...\n",
      "   Processados 422/490...\n",
      "   Processados 424/490...\n",
      "   Processados 426/490...\n",
      "   Processados 428/490...\n",
      "   Processados 430/490...\n",
      "   Processados 432/490...\n",
      "   Processados 434/490...\n",
      "   Processados 436/490...\n",
      "   Processados 438/490...\n",
      "   Processados 440/490...\n",
      "   Processados 442/490...\n",
      "   Processados 444/490...\n",
      "   Processados 446/490...\n",
      "   Processados 448/490...\n",
      "   Processados 450/490...\n",
      "   Processados 452/490...\n",
      "   Processados 454/490...\n",
      "   Processados 456/490...\n",
      "   Processados 458/490...\n",
      "   Processados 460/490...\n",
      "   Processados 462/490...\n",
      "   Processados 464/490...\n",
      "   Processados 466/490...\n",
      "   Processados 468/490...\n",
      "   Processados 470/490...\n",
      "   Processados 472/490...\n",
      "   Processados 474/490...\n",
      "   Processados 476/490...\n",
      "   Processados 478/490...\n",
      "   Processados 480/490...\n",
      "   Processados 482/490...\n",
      "   Processados 484/490...\n",
      "   Processados 486/490...\n",
      "   Processados 488/490...\n",
      "   Processados 490/490...\n",
      "Warning: Skipping 12 empty/invalid text chunk(s). Processing 478 valid chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing passages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 478/478 [00:00<00:00, 27811.53chunk/s]\n",
      "WARNING - leann.embedding_compute - Text 477 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "\n",
      "WARNING - leann.embedding_compute - Text 477 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING - leann.embedding_compute - Text 478 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING - leann.embedding_compute - Truncation summary: 2/478 texts truncated (removed 55531 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/4 [00:00<?, ?it/s]WARNING - leann.embedding_compute - Text 478 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING - leann.embedding_compute - Truncation summary: 2/478 texts truncated (removed 55531 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:15<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 64 for level: 0\n",
      "Starting conversion: leann_index.leann/leann_index.index -> leann_index.leann/leann_index.csr.tmp\n",
      "[0.00s] Reading Index HNSW header...\n",
      "[0.00s]   Header read: d=768, ntotal=478\n",
      "[0.00s] Reading HNSW struct vectors...\n",
      "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
      "[0.00s]   Read assign_probas (6)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=6, Bytes=48\n",
      "[0.00s]   Read assign_probas (6)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=7, Bytes=28\n",
      "[0.15s]   Read cum_nneighbor_per_level (7)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=7, Bytes=28\n",
      "[0.15s]   Read cum_nneighbor_per_level (7)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count=478, Bytes=1912\n",
      "[0.27s]   Read levels (478)\n",
      "[0.40s]   Probing for compact storage flag...\n",
      "[0.40s]   Found compact flag: False\n",
      "[0.40s]   Compact flag is False, reading original format...\n",
      "[0.40s]   Probing for potential extra byte before non-compact offsets...\n",
      "[0.40s]   Found and consumed an unexpected 0x00 byte.\n",
      "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=479, Bytes=3832\n",
      "[0.40s]   Read offsets (479)\n",
      "[0.52s]   Attempting to read neighbors vector...\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=479, Bytes=3832\n",
      "[0.40s]   Read offsets (479)\n",
      "[0.52s]   Attempting to read neighbors vector...\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=30912, Bytes=123648\n",
      "[0.52s]   Read neighbors (30912)\n",
      "Count=30912, Bytes=123648\n",
      "[0.52s]   Read neighbors (30912)\n",
      "[0.64s]   Read scalar params (ep=473, max_lvl=1)\n",
      "[0.64s] Checking for storage data...\n",
      "[0.64s]   Found storage fourcc: 49467849.\n",
      "[0.64s] Converting to CSR format...\n",
      "[0.64s]   Conversion loop finished.                        \n",
      "[0.64s] Running validation checks...\n",
      "    Checking total valid neighbor count...\n",
      "    OK: Total valid neighbors = 6555\n",
      "    Checking final pointer indices...\n",
      "    OK: Final pointers match data size.\n",
      "[0.64s] Deleting original neighbors and offsets arrays...\n",
      "    CSR Stats: |data|=6555, |level_ptr|=966\n",
      "[0.76s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
      "   Pruning embeddings: Writing NULL storage marker.\n",
      "[0.89s] Conversion complete.\n",
      "‚úÖ Base vetorial criada em: ./leann_index.leann/leann_index\n",
      "üìä Economia de espa√ßo: ~97% comparado ao FAISS\n",
      "[0.64s]   Read scalar params (ep=473, max_lvl=1)\n",
      "[0.64s] Checking for storage data...\n",
      "[0.64s]   Found storage fourcc: 49467849.\n",
      "[0.64s] Converting to CSR format...\n",
      "[0.64s]   Conversion loop finished.                        \n",
      "[0.64s] Running validation checks...\n",
      "    Checking total valid neighbor count...\n",
      "    OK: Total valid neighbors = 6555\n",
      "    Checking final pointer indices...\n",
      "    OK: Final pointers match data size.\n",
      "[0.64s] Deleting original neighbors and offsets arrays...\n",
      "    CSR Stats: |data|=6555, |level_ptr|=966\n",
      "[0.76s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
      "   Pruning embeddings: Writing NULL storage marker.\n",
      "[0.89s] Conversion complete.\n",
      "‚úÖ Base vetorial criada em: ./leann_index.leann/leann_index\n",
      "üìä Economia de espa√ßo: ~97% comparado ao FAISS\n"
     ]
    }
   ],
   "source": [
    "from leann import LeannBuilder\n",
    "from pathlib import Path\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Defina onde seu √≠ndice ser√° salvo\n",
    "INDEX_PATH = \"./leann_index.leann/leann_index\"\n",
    "\n",
    "# Crie o construtor usando Ollama para embeddings\n",
    "builder = LeannBuilder(\n",
    "    backend_name=\"hnsw\",                # Motor de busca (padr√£o, mais leve)\n",
    "    embedding_mode=\"ollama\",            # Usar Ollama para embeddings\n",
    "    embedding_model=\"nomic-embed-text\"  # Modelo de embedding via Ollama\n",
    ")\n",
    "\n",
    "# Adicione seus documentos\n",
    "pasta_documentos = Path(\"./leann_index\")\n",
    "\n",
    "# Usando SimpleDirectoryReader para detec√ß√£o autom√°tica de tipos\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=pasta_documentos,\n",
    "    recursive=True,  # Processa subpastas tamb√©m\n",
    "    required_exts=['.pdf', '.txt', '.md', '.docx']  # Filtra apenas esses tipos\n",
    ")\n",
    "\n",
    "# Carrega os documentos\n",
    "documentos = reader.load_data()\n",
    "print(f\"üìÑ Encontrados {len(documentos)} documentos\")\n",
    "\n",
    "\n",
    "# Adiciona cada documento ao builder\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    builder.add_text(\n",
    "        text=doc.text,\n",
    "        metadata={\n",
    "            \"source\": doc.metadata.get(\"file_name\", \"unknown\"),\n",
    "            \"file_path\": doc.metadata.get(\"file_path\", \"\"),\n",
    "            \"file_type\": doc.metadata.get(\"file_type\", \"\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Mostra progresso a cada 2 documentos\n",
    "    if i % 2 == 0:\n",
    "        print(f\"   Processados {i}/{len(documentos)}...\")\n",
    "\n",
    "# Constr√≥i o √≠ndice (isso pode demorar dependendo do volume)\n",
    "builder.build_index(INDEX_PATH)\n",
    "\n",
    "print(f\"‚úÖ Base vetorial criada em: {INDEX_PATH}\")\n",
    "print(f\"üìä Economia de espa√ßo: ~97% comparado ao FAISS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d82d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALIDA√á√ÉO DE SIMILARIDADE COM LLM LOCAL (OLLAMA) - OTIMIZADO\n",
      "================================================================================\n",
      "\n",
      "Carregando dados...\n",
      "‚úì Projetos carregados: 366\n",
      "‚úì Pares similares carregados: 70\n",
      "\n",
      "‚öôÔ∏è Configura√ß√£o:\n",
      "   Modelo: qwen3:30b\n",
      "   Batch size: 10\n",
      "   Max chars por campo: 1500\n",
      "   Max chars LeANN: 4000\n",
      "   num_predict: 1500\n",
      "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
      "[read_HNSW NL v4] Read levels vector, size: 478\n",
      "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
      "[read_HNSW NL v4] Read compact_level_ptr, size: 966\n",
      "[read_HNSW NL v4] Read compact_node_offsets, size: 479\n",
      "[read_HNSW NL v4] Read entry_point: 473, max_level: 1\n",
      "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
      "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 13650\n",
      "[read_HNSW NL v4] Reading neighbors data into memory.\n",
      "[read_HNSW NL v4] Read neighbors data, size: 6555\n",
      "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
      "INFO: Skipping external storage loading, since is_recompute is true.\n",
      "‚úì LeANN Searcher inicializado\n",
      "\n",
      "Iniciando processamento...\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISE\n",
      "================================================================================\n",
      "\n",
      "üìä Total de pares: 70\n",
      "‚úì LeANN Searcher inicializado\n",
      "\n",
      "Iniciando processamento...\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISE\n",
      "================================================================================\n",
      "\n",
      "üìä Total de pares: 70\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.41it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.41it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.10it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68931 x 68967: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68304 x 68315: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.69it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.69it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "WARNING:leann.embedding_compute:Text 4 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/4 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 4 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/4 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68305 x 68316: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 13 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.32it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.32it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.51it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.51it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68824 x 68828: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.69it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.69it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.50it/s]\n",
      "WARNING:leann.embedding_compute:Text 8 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/8 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 8 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/8 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 62849 x 62887: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "WARNING:leann.embedding_compute:Text 23 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "WARNING:leann.embedding_compute:Text 23 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "WARNING:leann.embedding_compute:Text 11 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 11 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.34it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 60401 x 60905: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.34it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63136 x 63366: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68310 x 68319: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68927 x 68963: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "WARNING:leann.embedding_compute:Text 6 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/6 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 6 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/6 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68929 x 68965: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.79it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.79it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63100 x 63136: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.76it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.76it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63106 x 63372: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.32it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63100 x 63366: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65783 x 65787: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63106 x 63142: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63142 x 63372: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65776 x 65783: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65776 x 65787: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 19 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63103 x 63139: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63147 x 65745: ID√äNTICOS | Mesmo: ‚úì\n",
      "\n",
      "  üìä Progresso: 20/70 | Sucessos: 20 | Erros: 0\n",
      "\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s]\n",
      "WARNING:leann.embedding_compute:Text 34 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/34 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s]\n",
      "WARNING:leann.embedding_compute:Text 34 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/34 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "WARNING:leann.embedding_compute:Text 11 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 11 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59741 x 60405: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65895 x 66753: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63145 x 65783: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63145 x 65787: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63145 x 65776: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.27it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65779 x 65782: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.24it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65775 x 65779: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65775 x 65782: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63147 x 65786: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.84it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.84it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.13it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.13it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.79it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.79it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65745 x 65786: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.27it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.27it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.78it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.78it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63144 x 65782: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63144 x 65779: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65774 x 65781: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.92it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.92it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.26it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.26it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63144 x 65775: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.44it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.44it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 61128 x 61182: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65774 x 65778: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.68it/s]\n",
      "WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.68it/s]\n",
      "WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.79it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 67232 x 67242: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63143 x 65781: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63143 x 65774: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65778 x 65781: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "\n",
      "  üìä Progresso: 40/70 | Sucessos: 40 | Erros: 0\n",
      "\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.96it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.36it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.36it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 63143 x 65778: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 17 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/17 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 17 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/17 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
      "WARNING:leann.embedding_compute:Text 12 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/12 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 61137 x 62795: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 37 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/37 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 37 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/37 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59225 x 59364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.57it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.57it/s]\n",
      "WARNING:leann.embedding_compute:Text 1 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/1 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 1 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/1 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59905 x 59906: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59164 x 59364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.23it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.23it/s]\n",
      "WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 15 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/15 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 67229 x 67243: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 62147 x 62174: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.50it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.50it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.76it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.76it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.64it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.64it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 60650 x 62128: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 9 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/9 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59164 x 59225: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 13 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/13 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.12it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.12it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 65598 x 65599: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "WARNING:leann.embedding_compute:Text 17 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/17 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "WARNING:leann.embedding_compute:Text 17 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/17 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.72it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.24it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 60600 x 62101: ID√äNTICOS | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 26 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/26 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 26 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/26 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.75it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.75it/s]\n",
      "WARNING:leann.embedding_compute:Text 23 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 23 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.16it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.16it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 67228 x 67229: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "WARNING:leann.embedding_compute:Text 5 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/5 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 5 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/5 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 67285 x 67286: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.54it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.54it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59089 x 67370: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n",
      "WARNING:leann.embedding_compute:Text 16 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/16 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.66it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.74it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.92it/s]\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.92it/s]\n",
      "WARNING:leann.embedding_compute:Text 7 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/7 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 60646 x 60647: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56244 x 67366: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.39it/s]\n",
      "WARNING:leann.embedding_compute:Text 33 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/33 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.55it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.77it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.46it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.46it/s]\n",
      "WARNING:leann.embedding_compute:Text 2 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/2 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 2 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/2 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56280 x 56364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.32it/s]\n",
      "WARNING:leann.embedding_compute:Text 35 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/35 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.32it/s]\n",
      "WARNING:leann.embedding_compute:Text 35 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/35 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "WARNING:leann.embedding_compute:Text 4 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/4 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 4 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/4 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 62165 x 62167: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.10it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.10it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.55it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 2 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/2 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 2 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/2 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.42it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59894 x 59895: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.46it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.46it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56274 x 67366: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "\n",
      "  üìä Progresso: 60/70 | Sucessos: 60 | Erros: 0\n",
      "\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56244 x 56363: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s]\n",
      "WARNING:leann.embedding_compute:Text 23 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s]\n",
      "WARNING:leann.embedding_compute:Text 23 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/23 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "WARNING:leann.embedding_compute:Text 6 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/6 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 6 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/6 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 58467 x 59402: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.28it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 62123 x 62124: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.10it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.10it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.49it/s]\n",
      "WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 14 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/14 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56244 x 56364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 37 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/37 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.40it/s]\n",
      "WARNING:leann.embedding_compute:Text 37 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/37 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.21it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.07it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "WARNING:leann.embedding_compute:Text 5 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/5 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "WARNING:leann.embedding_compute:Text 5 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/5 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 60697 x 60800: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.19s/it]\n",
      "WARNING:leann.embedding_compute:Text 21 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/21 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.19s/it]\n",
      "WARNING:leann.embedding_compute:Text 21 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/21 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "WARNING:leann.embedding_compute:Text 11 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 11 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/11 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.68it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 59876 x 59899: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 18 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/18 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.46it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.46it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56274 x 56364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56363 x 67366: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.99it/s]\n",
      "WARNING:leann.embedding_compute:Text 19 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/19 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "WARNING:leann.embedding_compute:Text 10 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/10 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 56363 x 56364: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n",
      "ZmqDistanceComputer initialized: d=768, metric=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HNSW RNG] get_vector_zmq id=473 cache_hit=0\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "WARNING:leann.embedding_compute:Text 22 truncated: 4433 ‚Üí 2048 tokens (2385 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/22 texts truncated (removed 2385 tokens total, longest was 4433 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "WARNING:leann.embedding_compute:Text 20 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched):   0%|          | 0/1 [00:00<?, ?it/s]WARNING:leann.embedding_compute:Text 20 truncated: 55194 ‚Üí 2048 tokens (53146 tokens removed)\n",
      "WARNING:leann.embedding_compute:Truncation summary: 1/20 texts truncated (removed 53146 tokens total, longest was 55194 tokens)\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Computing Ollama embeddings (batched): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Par 68467 x 68512: MUITO_SIMILARES | Mesmo: ‚úì\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "üìä Total: 70\n",
      "   ‚úì Sucesso: 70 (100.0%)\n",
      "   ‚ùå Erros: 0 (0.0%)\n",
      "   ‚è±Ô∏è Tempo: 27.8 min\n",
      "\n",
      "üìã Distribui√ß√£o:\n",
      "classificacao\n",
      "ID√äNTICOS          37\n",
      "MUITO_SIMILARES    33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìå Mesmo tratamento: 70/70 (100.0%)\n",
      "\n",
      "‚úì Salvo em: validacao_llm_pares_similares.csv\n",
      "\n",
      "================================================================================\n",
      "CONCLU√çDO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "üìä Total: 70\n",
      "   ‚úì Sucesso: 70 (100.0%)\n",
      "   ‚ùå Erros: 0 (0.0%)\n",
      "   ‚è±Ô∏è Tempo: 27.8 min\n",
      "\n",
      "üìã Distribui√ß√£o:\n",
      "classificacao\n",
      "ID√äNTICOS          37\n",
      "MUITO_SIMILARES    33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìå Mesmo tratamento: 70/70 (100.0%)\n",
      "\n",
      "‚úì Salvo em: validacao_llm_pares_similares.csv\n",
      "\n",
      "================================================================================\n",
      "CONCLU√çDO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHUNK 3 OTIMIZADO: VALIDA√á√ÉO COM LLM LOCAL (OLLAMA)\n",
    "# VERS√ÉO CORRIGIDA - COM TRUNCAMENTO E PROMPT OTIMIZADO\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ollama\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from leann import LeannSearcher\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDA√á√ÉO DE SIMILARIDADE COM LLM LOCAL (OLLAMA) - OTIMIZADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Carregar os dados\n",
    "print(\"\\nCarregando dados...\")\n",
    "eletr_2021_proc = pd.read_csv('eletr_2021_proc.csv', sep=';', encoding='utf-8-sig')\n",
    "eletr_2021_proc_similar = pd.read_csv('eletr_2021_proc_similar.csv', sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úì Projetos carregados: {len(eletr_2021_proc)}\")\n",
    "print(f\"‚úì Pares similares carregados: {len(eletr_2021_proc_similar)}\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURA√á√ÉO\n",
    "# ============================================================\n",
    "\n",
    "MODEL = \"qwen3:30b\"\n",
    "MAX_CHARS_CAMPO = 1500  # Aumentado - temos contexto de sobra\n",
    "MAX_CHARS_LEANN = 4000  # Aumentado para mais contexto de refer√™ncia\n",
    "NUM_PREDICT = 1500  # Aumentado para respostas mais completas\n",
    "BATCH_SIZE = 10  # Reduzido para melhor controle\n",
    "MAX_TOTAL_CHARS = 80000  # Limite total para evitar estouro\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Configura√ß√£o:\")\n",
    "print(f\"   Modelo: {MODEL}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Max chars por campo: {MAX_CHARS_CAMPO}\")\n",
    "print(f\"   Max chars LeANN: {MAX_CHARS_LEANN}\")\n",
    "print(f\"   num_predict: {NUM_PREDICT}\")\n",
    "\n",
    "# ============================================================\n",
    "# INICIALIZAR LEANN\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    leann_searcher = LeannSearcher(index_path=\"./leann_index.leann/leann_index\")\n",
    "    print(\"‚úì LeANN Searcher inicializado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è LeANN n√£o dispon√≠vel: {e}\")\n",
    "    leann_searcher = None\n",
    "\n",
    "# ============================================================\n",
    "# FUN√á√ïES AUXILIARES COM TRUNCAMENTO\n",
    "# ============================================================\n",
    "\n",
    "def truncar_texto(texto, max_chars=800):\n",
    "    \"\"\"Trunca texto preservando palavras completas.\"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return \"N√£o informado\"\n",
    "    texto = str(texto).strip()\n",
    "    texto = ' '.join(texto.split())  # Normaliza espa√ßos\n",
    "    if len(texto) <= max_chars:\n",
    "        return texto\n",
    "    # Trunca na √∫ltima palavra completa\n",
    "    truncado = texto[:max_chars].rsplit(' ', 1)[0]\n",
    "    return truncado + \"...\"\n",
    "\n",
    "def buscar_contexto_inovacao(searcher, texto: str, top_k: int = 3, max_chars: int = 2000) -> str:\n",
    "    \"\"\"Busca contexto LeANN com limite de tamanho.\"\"\"\n",
    "    if searcher is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        resultados = searcher.search(texto[:500], top_k=top_k)  # Limita texto de busca\n",
    "        contextos = []\n",
    "        total_chars = 0\n",
    "        for i, resultado in enumerate(resultados, 1):\n",
    "            texto_resultado = resultado.text[:600]  # Limita cada resultado\n",
    "            if total_chars + len(texto_resultado) > max_chars:\n",
    "                break\n",
    "            contextos.append(f\"[{i}] {texto_resultado}\")\n",
    "            total_chars += len(texto_resultado)\n",
    "        return \"\\n\".join(contextos) if contextos else \"\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extrair_info_projeto(projeto_row: pd.Series, max_chars: int = 800) -> dict:\n",
    "    \"\"\"Extrai informa√ß√µes do projeto com truncamento.\"\"\"\n",
    "    campos = [\"nome_projeto\", \"elemento_tecnologico\", \"desafio_tecnologico\", \"metodologia\"]\n",
    "    info = {}\n",
    "    for campo in campos:\n",
    "        if campo in projeto_row.index:\n",
    "            info[campo] = truncar_texto(projeto_row[campo], max_chars)\n",
    "        else:\n",
    "            info[campo] = \"N√£o informado\"\n",
    "    return info\n",
    "\n",
    "# ============================================================\n",
    "# SYSTEM PROMPT SIMPLIFICADO E DIRETO\n",
    "# ============================================================\n",
    "\n",
    "SYSTEM_PROMPT_BASE = \"\"\"Voc√™ √© um especialista em avalia√ß√£o de projetos de P&D para enquadramento na Lei do Bem (Lei n¬∫ 11.196/2005).\n",
    "\n",
    "## CONTEXTO LEGAL E T√âCNICO\n",
    "\n",
    "A Lei do Bem oferece incentivos fiscais para empresas que investem em Pesquisa e Desenvolvimento tecnol√≥gico. Para um projeto ser eleg√≠vel, deve demonstrar:\n",
    "\n",
    "### 1. REQUISITOS FUNDAMENTAIS DE P&D (Manual de Frascati - OCDE)\n",
    "\n",
    "**Pesquisa B√°sica:** Trabalho experimental ou te√≥rico para adquirir novos conhecimentos sobre fen√¥menos e fatos observ√°veis, sem aplica√ß√£o ou uso particular em vista.\n",
    "\n",
    "**Pesquisa Aplicada:** Investiga√ß√£o original para adquirir novos conhecimentos, dirigida a objetivo pr√°tico espec√≠fico.\n",
    "\n",
    "**Desenvolvimento Experimental:** Trabalho sistem√°tico baseado em conhecimentos existentes, visando produ√ß√£o de novos materiais, produtos, dispositivos, processos, sistemas ou servi√ßos, ou melhoria substancial dos j√° existentes.\n",
    "\n",
    "### 2. CRIT√âRIOS DE ENQUADRAMENTO (5 requisitos obrigat√≥rios)\n",
    "\n",
    "1. **NOVIDADE:** O projeto deve buscar novo conhecimento ou aplica√ß√£o n√£o trivial\n",
    "2. **CRIATIVIDADE:** Deve haver conceitos e hip√≥teses originais, n√£o √≥bvios para profissional da √°rea\n",
    "3. **INCERTEZA TECNOL√ìGICA:** O resultado n√£o √© previs√≠vel com base no estado da arte\n",
    "4. **SISTEMATICIDADE:** Metodologia estruturada com objetivos, cronograma e recursos definidos\n",
    "5. **TRANSFERIBILIDADE:** Resultados devem ser reproduz√≠veis ou codific√°veis\n",
    "\n",
    "### 3. O QUE N√ÉO √â P&D (exclus√µes importantes)\n",
    "\n",
    "- Melhorias rotineiras ou incrementais de produtos/processos existentes\n",
    "- Customiza√ß√£o de software ou adapta√ß√£o para cliente espec√≠fico\n",
    "- Treinamento de pessoal ou implanta√ß√£o de sistemas comerciais\n",
    "- Atividades de engenharia de produ√ß√£o ou controle de qualidade rotineiro\n",
    "- Prospec√ß√£o, explora√ß√£o ou perfura√ß√£o de petr√≥leo/g√°s\n",
    "- Mudan√ßas est√©ticas ou de design sem avan√ßo tecnol√≥gico\n",
    "\n",
    "### 4. ELEMENTOS DE AN√ÅLISE PARA COMPARA√á√ÉO\n",
    "\n",
    "**ELEMENTO TECNOL√ìGICO:** Qual tecnologia, m√©todo ou sistema est√° sendo desenvolvido/aprimorado?\n",
    "- Hardware, software, processo produtivo, material, algoritmo, etc.\n",
    "\n",
    "**DESAFIO TECNOL√ìGICO:** Qual problema t√©cnico-cient√≠fico est√° sendo resolvido?\n",
    "- Qual a incerteza? O que n√£o se sabe fazer ou n√£o existe no mercado?\n",
    "\n",
    "**METODOLOGIA:** Como o problema ser√° resolvido?\n",
    "- Quais etapas de pesquisa? H√° experimenta√ß√£o? H√° valida√ß√£o?\n",
    "\n",
    "---\n",
    "\n",
    "## SUA TAREFA: COMPARAR DOIS PROJETOS\n",
    "\n",
    "Analise os dois projetos e determine se s√£o:\n",
    "- O mesmo projeto (poss√≠vel duplica√ß√£o/pl√°gio)\n",
    "- Projetos relacionados (mesmo tema, diferentes abordagens)\n",
    "- Projetos independentes (sem rela√ß√£o significativa)\n",
    "\n",
    "### CRIT√âRIOS DE CLASSIFICA√á√ÉO\n",
    "\n",
    "| Classifica√ß√£o | Defini√ß√£o | Indicadores |\n",
    "|---------------|-----------|-------------|\n",
    "| **ID√äNTICOS** | Textos praticamente iguais | Mesmo elemento, mesmo desafio, mesma metodologia. Diferen√ßas apenas cosm√©ticas (sin√¥nimos, ordem de palavras). Poss√≠vel duplica√ß√£o ou c√≥pia. |\n",
    "| **MUITO_SIMILARES** | Mesmo n√∫cleo de inova√ß√£o | Mesmo dom√≠nio tecnol√≥gico e problema central. Metodologias muito parecidas. Varia√ß√µes menores (ex: par√¢metros diferentes, escopo ligeiramente diferente). |\n",
    "| **SIMILARES** | Mesma √°rea tecnol√≥gica | Tecnologias relacionadas mas elementos distintos. Desafios no mesmo campo mas problemas diferentes. Metodologias com algumas etapas em comum. |\n",
    "| **DISTINTOS** | Sem rela√ß√£o significativa | Elementos tecnol√≥gicos claramente diferentes. Desafios sem conex√£o. Metodologias independentes. √Åreas ou dom√≠nios diferentes. |\n",
    "\n",
    "### REGRAS OBRIGAT√ìRIAS PARA \"mesmo_tratamento\"\n",
    "\n",
    "| Classifica√ß√£o | mesmo_tratamento | Justificativa |\n",
    "|---------------|------------------|---------------|\n",
    "| ID√äNTICOS | **true** (OBRIGAT√ìRIO) | Projetos id√™nticos DEVEM receber tratamento igual - √© logicamente imposs√≠vel trat√°-los diferente |\n",
    "| DISTINTOS | **false** (OBRIGAT√ìRIO) | Projetos diferentes DEVEM ser avaliados independentemente |\n",
    "| MUITO_SIMILARES | Depende da an√°lise | true: se compartilham mesmo n√∫cleo de inova√ß√£o; false: se cada um tem m√©rito pr√≥prio |\n",
    "| SIMILARES | Depende da an√°lise | true: se risco de serem mesmo projeto; false: se genuinamente distintos |\n",
    "\n",
    "### SINAIS DE ALERTA (alerta_duplicacao = true)\n",
    "\n",
    "- Textos com mais de 80% de sobreposi√ß√£o\n",
    "- Mesmas frases ou par√°grafos repetidos\n",
    "- Descri√ß√µes t√©cnicas id√™nticas com nomes de empresa diferentes\n",
    "- Projetos de empresas diferentes com elementos tecnol√≥gicos id√™nticos\n",
    "\n",
    "---\n",
    "\n",
    "## FORMATO DE RESPOSTA\n",
    "\n",
    "Responda EXCLUSIVAMENTE com o JSON abaixo, sem texto adicional antes ou depois:\n",
    "\n",
    "{\n",
    "    \"classificacao\": \"ID√äNTICOS|MUITO_SIMILARES|SIMILARES|DISTINTOS\",\n",
    "    \"mesmo_tratamento\": true|false,\n",
    "    \"justificativa\": \"Compara√ß√£o espec√≠fica dos elementos tecnol√≥gicos, desafios e metodologias dos dois projetos\",\n",
    "    \"alerta_duplicacao\": true|false\n",
    "}\n",
    "\n",
    "IMPORTANTE: \n",
    "- N√£o inclua explica√ß√µes fora do JSON\n",
    "- N√£o use markdown ou formata√ß√£o adicional\n",
    "- Justifique sempre comparando explicitamente os 3 elementos: tecnol√≥gico, desafio e metodologia\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# FUN√á√ÉO DE AN√ÅLISE OTIMIZADA\n",
    "# ============================================================\n",
    "\n",
    "def analisar_par_projetos(proj1_data, proj2_data, empresa1, empresa2, par_id, id_proj1, id_proj2):\n",
    "    \"\"\"Analisa um par de projetos com prompt otimizado.\"\"\"\n",
    "    \n",
    "    # Extrair info com truncamento\n",
    "    info1 = extrair_info_projeto(proj1_data, MAX_CHARS_CAMPO)\n",
    "    info2 = extrair_info_projeto(proj2_data, MAX_CHARS_CAMPO)\n",
    "    \n",
    "    # Buscar contexto LeANN (limitado)\n",
    "    texto_busca = f\"{info1.get('elemento_tecnologico', '')} {info2.get('elemento_tecnologico', '')}\"\n",
    "    contexto_leann = buscar_contexto_inovacao(leann_searcher, texto_busca, top_k=2, max_chars=MAX_CHARS_LEANN)\n",
    "    \n",
    "    # System prompt com contexto opcional\n",
    "    system_prompt = SYSTEM_PROMPT_BASE\n",
    "    if contexto_leann:\n",
    "        system_prompt += f\"\\n\\nCONTEXTO DE REFER√äNCIA:\\n{contexto_leann}\"\n",
    "    \n",
    "    # User prompt compacto\n",
    "    user_prompt = f\"\"\"PROJETO 1 ({empresa1[:30]}):\n",
    "- Nome: {info1['nome_projeto'][:100]}\n",
    "- Elemento: {info1['elemento_tecnologico']}\n",
    "- Desafio: {info1['desafio_tecnologico']}\n",
    "\n",
    "PROJETO 2 ({empresa2[:30]}):\n",
    "- Nome: {info2['nome_projeto'][:100]}\n",
    "- Elemento: {info2['elemento_tecnologico']}\n",
    "- Desafio: {info2['desafio_tecnologico']}\n",
    "\n",
    "Responda APENAS com o JSON especificado.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': user_prompt}\n",
    "            ],\n",
    "            options={\n",
    "                'temperature': 0.1,\n",
    "                'num_predict': NUM_PREDICT,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        llm_response = response['message']['content']\n",
    "        \n",
    "        # Limpeza robusta da resposta\n",
    "        llm_response = re.sub(r'<think>.*?</think>', '', llm_response, flags=re.DOTALL)\n",
    "        llm_response = llm_response.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        # Extrair JSON\n",
    "        json_match = re.search(r'\\{\\s*\"classificacao\".*?\\}', llm_response, re.DOTALL)\n",
    "        \n",
    "        if not json_match:\n",
    "            # Tentar encontrar qualquer JSON v√°lido\n",
    "            json_match = re.search(r'\\{[^{}]*\"classificacao\"[^{}]*\\}', llm_response, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            parsed = json.loads(json_str)\n",
    "            \n",
    "            # Normalizar classifica√ß√£o\n",
    "            classificacao = str(parsed.get('classificacao', '')).upper().strip()\n",
    "            classificacao = classificacao.replace('√ä', 'E').replace('√ç', 'I')\n",
    "            \n",
    "            # Aplicar regras obrigat√≥rias\n",
    "            if 'IDENT' in classificacao or classificacao == 'IDENTICOS':\n",
    "                parsed['classificacao'] = 'ID√äNTICOS'\n",
    "                parsed['mesmo_tratamento'] = True\n",
    "            elif 'DISTINT' in classificacao:\n",
    "                parsed['classificacao'] = 'DISTINTOS'\n",
    "                parsed['mesmo_tratamento'] = False\n",
    "            elif 'MUITO' in classificacao:\n",
    "                parsed['classificacao'] = 'MUITO_SIMILARES'\n",
    "            elif 'SIMILAR' in classificacao:\n",
    "                parsed['classificacao'] = 'SIMILARES'\n",
    "            \n",
    "            parsed['par_id'] = par_id\n",
    "            parsed['id_projeto_1'] = id_proj1\n",
    "            parsed['id_projeto_2'] = id_proj2\n",
    "            return parsed\n",
    "        else:\n",
    "            return {\n",
    "                \"erro\": \"JSON n√£o encontrado\",\n",
    "                \"par_id\": par_id,\n",
    "                \"id_projeto_1\": id_proj1,\n",
    "                \"id_projeto_2\": id_proj2,\n",
    "                \"resposta_raw\": llm_response[:200]\n",
    "            }\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"erro\": f\"JSON inv√°lido: {str(e)[:50]}\",\n",
    "            \"par_id\": par_id,\n",
    "            \"id_projeto_1\": id_proj1,\n",
    "            \"id_projeto_2\": id_proj2\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"erro\": f\"Exce√ß√£o: {str(e)[:50]}\",\n",
    "            \"par_id\": par_id,\n",
    "            \"id_projeto_1\": id_proj1,\n",
    "            \"id_projeto_2\": id_proj2\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESSAMENTO EM LOTES\n",
    "# ============================================================\n",
    "\n",
    "def processar_todos_pares():\n",
    "    \"\"\"Processa todos os pares de forma otimizada.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO AN√ÅLISE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Criar √≠ndice por id_projeto\n",
    "    proj_dict = eletr_2021_proc.set_index('id_projeto').to_dict('index')\n",
    "    \n",
    "    total_pares = len(eletr_2021_proc_similar)\n",
    "    print(f\"\\nüìä Total de pares: {total_pares}\")\n",
    "    \n",
    "    todos_resultados = []\n",
    "    erros = 0\n",
    "    sucessos = 0\n",
    "    \n",
    "    for idx, row in eletr_2021_proc_similar.iterrows():\n",
    "        id_proj1 = row['IdProjeto_1']\n",
    "        id_proj2 = row['IdProjeto_2']\n",
    "        \n",
    "        # Buscar dados dos projetos\n",
    "        if id_proj1 not in proj_dict or id_proj2 not in proj_dict:\n",
    "            print(f\"  ‚ö†Ô∏è Par {idx}: Projeto n√£o encontrado\")\n",
    "            continue\n",
    "        \n",
    "        proj1_data = pd.Series(proj_dict[id_proj1])\n",
    "        proj2_data = pd.Series(proj_dict[id_proj2])\n",
    "        \n",
    "        empresa1 = str(row.get('Empresa_1', 'Empresa 1'))\n",
    "        empresa2 = str(row.get('Empresa_2', 'Empresa 2'))\n",
    "        \n",
    "        # Analisar par\n",
    "        resultado = analisar_par_projetos(\n",
    "            proj1_data, proj2_data,\n",
    "            empresa1, empresa2,\n",
    "            idx, id_proj1, id_proj2\n",
    "        )\n",
    "        \n",
    "        # Adicionar info do par\n",
    "        resultado['nome_projeto_1'] = row['NomeProjeto_1']\n",
    "        resultado['nome_projeto_2'] = row['NomeProjeto_2']\n",
    "        resultado['similaridade_coseno'] = row['Similaridade_score']\n",
    "        resultado['mesma_empresa'] = row.get('Mesma_Empresa', False)\n",
    "        \n",
    "        todos_resultados.append(resultado)\n",
    "        \n",
    "        # Log\n",
    "        if 'erro' in resultado:\n",
    "            erros += 1\n",
    "            print(f\"  ‚ùå Par {id_proj1} x {id_proj2}: {resultado['erro'][:40]}\")\n",
    "        else:\n",
    "            sucessos += 1\n",
    "            classif = resultado.get('classificacao', 'N/A')\n",
    "            mesmo = \"‚úì\" if resultado.get('mesmo_tratamento', False) else \"‚úó\"\n",
    "            print(f\"  ‚úì Par {id_proj1} x {id_proj2}: {classif} | Mesmo: {mesmo}\")\n",
    "        \n",
    "        # Progresso a cada 20 pares\n",
    "        if (idx + 1) % 20 == 0:\n",
    "            print(f\"\\n  üìä Progresso: {idx+1}/{total_pares} | Sucessos: {sucessos} | Erros: {erros}\\n\")\n",
    "        \n",
    "        # Pausa para n√£o sobrecarregar\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return todos_resultados\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTAR\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nIniciando processamento...\")\n",
    "inicio = time.time()\n",
    "\n",
    "resultados = processar_todos_pares()\n",
    "\n",
    "tempo_total = time.time() - inicio\n",
    "\n",
    "# ============================================================\n",
    "# AN√ÅLISE DOS RESULTADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "total = len(df_resultados)\n",
    "com_erro = df_resultados['erro'].notna().sum() if 'erro' in df_resultados.columns else 0\n",
    "sem_erro = total - com_erro\n",
    "\n",
    "print(f\"\\nüìä Total: {total}\")\n",
    "print(f\"   ‚úì Sucesso: {sem_erro} ({sem_erro/total*100:.1f}%)\")\n",
    "print(f\"   ‚ùå Erros: {com_erro} ({com_erro/total*100:.1f}%)\")\n",
    "print(f\"   ‚è±Ô∏è Tempo: {tempo_total/60:.1f} min\")\n",
    "\n",
    "if 'classificacao' in df_resultados.columns:\n",
    "    df_validos = df_resultados[df_resultados['classificacao'].notna()]\n",
    "    print(f\"\\nüìã Distribui√ß√£o:\")\n",
    "    print(df_validos['classificacao'].value_counts())\n",
    "    \n",
    "    if 'mesmo_tratamento' in df_validos.columns:\n",
    "        mesmo = df_validos['mesmo_tratamento'].sum()\n",
    "        print(f\"\\nüìå Mesmo tratamento: {mesmo}/{len(df_validos)} ({mesmo/len(df_validos)*100:.1f}%)\")\n",
    "\n",
    "# Salvar\n",
    "arquivo = 'validacao_llm_pares_similares.csv'\n",
    "df_resultados.to_csv(arquivo, index=False, encoding='utf-8-sig', sep=';')\n",
    "print(f\"\\n‚úì Salvo em: {arquivo}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLU√çDO\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
