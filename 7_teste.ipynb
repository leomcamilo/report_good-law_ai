{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e901ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o dataset...\n",
      "‚úì Dados carregados\n",
      "\n",
      "================================================================================\n",
      "DADOS CARREGADOS COM SUCESSO\n",
      "================================================================================\n",
      "Total de registros: 74,502\n",
      "Total de colunas: 26\n",
      "\n",
      "================================================================================\n",
      "APLICANDO FILTRO CR√çTICO - REMOVENDO 2023\n",
      "================================================================================\n",
      "Registros por ano ANTES do filtro:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "2023    12814\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Removidos 12,814 registros de 2023 (17.2%)\n",
      "‚úì Dataset filtrado: 61,688 registros (2018-2022)\n",
      "\n",
      "Registros por ano AP√ìS filtro:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "Name: count, dtype: int64\n",
      "================================================================================\n",
      "‚úì Todas as colunas esperadas encontradas\n",
      "\n",
      "Empresas √∫nicas: 4,885\n",
      "Anos dispon√≠veis: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022)]\n",
      "\n",
      "Projetos multianuais: 46,238 (75.0%)\n",
      "\n",
      "Distribui√ß√£o por setor:\n",
      "setor_analise\n",
      "TIC                          16272\n",
      "Qu√≠mica e Farm√°cia           11708\n",
      "Mec√¢nica e Transporte         7990\n",
      "Agroind√∫stria e Alimentos     7499\n",
      "Transversal                   7090\n",
      "Eletroeletr√¥nica              6438\n",
      "Metalurgia e Minera√ß√£o        4656\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Projetos por ano:\n",
      "ano_referencia\n",
      "2018    10876\n",
      "2019    12168\n",
      "2020    11660\n",
      "2021    13198\n",
      "2022    13786\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "INFORMA√á√ïES DO DATASET\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 61688 entries, 0 to 61687\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   id_empresa_ano            61688 non-null  int64 \n",
      " 1   ano_referencia            61688 non-null  int64 \n",
      " 2   empresa_razao_social      61688 non-null  object\n",
      " 3   cnpj                      61688 non-null  int64 \n",
      " 4   atividade_economica       61688 non-null  object\n",
      " 5   codigo_atividade_ibge     61688 non-null  object\n",
      " 6   porte_empresa             61688 non-null  object\n",
      " 7   numero_projeto            61688 non-null  int64 \n",
      " 8   id_projeto                61688 non-null  int64 \n",
      " 9   nome_projeto              61686 non-null  object\n",
      " 10  descricao_projeto         61619 non-null  object\n",
      " 11  tipo_projeto              61688 non-null  object\n",
      " 12  area_projeto              50786 non-null  object\n",
      " 13  palavras_chave            43514 non-null  object\n",
      " 14  natureza                  61687 non-null  object\n",
      " 15  elemento_tecnologico      61687 non-null  object\n",
      " 16  desafio_tecnologico       61686 non-null  object\n",
      " 17  metodologia               61677 non-null  object\n",
      " 18  informacao_complementar   33805 non-null  object\n",
      " 19  resultado_economico       9716 non-null   object\n",
      " 20  resultado_inovacao        9768 non-null   object\n",
      " 21  descricao_rh              9134 non-null   object\n",
      " 22  descricao_materiais       5946 non-null   object\n",
      " 23  ciclo_maior_1_ano         61652 non-null  object\n",
      " 24  atividade_pdi_continuada  0 non-null      object\n",
      " 25  setor_analise             61653 non-null  object\n",
      " 26  projeto_multianual        61688 non-null  bool  \n",
      " 27  projeto_chave             61688 non-null  object\n",
      "dtypes: bool(1), int64(5), object(22)\n",
      "memory usage: 13.2+ MB\n",
      "None\n",
      "\n",
      "Primeiras 3 linhas do dataset:\n",
      "   id_empresa_ano  ano_referencia                empresa_razao_social  \\\n",
      "0               1            2018  ABBOTT LABORATORIOS DO BRASIL LTDA   \n",
      "1               1            2018  ABBOTT LABORATORIOS DO BRASIL LTDA   \n",
      "2               2            2018  ACHE LABORATORIOS FARMACEUTICOS SA   \n",
      "\n",
      "             cnpj                                atividade_economica  \\\n",
      "0  56998701000116  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "1  56998701000116  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "2  60659463000191  Fabrica√ß√£o de medicamentos alop√°ticos para uso...   \n",
      "\n",
      "  codigo_atividade_ibge porte_empresa  numero_projeto  id_projeto  \\\n",
      "0          C.21.21-1/01        Demais               1        7911   \n",
      "1          C.21.21-1/01        Demais               2        7912   \n",
      "2          C.21.21-1/01        Demais               1        5796   \n",
      "\n",
      "                                        nome_projeto  ...  \\\n",
      "0  Desenvolvimento de uma nova linha de medicamen...  ...   \n",
      "1  Melhorias em produtos farmac√™uticos e novas me...  ...   \n",
      "2  Estudos, s√≠nteses, descoberta e aplica√ß√µes de ...  ...   \n",
      "\n",
      "  informacao_complementar resultado_economico resultado_inovacao descricao_rh  \\\n",
      "0                     NaN                 NaN                NaN          NaN   \n",
      "1                     NaN                 NaN                NaN          NaN   \n",
      "2                     NaN                 NaN                NaN          NaN   \n",
      "\n",
      "  descricao_materiais ciclo_maior_1_ano atividade_pdi_continuada  \\\n",
      "0                 NaN               Sim                      NaN   \n",
      "1                 NaN               Sim                      NaN   \n",
      "2                 NaN               Sim                      NaN   \n",
      "\n",
      "        setor_analise projeto_multianual  \\\n",
      "0  Qu√≠mica e Farm√°cia               True   \n",
      "1  Qu√≠mica e Farm√°cia               True   \n",
      "2  Qu√≠mica e Farm√°cia               True   \n",
      "\n",
      "                                       projeto_chave  \n",
      "0  56998701000116_Desenvolvimento de uma nova lin...  \n",
      "1  56998701000116_Melhorias em produtos farmac√™ut...  \n",
      "2  60659463000191_Estudos, s√≠nteses, descoberta e...  \n",
      "\n",
      "[3 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tentar diferentes abordagens para carregar o CSV problem√°tico\n",
    "print(\"Tentando carregar o dataset...\")\n",
    "\n",
    "# M√©todo 1: Tentar com error_bad_lines para pular linhas problem√°ticas\n",
    "try:\n",
    "    df = pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv', \n",
    "                     encoding='UTF-8', \n",
    "                     low_memory=False,\n",
    "                     sep=';',  # Garantir que est√° usando v√≠rgula\n",
    "                     quotechar='\"')  # Tratar aspas\n",
    "    print(\"‚úì Dados carregados\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no m√©todo 1: {e}\")\n",
    "    \n",
    "    # M√©todo 2: Ler linha por linha para identificar o problema\n",
    "    try:\n",
    "        # Primeiro, descobrir quantas colunas deveria ter\n",
    "        with open('csv_longo/projetos_resultados_pessoas_valores.csv', 'r', encoding='latin-1') as f:\n",
    "            header = f.readline()\n",
    "            n_cols = len(header.split(','))\n",
    "            print(f\"N√∫mero esperado de colunas: {n_cols}\")\n",
    "        \n",
    "        # Carregar pulando linhas ruins\n",
    "        df = pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv',\n",
    "                        encoding='latin-1',\n",
    "                        low_memory=False,\n",
    "                        on_bad_lines='warn',\n",
    "                        engine='python',\n",
    "                        sep=',',\n",
    "                        quotechar='\"',\n",
    "                        escapechar='\\\\')\n",
    "        print(\"‚úì Dados carregados com engine='python'\")\n",
    "    except:\n",
    "        # M√©todo 3: √öltima tentativa - ler em chunks\n",
    "        chunks = []\n",
    "        chunk_size = 10000\n",
    "        problematic_lines = []\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv('csv_longo/projetos_resultados_pessoas_valores.csv',\n",
    "                                             encoding='latin-1',\n",
    "                                             low_memory=False,\n",
    "                                             on_bad_lines='skip',\n",
    "                                             chunksize=chunk_size)):\n",
    "            chunks.append(chunk)\n",
    "            print(f\"  Chunk {i+1} carregado ({len(chunk)} linhas)\")\n",
    "            \n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        print(\"‚úì Dados carregados em chunks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DADOS CARREGADOS COM SUCESSO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total de registros: {len(df):,}\")\n",
    "print(f\"Total de colunas: {df.shape[1]}\")\n",
    "\n",
    "# ============================================================\n",
    "# FILTRO CR√çTICO: REMOVER DADOS DE 2023 (DADOS INCOMPLETOS)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APLICANDO FILTRO CR√çTICO - REMOVENDO 2023\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar distribui√ß√£o antes do filtro\n",
    "if 'ano_referencia' in df.columns:\n",
    "    print(f\"Registros por ano ANTES do filtro:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "    \n",
    "    # Contagem antes\n",
    "    total_antes = len(df)\n",
    "    registros_2023 = (df['ano_referencia'] == 2023).sum()\n",
    "    \n",
    "    # APLICAR FILTRO - REMOVER 2023\n",
    "    df = df[df['ano_referencia'] != 2023].copy()\n",
    "    \n",
    "    print(f\"\\n‚úì Removidos {registros_2023:,} registros de 2023 ({registros_2023/total_antes*100:.1f}%)\")\n",
    "    print(f\"‚úì Dataset filtrado: {len(df):,} registros (2018-2022)\")\n",
    "    \n",
    "    print(f\"\\nRegistros por ano AP√ìS filtro:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Coluna 'ano_referencia' n√£o encontrada - verificar estrutura dos dados\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar colunas esperadas\n",
    "colunas_esperadas = ['id_projeto', 'ano_referencia', 'empresa_razao_social', 'cnpj', \n",
    "                     'nome_projeto', 'descricao_projeto', 'tipo_projeto', 'natureza',\n",
    "                     'elemento_tecnologico', 'desafio_tecnologico', 'metodologia',\n",
    "                     'setor_analise', 'ciclo_maior_1_ano']\n",
    "\n",
    "colunas_faltando = [col for col in colunas_esperadas if col not in df.columns]\n",
    "if colunas_faltando:\n",
    "    print(f\"\\n‚ö†Ô∏è Colunas faltando: {colunas_faltando}\")\n",
    "    print(\"Colunas dispon√≠veis:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:3d}. {col}\")\n",
    "else:\n",
    "    print(\"‚úì Todas as colunas esperadas encontradas\")\n",
    "\n",
    "# Continuar com a an√°lise se temos as colunas principais\n",
    "if all(col in df.columns for col in ['cnpj', 'ano_referencia', 'nome_projeto']):\n",
    "    print(f\"\\nEmpresas √∫nicas: {df['cnpj'].nunique():,}\")\n",
    "    print(f\"Anos dispon√≠veis: {sorted(df['ano_referencia'].dropna().unique())}\")\n",
    "    \n",
    "    # An√°lise de projetos multianuais\n",
    "    if 'ciclo_maior_1_ano' in df.columns:\n",
    "        df['projeto_multianual'] = df['ciclo_maior_1_ano'] == 'Sim'\n",
    "        print(f\"\\nProjetos multianuais: {df['projeto_multianual'].sum():,} ({df['projeto_multianual'].mean()*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Coluna 'ciclo_maior_1_ano' n√£o encontrada\")\n",
    "    \n",
    "    # Criar identificador √∫nico para rastrear projetos entre anos\n",
    "    df['projeto_chave'] = df['cnpj'].astype(str) + '_' + df['nome_projeto'].fillna('').astype(str).str[:50]\n",
    "    \n",
    "    # Distribui√ß√£o por setor\n",
    "    if 'setor_analise' in df.columns:\n",
    "        print(\"\\nDistribui√ß√£o por setor:\")\n",
    "        print(df['setor_analise'].value_counts())\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Coluna 'setor_analise' n√£o encontrada\")\n",
    "    \n",
    "    # Verificar anos com dados\n",
    "    print(\"\\nProjetos por ano:\")\n",
    "    print(df['ano_referencia'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n‚ùå Colunas essenciais n√£o encontradas. Verifique o arquivo CSV.\")\n",
    "\n",
    "# Mostrar informa√ß√µes sobre o dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INFORMA√á√ïES DO DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(df.info())\n",
    "\n",
    "# Verificar primeiras linhas\n",
    "print(\"\\nPrimeiras 3 linhas do dataset:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fcb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 11:07:04.020789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISE DE SIMILARIDADE COM GRANITE IBM - THRESHOLD 0.85\n",
      "================================================================================\n",
      "\n",
      "Filtrando dados de Eletroeletr√¥nica - 2021 - Processo...\n",
      "‚úì Projetos filtrados: 366\n",
      "\n",
      "================================================================================\n",
      "PREPARA√á√ÉO DOS DADOS\n",
      "================================================================================\n",
      "\n",
      "Estat√≠sticas dos textos:\n",
      "  - Total de projetos: 366\n",
      "  - Comprimento m√©dio: 8058 caracteres\n",
      "  - Comprimento m√≠nimo: 1077 caracteres\n",
      "  - Comprimento m√°ximo: 16166 caracteres\n",
      "\n",
      "================================================================================\n",
      "GERANDO EMBEDDINGS COM GRANITE IBM\n",
      "================================================================================\n",
      "Carregando modelo ibm-granite/granite-embedding-278m-multilingual...\n",
      "‚úì Modelo Granite carregado com sucesso\n",
      "\n",
      "Gerando embeddings para 366 projetos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e9e35498cc494f8e5894ff497ce89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embeddings gerados: shape (366, 768)\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO SIMILARIDADES\n",
      "================================================================================\n",
      "Calculando matriz de similaridade...\n",
      "\n",
      "‚úì Matriz calculada: (366, 366)\n",
      "  - Total de compara√ß√µes √∫nicas: 66,795\n",
      "\n",
      "Estat√≠sticas de similaridade:\n",
      "  - M√©dia: 0.6096\n",
      "  - Desvio padr√£o: 0.0578\n",
      "  - M√≠nima: 0.4090\n",
      "  - M√°xima: 1.0000\n",
      "  - Mediana: 0.6069\n",
      "\n",
      "Percentis:\n",
      "  - 75%: 0.6459\n",
      "  - 80%: 0.6556\n",
      "  - 85%: 0.6678\n",
      "  - 90%: 0.6831\n",
      "  - 95%: 0.7071\n",
      "  - 99%: 0.7563\n",
      "\n",
      "================================================================================\n",
      "IDENTIFICANDO PARES SIMILARES (THRESHOLD >= 0.85)\n",
      "================================================================================\n",
      "Procurando pares com similaridade >= 0.85...\n",
      "\n",
      "‚úì Pares encontrados: 70\n",
      "\n",
      "Estat√≠sticas dos pares similares:\n",
      "  - Similaridade m√°xima: 1.0000\n",
      "  - Similaridade m√©dia: 0.9478\n",
      "  - Similaridade m√≠nima: 0.8500\n",
      "\n",
      "Distribui√ß√£o por faixas:\n",
      "  - [0.98, 1.00): 33 pares (47.1%)\n",
      "  - [0.95, 0.98): 10 pares (14.3%)\n",
      "  - [0.90, 0.95): 8 pares (11.4%)\n",
      "  - [0.85, 0.90): 19 pares (27.1%)\n",
      "\n",
      "Top 10 pares mais similares:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68931] Torre M√≥vel - Desenvolvimento de Torre de Emerg√™nc...\n",
      "  Projeto 2: [68967] Torre M√≥vel - Desenvolvimento de Torre de Emerg√™nc...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68304] Desenvolvimento experimental de estrat√©gias para c...\n",
      "  Projeto 2: [68315] Desenvolvimento experimental de estrat√©gias para c...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68305] Desenvolvimento de solu√ß√µes para a eletromobilidad...\n",
      "  Projeto 2: [68316] Desenvolvimento de solu√ß√µes para a eletromobilidad...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68824] Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, ...\n",
      "  Projeto 2: [68828] Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, ...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [62849] Desenvolvimento experimental de solu√ß√µes tecnol√≥gi...\n",
      "  Projeto 2: [62887] Desenvolvimento experimental de solu√ß√µes tecnol√≥gi...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [60401] Desenvolvimento experimental de solu√ß√µes para apri...\n",
      "  Projeto 2: [60905] Desenvolvimento experimental de solu√ß√µes para apri...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [63136] Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "  Projeto 2: [63366] Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68310] Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnol...\n",
      "  Projeto 2: [68319] Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnol...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68927] Limpeza de Isoladores - Sistema inteligente de pla...\n",
      "  Projeto 2: [68963] Limpeza de Isoladores - Sistema inteligente de pla...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "Similaridade: 1.0000\n",
      "  Projeto 1: [68929] Manuten√ß√£o preditiva - Sistema inteligente de manu...\n",
      "  Projeto 2: [68965] Manuten√ß√£o preditiva - Sistema inteligente de manu...\n",
      "  Tipo: EMPRESAS DIFERENTES\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE POR TIPO DE PAR\n",
      "================================================================================\n",
      "  - Pares da mesma empresa: 11 (15.7%)\n",
      "  - Pares entre empresas diferentes: 59 (84.3%)\n",
      "\n",
      "Empresas com mais projetos similares:\n",
      "  - ITUMBIARA TRANSMISSORA DE ENERGIA S/A: 11 apari√ß√µes em pares similares\n",
      "  - EXPANSION TRANSMISSAO DE ENERGIA ELETRICA S/A: 9 apari√ß√µes em pares similares\n",
      "  - SERRA DA MESA TRANSMISSORA DE ENERGIA S. A.: 9 apari√ß√µes em pares similares\n",
      "  - WEG EQUIPAMENTOS ELETRICOS S/A: 8 apari√ß√µes em pares similares\n",
      "  - SCHWEITZER ENGINEERING LABORATORIES COMERCIAL LTDA: 7 apari√ß√µes em pares similares\n",
      "\n",
      "================================================================================\n",
      "SALVANDO RESULTADOS\n",
      "================================================================================\n",
      "‚úì Dataset filtrado salvo: eletr_2021_proc.csv\n",
      "  - Total de projetos: 366\n",
      "  - Total de colunas: 28\n",
      "\n",
      "‚úì Pares similares salvos: eletr_2021_proc_similar.csv\n",
      "  - Total de pares: 70\n",
      "  - Colunas inclu√≠das: IdProjeto_1, NomeProjeto_1, IdProjeto_2, NomeProjeto_2, Similaridade_score, Empresa_1, Empresa_2, Mesma_Empresa, CNPJ_1, CNPJ_2\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE CONCLU√çDA COM SUCESSO\n",
      "================================================================================\n",
      "\n",
      "üìä RESUMO EXECUTIVO:\n",
      "  ‚Ä¢ Modelo utilizado: Granite IBM Multilingual\n",
      "  ‚Ä¢ Projetos analisados: 366\n",
      "  ‚Ä¢ Threshold aplicado: 0.85\n",
      "  ‚Ä¢ Pares similares identificados: 70\n",
      "  ‚Ä¢ Taxa de pares similares: 0.105%\n",
      "\n",
      "üìÅ Arquivos gerados:\n",
      "  1. eletr_2021_proc.csv - Base completa filtrada\n",
      "  2. eletr_2021_proc_similar.csv - Pares com similaridade >= 0.85\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHUNK 2: AN√ÅLISE DEFINITIVA COM GRANITE - THRESHOLD 0.85\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISE DE SIMILARIDADE COM GRANITE IBM - THRESHOLD 0.85\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar dados\n",
    "print(\"\\nFiltrando dados de Eletroeletr√¥nica - 2021 - Processo...\")\n",
    "filtro = (\n",
    "    (df['setor_analise'] == 'Eletroeletr√¥nica') & \n",
    "    (df['ano_referencia'] == 2021) & \n",
    "    (df['natureza'] == 'Processo')\n",
    ")\n",
    "\n",
    "eletr_2021_proc = df[filtro].copy()\n",
    "print(f\"‚úì Projetos filtrados: {len(eletr_2021_proc)}\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARA√á√ÉO DOS TEXTOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARA√á√ÉO DOS DADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Campos de texto principais\n",
    "campos_texto = ['nome_projeto', 'elemento_tecnologico', 'desafio_tecnologico', \n",
    "                'metodologia', 'descricao_projeto']\n",
    "\n",
    "# Limpar valores nulos\n",
    "for campo in campos_texto:\n",
    "    if campo in eletr_2021_proc.columns:\n",
    "        eletr_2021_proc[campo] = eletr_2021_proc[campo].fillna('').astype(str)\n",
    "\n",
    "# Criar texto completo sem truncamento\n",
    "def criar_texto_completo(row):\n",
    "    \"\"\"Concatena todos os campos dispon√≠veis\"\"\"\n",
    "    partes = []\n",
    "    for campo in campos_texto:\n",
    "        if campo in row and row[campo] and str(row[campo]).strip():\n",
    "            partes.append(str(row[campo]).strip())\n",
    "    return \" \".join(partes)\n",
    "\n",
    "eletr_2021_proc['texto_completo'] = eletr_2021_proc.apply(criar_texto_completo, axis=1)\n",
    "\n",
    "# Estat√≠sticas dos textos\n",
    "comprimentos = eletr_2021_proc['texto_completo'].str.len()\n",
    "print(f\"\\nEstat√≠sticas dos textos:\")\n",
    "print(f\"  - Total de projetos: {len(eletr_2021_proc)}\")\n",
    "print(f\"  - Comprimento m√©dio: {comprimentos.mean():.0f} caracteres\")\n",
    "print(f\"  - Comprimento m√≠nimo: {comprimentos.min():.0f} caracteres\")\n",
    "print(f\"  - Comprimento m√°ximo: {comprimentos.max():.0f} caracteres\")\n",
    "\n",
    "# Verificar e remover textos vazios\n",
    "textos_vazios = (comprimentos == 0).sum()\n",
    "if textos_vazios > 0:\n",
    "    print(f\"  ‚ö†Ô∏è Removendo {textos_vazios} projetos sem texto\")\n",
    "    eletr_2021_proc = eletr_2021_proc[comprimentos > 0].copy()\n",
    "\n",
    "# ============================================================\n",
    "# GERAR EMBEDDINGS COM GRANITE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO EMBEDDINGS COM GRANITE IBM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Carregar modelo Granite\n",
    "print(\"Carregando modelo ibm-granite/granite-embedding-278m-multilingual...\")\n",
    "try:\n",
    "    model = SentenceTransformer('ibm-granite/granite-embedding-278m-multilingual')\n",
    "    print(\"‚úì Modelo Granite carregado com sucesso\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Usando modelo alternativo multil√≠ngue...\")\n",
    "    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    print(\"‚úì Modelo alternativo carregado\")\n",
    "\n",
    "# Preparar textos\n",
    "textos = eletr_2021_proc['texto_completo'].tolist()\n",
    "ids_projetos = eletr_2021_proc['id_projeto'].tolist() if 'id_projeto' in eletr_2021_proc.columns else eletr_2021_proc.index.tolist()\n",
    "nomes_projetos = eletr_2021_proc['nome_projeto'].tolist()\n",
    "\n",
    "print(f\"\\nGerando embeddings para {len(textos)} projetos...\")\n",
    "\n",
    "# Gerar embeddings\n",
    "embeddings = model.encode(\n",
    "    textos,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Embeddings gerados: shape {embeddings.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# CALCULAR MATRIZ DE SIMILARIDADE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULANDO SIMILARIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular matriz de similaridade\n",
    "print(\"Calculando matriz de similaridade...\")\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "upper_triangle = np.triu(similarity_matrix, k=1)\n",
    "all_similarities = upper_triangle[upper_triangle > 0]\n",
    "\n",
    "print(f\"\\n‚úì Matriz calculada: {similarity_matrix.shape}\")\n",
    "print(f\"  - Total de compara√ß√µes √∫nicas: {len(all_similarities):,}\")\n",
    "print(f\"\\nEstat√≠sticas de similaridade:\")\n",
    "print(f\"  - M√©dia: {all_similarities.mean():.4f}\")\n",
    "print(f\"  - Desvio padr√£o: {all_similarities.std():.4f}\")\n",
    "print(f\"  - M√≠nima: {all_similarities.min():.4f}\")\n",
    "print(f\"  - M√°xima: {all_similarities.max():.4f}\")\n",
    "print(f\"  - Mediana: {np.median(all_similarities):.4f}\")\n",
    "\n",
    "# Percentis importantes\n",
    "percentis = [75, 80, 85, 90, 95, 99]\n",
    "print(f\"\\nPercentis:\")\n",
    "for p in percentis:\n",
    "    valor = np.percentile(all_similarities, p)\n",
    "    print(f\"  - {p}%: {valor:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# IDENTIFICAR PARES SIMILARES (>= 0.85)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IDENTIFICANDO PARES SIMILARES (THRESHOLD >= 0.85)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "threshold = 0.85\n",
    "pares_similares = []\n",
    "\n",
    "# Iterar sobre triangular superior para evitar duplicatas\n",
    "print(\"Procurando pares com similaridade >= 0.85...\")\n",
    "for i in range(len(ids_projetos)):\n",
    "    for j in range(i + 1, len(ids_projetos)):\n",
    "        similaridade = similarity_matrix[i, j]\n",
    "        \n",
    "        if similaridade >= threshold:\n",
    "            # Coletar informa√ß√µes adicionais se dispon√≠veis\n",
    "            registro = {\n",
    "                'IdProjeto_1': ids_projetos[i],\n",
    "                'NomeProjeto_1': nomes_projetos[i],\n",
    "                'IdProjeto_2': ids_projetos[j],\n",
    "                'NomeProjeto_2': nomes_projetos[j],\n",
    "                'Similaridade_score': float(similaridade)\n",
    "            }\n",
    "            \n",
    "            # Adicionar informa√ß√µes de empresa se dispon√≠veis\n",
    "            if 'empresa_razao_social' in eletr_2021_proc.columns:\n",
    "                registro['Empresa_1'] = eletr_2021_proc.iloc[i]['empresa_razao_social']\n",
    "                registro['Empresa_2'] = eletr_2021_proc.iloc[j]['empresa_razao_social']\n",
    "                registro['Mesma_Empresa'] = registro['Empresa_1'] == registro['Empresa_2']\n",
    "            \n",
    "            if 'cnpj' in eletr_2021_proc.columns:\n",
    "                registro['CNPJ_1'] = eletr_2021_proc.iloc[i]['cnpj']\n",
    "                registro['CNPJ_2'] = eletr_2021_proc.iloc[j]['cnpj']\n",
    "            \n",
    "            pares_similares.append(registro)\n",
    "\n",
    "# Criar DataFrame com pares similares\n",
    "eletr_2021_proc_similar = pd.DataFrame(pares_similares)\n",
    "\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    # Ordenar por similaridade\n",
    "    eletr_2021_proc_similar = eletr_2021_proc_similar.sort_values('Similaridade_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\n‚úì Pares encontrados: {len(eletr_2021_proc_similar)}\")\n",
    "    \n",
    "    # Estat√≠sticas dos pares\n",
    "    print(f\"\\nEstat√≠sticas dos pares similares:\")\n",
    "    print(f\"  - Similaridade m√°xima: {eletr_2021_proc_similar['Similaridade_score'].max():.4f}\")\n",
    "    print(f\"  - Similaridade m√©dia: {eletr_2021_proc_similar['Similaridade_score'].mean():.4f}\")\n",
    "    print(f\"  - Similaridade m√≠nima: {eletr_2021_proc_similar['Similaridade_score'].min():.4f}\")\n",
    "    \n",
    "    # An√°lise por faixas\n",
    "    print(f\"\\nDistribui√ß√£o por faixas:\")\n",
    "    faixas = [(0.98, 1.00), (0.95, 0.98), (0.90, 0.95), (0.85, 0.90)]\n",
    "    for min_val, max_val in faixas:\n",
    "        if max_val == 1.00:\n",
    "            count = (eletr_2021_proc_similar['Similaridade_score'] >= min_val).sum()\n",
    "        else:\n",
    "            count = ((eletr_2021_proc_similar['Similaridade_score'] >= min_val) & \n",
    "                    (eletr_2021_proc_similar['Similaridade_score'] < max_val)).sum()\n",
    "        pct = count / len(eletr_2021_proc_similar) * 100 if len(eletr_2021_proc_similar) > 0 else 0\n",
    "        print(f\"  - [{min_val:.2f}, {max_val:.2f}): {count} pares ({pct:.1f}%)\")\n",
    "    \n",
    "    # Top 10 pares mais similares\n",
    "    print(f\"\\nTop 10 pares mais similares:\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx, row in eletr_2021_proc_similar.head(10).iterrows():\n",
    "        print(f\"\\nSimilaridade: {row['Similaridade_score']:.4f}\")\n",
    "        print(f\"  Projeto 1: [{row['IdProjeto_1']}] {row['NomeProjeto_1'][:50]}...\")\n",
    "        print(f\"  Projeto 2: [{row['IdProjeto_2']}] {row['NomeProjeto_2'][:50]}...\")\n",
    "        if 'Mesma_Empresa' in row:\n",
    "            tipo = \"MESMA EMPRESA\" if row['Mesma_Empresa'] else \"EMPRESAS DIFERENTES\"\n",
    "            print(f\"  Tipo: {tipo}\")\n",
    "    \n",
    "    # An√°lise por empresa se dispon√≠vel\n",
    "    if 'Mesma_Empresa' in eletr_2021_proc_similar.columns:\n",
    "        mesma_empresa = eletr_2021_proc_similar['Mesma_Empresa'].sum()\n",
    "        diferentes = len(eletr_2021_proc_similar) - mesma_empresa\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"AN√ÅLISE POR TIPO DE PAR\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"  - Pares da mesma empresa: {mesma_empresa} ({mesma_empresa/len(eletr_2021_proc_similar)*100:.1f}%)\")\n",
    "        print(f\"  - Pares entre empresas diferentes: {diferentes} ({diferentes/len(eletr_2021_proc_similar)*100:.1f}%)\")\n",
    "        \n",
    "        # Empresas com mais pares similares\n",
    "        if 'Empresa_1' in eletr_2021_proc_similar.columns:\n",
    "            print(f\"\\nEmpresas com mais projetos similares:\")\n",
    "            todas_empresas = pd.concat([\n",
    "                eletr_2021_proc_similar['Empresa_1'],\n",
    "                eletr_2021_proc_similar['Empresa_2']\n",
    "            ])\n",
    "            top_empresas = todas_empresas.value_counts().head(5)\n",
    "            for empresa, count in top_empresas.items():\n",
    "                print(f\"  - {empresa[:50]}: {count} apari√ß√µes em pares similares\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Nenhum par encontrado com similaridade >= {threshold}\")\n",
    "\n",
    "# ============================================================\n",
    "# SALVAR RESULTADOS EM CSV\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SALVANDO RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Remover coluna tempor√°ria antes de salvar\n",
    "if 'texto_completo' in eletr_2021_proc.columns:\n",
    "    eletr_2021_proc_export = eletr_2021_proc.drop(columns=['texto_completo'])\n",
    "else:\n",
    "    eletr_2021_proc_export = eletr_2021_proc.copy()\n",
    "\n",
    "# Salvar dataset filtrado\n",
    "arquivo_projetos = 'eletr_2021_proc.csv'\n",
    "eletr_2021_proc_export.to_csv(arquivo_projetos, index=False, encoding='utf-8-sig', sep=';')\n",
    "print(f\"‚úì Dataset filtrado salvo: {arquivo_projetos}\")\n",
    "print(f\"  - Total de projetos: {len(eletr_2021_proc_export)}\")\n",
    "print(f\"  - Total de colunas: {eletr_2021_proc_export.shape[1]}\")\n",
    "\n",
    "# Salvar pares similares\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    # Selecionar colunas essenciais para o CSV\n",
    "    colunas_essenciais = ['IdProjeto_1', 'NomeProjeto_1', 'IdProjeto_2', 'NomeProjeto_2', 'Similaridade_score']\n",
    "    colunas_extras = ['Empresa_1', 'Empresa_2', 'Mesma_Empresa', 'CNPJ_1', 'CNPJ_2']\n",
    "    \n",
    "    # Adicionar colunas extras se existirem\n",
    "    colunas_export = colunas_essenciais + [col for col in colunas_extras if col in eletr_2021_proc_similar.columns]\n",
    "    eletr_2021_proc_similar_export = eletr_2021_proc_similar[colunas_export]\n",
    "    \n",
    "    arquivo_similares = 'eletr_2021_proc_similar.csv'\n",
    "    eletr_2021_proc_similar_export.to_csv(arquivo_similares, index=False, encoding='utf-8-sig', sep=';')\n",
    "    print(f\"\\n‚úì Pares similares salvos: {arquivo_similares}\")\n",
    "    print(f\"  - Total de pares: {len(eletr_2021_proc_similar_export)}\")\n",
    "    print(f\"  - Colunas inclu√≠das: {', '.join(colunas_export)}\")\n",
    "else:\n",
    "    # Criar arquivo vazio com estrutura b√°sica\n",
    "    df_vazio = pd.DataFrame(columns=['IdProjeto_1', 'NomeProjeto_1', 'IdProjeto_2', 'NomeProjeto_2', 'Similaridade_score'])\n",
    "    df_vazio.to_csv('eletr_2021_proc_similar.csv', index=False, encoding='utf-8-sig', sep=';')\n",
    "    print(f\"\\n‚úì Arquivo de pares similares criado (vazio - nenhum par acima do threshold)\")\n",
    "\n",
    "# ============================================================\n",
    "# RESUMO FINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE CONCLU√çDA COM SUCESSO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä RESUMO EXECUTIVO:\")\n",
    "print(f\"  ‚Ä¢ Modelo utilizado: Granite IBM Multilingual\")\n",
    "print(f\"  ‚Ä¢ Projetos analisados: {len(eletr_2021_proc)}\")\n",
    "print(f\"  ‚Ä¢ Threshold aplicado: {threshold}\")\n",
    "print(f\"  ‚Ä¢ Pares similares identificados: {len(eletr_2021_proc_similar)}\")\n",
    "\n",
    "if len(eletr_2021_proc_similar) > 0:\n",
    "    taxa = len(eletr_2021_proc_similar) / (len(eletr_2021_proc) * (len(eletr_2021_proc) - 1) / 2) * 100\n",
    "    print(f\"  ‚Ä¢ Taxa de pares similares: {taxa:.3f}%\")\n",
    "\n",
    "print(f\"\\nüìÅ Arquivos gerados:\")\n",
    "print(f\"  1. eletr_2021_proc.csv - Base completa filtrada\")\n",
    "print(f\"  2. eletr_2021_proc_similar.csv - Pares com similaridade >= 0.85\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d82d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALIDA√á√ÉO ASS√çNCRONA DE SIMILARIDADE COM LLM LOCAL (OLLAMA)\n",
      "================================================================================\n",
      "\n",
      "Carregando dados...\n",
      "‚úì Projetos carregados: 366\n",
      "‚úì Pares similares carregados: 70\n",
      "\n",
      "================================================================================\n",
      "CONFIGURA√á√ÉO DO OLLAMA\n",
      "================================================================================\n",
      "üì¶ Modelo configurado: qwen3:30b\n",
      "‚öôÔ∏è  Batch size: 5\n",
      "‚ö†Ô∏è Erro ao listar modelos: 'name'\n",
      "üí° Certifique-se que o Ollama est√° rodando: ollama serve\n",
      "\n",
      "================================================================================\n",
      "CRIT√âRIOS DE INOVA√á√ÉO - LEI DO BEM\n",
      "================================================================================\n",
      "\n",
      "CRIT√âRIOS DE AVALIA√á√ÉO DE INOVA√á√ÉO (Lei 11.196/2005):\n",
      "\n",
      "1. **Novidade ou Aperfei√ßoamento** - O projeto introduz algo novo ou melhora significativamente algo existente?\n",
      "2. **Risco Tecnol√≥gico** - Existe incerteza quanto √† viabilidade t√©cnica?\n",
      "3. **Incremento Tecnol√≥gico** - H√° avan√ßo no conhecimento ou capacita√ß√£o tecnol√≥gica?\n",
      "4. **Aplica√ß√£o Industrial** - O resultado pode ser aplicado em processos produtivos?\n",
      "5. **Esfor√ßo Tecnol√≥gico** - Demanda conhecimento t√©cnico-cient√≠fico especializado?\n",
      "\n",
      "CLASSIFICA√á√ÉO DE SIMILARIDADE:\n",
      "- ID√äNTICOS: Mesma solu√ß√£o t√©cnica, mesmo problema, mesma abordagem\n",
      "- MUITO SIMILARES: Problema similar, solu√ß√µes compar√°veis, mesmo n√≠vel de inova√ß√£o\n",
      "- SIMILARES: Mesma √°rea tecnol√≥gica, complexidade equivalente\n",
      "- DISTINTOS: Apesar de vocabul√°rio similar, s√£o projetos tecnicamente diferentes\n",
      "\n",
      "\n",
      "Iniciando processamento...\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISE DOS PARES\n",
      "================================================================================\n",
      "\n",
      "üìä Total de pares para analisar: 70\n",
      "‚öôÔ∏è  Processando em lotes de 5...\n",
      "================================================================================\n",
      "Processando lote 1/14 (pares 1-5)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 68931 e Id 68967: ID√äNTICOS\n",
      "  ‚úì Par Id 68304 e Id 68315: ID√äNTICOS\n",
      "  ‚úì Par Id 68305 e Id 68316: ID√äNTICOS\n",
      "  ‚úì Par Id 68824 e Id 68828: ID√äNTICOS\n",
      "  ‚úì Par Id 62849 e Id 62887: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 2/14 (pares 6-10)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 60401 e Id 60905: ID√äNTICOS\n",
      "  ‚úì Par Id 63136 e Id 63366: ID√äNTICOS\n",
      "  ‚úì Par Id 68310 e Id 68319: ID√äNTICOS\n",
      "  ‚úì Par Id 68927 e Id 68963: ID√äNTICOS\n",
      "  ‚úì Par Id 68929 e Id 68965: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 3/14 (pares 11-15)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 63100 e Id 63136: ID√äNTICOS\n",
      "  ‚úì Par Id 63106 e Id 63372: ID√äNTICOS\n",
      "  ‚úì Par Id 63100 e Id 63366: ID√äNTICOS\n",
      "  ‚úì Par Id 65783 e Id 65787: ID√äNTICOS\n",
      "  ‚úì Par Id 63106 e Id 63142: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 4/14 (pares 16-20)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 63142 e Id 63372: ID√äNTICOS\n",
      "  ‚úì Par Id 65776 e Id 65783: ID√äNTICOS\n",
      "  ‚úì Par Id 65776 e Id 65787: ID√äNTICOS\n",
      "  ‚úì Par Id 63103 e Id 63139: ID√äNTICOS\n",
      "  ‚úì Par Id 63147 e Id 65745: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 5/14 (pares 21-25)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 59741 e Id 60405: ID√äNTICOS\n",
      "  ‚úì Par Id 65895 e Id 66753: ID√äNTICOS\n",
      "  ‚úì Par Id 63145 e Id 65783: ID√äNTICOS\n",
      "  ‚úì Par Id 63145 e Id 65787: ID√äNTICOS\n",
      "  ‚úì Par Id 63145 e Id 65776: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 6/14 (pares 26-30)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 65779 e Id 65782: ID√äNTICOS\n",
      "  ‚úì Par Id 65775 e Id 65779: ID√äNTICOS\n",
      "  ‚úì Par Id 65775 e Id 65782: ID√äNTICOS\n",
      "  ‚úì Par Id 63147 e Id 65786: ID√äNTICOS\n",
      "  ‚úì Par Id 65745 e Id 65786: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 7/14 (pares 31-35)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 63144 e Id 65782: ID√äNTICOS\n",
      "  ‚úì Par Id 63144 e Id 65779: ID√äNTICOS\n",
      "  ‚úì Par Id 65774 e Id 65781: ID√äNTICOS\n",
      "  ‚úì Par Id 63144 e Id 65775: ID√äNTICOS\n",
      "  ‚úì Par Id 61128 e Id 61182: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 8/14 (pares 36-40)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 65774 e Id 65778: ID√äNTICOS\n",
      "  ‚úì Par Id 67232 e Id 67242: ID√äNTICOS\n",
      "  ‚úì Par Id 63143 e Id 65781: ID√äNTICOS\n",
      "  ‚úì Par Id 63143 e Id 65774: ID√äNTICOS\n",
      "  ‚úì Par Id 65778 e Id 65781: ID√äNTICOS\n",
      "================================================================================\n",
      "Processando lote 9/14 (pares 41-45)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 63143 e Id 65778: ID√äNTICOS\n",
      "  ‚úì Par Id 61137 e Id 62795: ID√äNTICOS\n",
      "  ‚úì Par Id 59225 e Id 59364: ID√äNTICOS\n",
      "  ‚úì Par Id 59905 e Id 59906: MUITO_SIMILARES\n",
      "  ‚úì Par Id 59164 e Id 59364: MUITO_SIMILARES\n",
      "================================================================================\n",
      "Processando lote 10/14 (pares 46-50)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 67229 e Id 67243: MUITO_SIMILARES\n",
      "  ‚úì Par Id 62147 e Id 62174: MUITO_SIMILARES\n",
      "  ‚úì Par Id 60650 e Id 62128: ID√äNTICOS\n",
      "  ‚úì Par Id 59164 e Id 59225: MUITO_SIMILARES\n",
      "  ‚úì Par Id 65598 e Id 65599: MUITO_SIMILARES\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìä PROGRESSO: 50/70 pares processados\n",
      "   ‚úì Sucessos: 50 (100.0%)\n",
      "   ‚ùå Erros: 0 (0.0%)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Processando lote 11/14 (pares 51-55)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 60600 e Id 62101: ID√äNTICOS\n",
      "  ‚úì Par Id 67228 e Id 67229: MUITO_SIMILARES\n",
      "  ‚úì Par Id 67285 e Id 67286: MUITO_SIMILARES\n",
      "  ‚úì Par Id 59089 e Id 67370: MUITO_SIMILARES\n",
      "  ‚úì Par Id 60646 e Id 60647: MUITO_SIMILARES\n",
      "================================================================================\n",
      "Processando lote 12/14 (pares 56-60)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 56244 e Id 67366: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56280 e Id 56364: MUITO_SIMILARES\n",
      "  ‚úì Par Id 62165 e Id 62167: MUITO_SIMILARES\n",
      "  ‚úì Par Id 59894 e Id 59895: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56274 e Id 67366: MUITO_SIMILARES\n",
      "================================================================================\n",
      "Processando lote 13/14 (pares 61-65)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 56244 e Id 56363: MUITO_SIMILARES\n",
      "  ‚úì Par Id 58467 e Id 59402: MUITO_SIMILARES\n",
      "  ‚úì Par Id 62123 e Id 62124: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56244 e Id 56364: MUITO_SIMILARES\n",
      "  ‚úì Par Id 60697 e Id 60800: MUITO_SIMILARES\n",
      "================================================================================\n",
      "Processando lote 14/14 (pares 66-70)...\n",
      "================================================================================\n",
      "  ‚úì Par Id 59876 e Id 59899: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56274 e Id 56364: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56363 e Id 67366: MUITO_SIMILARES\n",
      "  ‚úì Par Id 56363 e Id 56364: MUITO_SIMILARES\n",
      "  ‚úì Par Id 68467 e Id 68512: MUITO_SIMILARES\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìä PROGRESSO: 70/70 pares processados\n",
      "   ‚úì Sucessos: 70 (100.0%)\n",
      "   ‚ùå Erros: 0 (0.0%)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE DOS RESULTADOS DA VALIDA√á√ÉO\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAT√çSTICAS GERAIS:\n",
      "  Total processado: 70\n",
      "  Processamento bem-sucedido: 70 (100.0%)\n",
      "  Erros: 0 (0.0%)\n",
      "  Tempo total: 16.4 minutos\n",
      "  Tempo m√©dio por par: 14.08 segundos\n",
      "\n",
      "‚úì Resultados v√°lidos para an√°lise: 70\n",
      "\n",
      "================================================================================\n",
      "DISTRIBUI√á√ÉO DE CLASSIFICA√á√ïES\n",
      "================================================================================\n",
      "  ID√äNTICOS           :   45 ( 64.3%)\n",
      "  MUITO_SIMILARES     :   25 ( 35.7%)\n",
      "\n",
      "üìã Projetos que devem ter MESMO tratamento: 70/70 (100.0%)\n",
      "‚ö†Ô∏è  Alertas de poss√≠vel duplica√ß√£o: 46\n",
      "\n",
      "================================================================================\n",
      "TOP 10 PARES MAIS CR√çTICOS\n",
      "================================================================================\n",
      "\n",
      "1. Par: Id 68931 ‚Üî Id 68967\n",
      "   Projeto 1: Torre M√≥vel - Desenvolvimento de Torre de Emerg√™ncia M√≥vel t...\n",
      "   Projeto 2: Torre M√≥vel - Desenvolvimento de Torre de Emerg√™ncia M√≥vel t...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam nome, objetivo, elemento tecnol√≥gico, desafio tecnol√≥gico e metodologia ...\n",
      "\n",
      "2. Par: Id 68304 ‚Üî Id 68315\n",
      "   Projeto 1: Desenvolvimento experimental de estrat√©gias para controle de...\n",
      "   Projeto 2: Desenvolvimento experimental de estrat√©gias para controle de...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam o mesmo nome, objetivo, elemento tecnol√≥gico, desafio tecnol√≥gico, metod...\n",
      "\n",
      "3. Par: Id 68305 ‚Üî Id 68316\n",
      "   Projeto 1: Desenvolvimento de solu√ß√µes para a eletromobilidade nacional...\n",
      "   Projeto 2: Desenvolvimento de solu√ß√µes para a eletromobilidade nacional...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam nome, objetivo, elemento tecnol√≥gico, desafios tecnol√≥gicos, metodologia...\n",
      "\n",
      "4. Par: Id 68824 ‚Üî Id 68828\n",
      "   Projeto 1: Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, pesquisa e...\n",
      "   Projeto 2: Ind√∫stria 4.0: moderniza√ß√£o de planta industrial, pesquisa e...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam descri√ß√µes id√™nticas em todos os aspectos t√©cnicos, metodol√≥gicos e de d...\n",
      "\n",
      "5. Par: Id 62849 ‚Üî Id 62887\n",
      "   Projeto 1: Desenvolvimento experimental de solu√ß√µes tecnol√≥gicas para a...\n",
      "   Projeto 2: Desenvolvimento experimental de solu√ß√µes tecnol√≥gicas para a...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam o mesmo nome, objetivo, elemento tecnol√≥gico, desafio tecnol√≥gico, metod...\n",
      "\n",
      "6. Par: Id 60401 ‚Üî Id 60905\n",
      "   Projeto 1: Desenvolvimento experimental de solu√ß√µes para aprimoramento ...\n",
      "   Projeto 2: Desenvolvimento experimental de solu√ß√µes para aprimoramento ...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam o mesmo nome, objetivo, elemento tecnol√≥gico, desafio tecnol√≥gico, metod...\n",
      "\n",
      "7. Par: Id 63136 ‚Üî Id 63366\n",
      "   Projeto 1: Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "   Projeto 2: Solu√ß√£o em Mobilidade El√©trica Eficiente...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam descri√ß√µes id√™nticas em todos os elementos-chave: nome, elemento tecnol√≥...\n",
      "\n",
      "8. Par: Id 68310 ‚Üî Id 68319\n",
      "   Projeto 1: Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnologia da re...\n",
      "   Projeto 2: Repovoamento do bagre-sapo: Aplica√ß√£o da biotecnologia da re...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam nome, objetivo, elemento tecnol√≥gico, desafio tecnol√≥gico e metodologia ...\n",
      "\n",
      "9. Par: Id 68927 ‚Üî Id 68963\n",
      "   Projeto 1: Limpeza de Isoladores - Sistema inteligente de planejamento,...\n",
      "   Projeto 2: Limpeza de Isoladores - Sistema inteligente de planejamento,...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam descri√ß√µes id√™nticas em todos os elementos: nome, elemento tecnol√≥gico, ...\n",
      "\n",
      "10. Par: Id 68929 ‚Üî Id 68965\n",
      "   Projeto 1: Manuten√ß√£o preditiva - Sistema inteligente de manuten√ß√£o pre...\n",
      "   Projeto 2: Manuten√ß√£o preditiva - Sistema inteligente de manuten√ß√£o pre...\n",
      "   Classifica√ß√£o: ID√äNTICOS\n",
      "   Similaridade: 1.000\n",
      "   Justificativa: Os dois projetos apresentam exatamente os mesmos elementos tecnol√≥gicos, desafios tecnol√≥gicos, meto...\n",
      "\n",
      "================================================================================\n",
      "SALVANDO RESULTADOS\n",
      "================================================================================\n",
      "‚úì Resultados salvos em: validacao_llm_pares_similares.csv\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE CONCLU√çDA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHUNK 3: VALIDA√á√ÉO ASS√çNCRONA COM LLM LOCAL (OLLAMA)\n",
    "# VERS√ÉO COM PACOTE OLLAMA - PROCESSA TODOS OS PARES\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ollama\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDA√á√ÉO ASS√çNCRONA DE SIMILARIDADE COM LLM LOCAL (OLLAMA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Carregar os dados\n",
    "print(\"\\nCarregando dados...\")\n",
    "eletr_2021_proc = pd.read_csv('eletr_2021_proc.csv', sep=';', encoding='utf-8-sig')\n",
    "eletr_2021_proc_similar = pd.read_csv('eletr_2021_proc_similar.csv', sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úì Projetos carregados: {len(eletr_2021_proc)}\")\n",
    "print(f\"‚úì Pares similares carregados: {len(eletr_2021_proc_similar)}\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURA√á√ÉO DO OLLAMA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURA√á√ÉO DO OLLAMA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configura√ß√£o simplificada - usa pacote ollama diretamente\n",
    "MODEL = \"qwen3:30b\"  # Altere para o modelo que voc√™ tem dispon√≠vel\n",
    "# Modelos comuns: \"llama2\", \"mistral\", \"qwen3:30b\", \"qwen3:32b\", \"gemma:2b\"\n",
    "BATCH_SIZE = 5  # Processar 5 requisi√ß√µes simult√¢neas\n",
    "\n",
    "print(f\"üì¶ Modelo configurado: {MODEL}\")\n",
    "print(f\"‚öôÔ∏è  Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Verificar se o modelo est√° dispon√≠vel\n",
    "try:\n",
    "    modelos_disponiveis = [m['name'] for m in ollama.list()['models']]\n",
    "    print(f\"\\n‚úì Modelos dispon√≠veis no Ollama:\")\n",
    "    for modelo in modelos_disponiveis:\n",
    "        print(f\"  - {modelo}\")\n",
    "    \n",
    "    if MODEL not in modelos_disponiveis:\n",
    "        print(f\"\\n‚ö†Ô∏è ATEN√á√ÉO: Modelo '{MODEL}' n√£o encontrado!\")\n",
    "        print(f\"üí° Baixe o modelo com: ollama pull {MODEL}\")\n",
    "        print(f\"üí° Ou altere a vari√°vel MODEL para um dos modelos acima\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao listar modelos: {e}\")\n",
    "    print(\"üí° Certifique-se que o Ollama est√° rodando: ollama serve\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR CRIT√âRIOS DE AVALIA√á√ÉO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIT√âRIOS DE INOVA√á√ÉO - LEI DO BEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "criterios_avaliacao = \"\"\"\n",
    "CRIT√âRIOS DE AVALIA√á√ÉO DE INOVA√á√ÉO (Lei 11.196/2005):\n",
    "\n",
    "1. **Novidade ou Aperfei√ßoamento** - O projeto introduz algo novo ou melhora significativamente algo existente?\n",
    "2. **Risco Tecnol√≥gico** - Existe incerteza quanto √† viabilidade t√©cnica?\n",
    "3. **Incremento Tecnol√≥gico** - H√° avan√ßo no conhecimento ou capacita√ß√£o tecnol√≥gica?\n",
    "4. **Aplica√ß√£o Industrial** - O resultado pode ser aplicado em processos produtivos?\n",
    "5. **Esfor√ßo Tecnol√≥gico** - Demanda conhecimento t√©cnico-cient√≠fico especializado?\n",
    "\n",
    "CLASSIFICA√á√ÉO DE SIMILARIDADE:\n",
    "- ID√äNTICOS: Mesma solu√ß√£o t√©cnica, mesmo problema, mesma abordagem\n",
    "- MUITO SIMILARES: Problema similar, solu√ß√µes compar√°veis, mesmo n√≠vel de inova√ß√£o\n",
    "- SIMILARES: Mesma √°rea tecnol√≥gica, complexidade equivalente\n",
    "- DISTINTOS: Apesar de vocabul√°rio similar, s√£o projetos tecnicamente diferentes\n",
    "\"\"\"\n",
    "\n",
    "print(criterios_avaliacao)\n",
    "\n",
    "# ============================================================\n",
    "# FUN√á√ÉO PARA AN√ÅLISE VIA LLM (USANDO PACOTE OLLAMA)\n",
    "# ============================================================\n",
    "\n",
    "def analisar_par_projetos(projeto1_data, projeto2_data, empresa1, empresa2, par_id, id_proj1, id_proj2):\n",
    "    \"\"\"\n",
    "    Analisa um par de projetos usando o LLM local via pacote ollama\n",
    "    VERS√ÉO SIMPLIFICADA - Usa ollama.generate() diretamente\n",
    "    \"\"\"\n",
    "    \n",
    "    # Montar o prompt estruturado\n",
    "    prompt = f\"\"\"\n",
    "Voc√™ √© um especialista em avalia√ß√£o de projetos de P&D para a Lei do Bem (Lei 11.196/2005). \n",
    "Analise os dois projetos abaixo e determine se devem ser tratados com os mesmos crit√©rios de avalia√ß√£o.\n",
    "\n",
    "{criterios_avaliacao}\n",
    "\n",
    "**PROJETO 1** - Empresa: {empresa1}\n",
    "Nome: {projeto1_data['nome_projeto']}\n",
    "Elemento Tecnol√≥gico: {projeto1_data['elemento_tecnologico'][:1000]}\n",
    "Desafio Tecnol√≥gico: {projeto1_data['desafio_tecnologico'][:1000]}\n",
    "Metodologia: {projeto1_data['metodologia'][:800]}\n",
    "\n",
    "**PROJETO 2** - Empresa: {empresa2}\n",
    "Nome: {projeto2_data['nome_projeto']}\n",
    "Elemento Tecnol√≥gico: {projeto2_data['elemento_tecnologico'][:1000]}\n",
    "Desafio Tecnol√≥gico: {projeto2_data['desafio_tecnologico'][:1000]}\n",
    "Metodologia: {projeto2_data['metodologia'][:800]}\n",
    "\n",
    "RESPONDA APENAS EM FORMATO JSON PURO (sem markdown, sem ```):\n",
    "{{\n",
    "    \"classificacao\": \"ID√äNTICOS|MUITO_SIMILARES|SIMILARES|DISTINTOS\",\n",
    "    \"mesmo_tratamento\": true/false,\n",
    "    \"justificativa\": \"explica√ß√£o breve\",\n",
    "    \"nivel_inovacao_proj1\": 1-5,\n",
    "    \"nivel_inovacao_proj2\": 1-5,\n",
    "    \"risco_tecnologico_similar\": true/false,\n",
    "    \"area_tecnologica\": \"descri√ß√£o da √°rea\",\n",
    "    \"alerta_duplicacao\": true/false\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Usar ollama.generate() - m√©todo s√≠ncrono mais simples\n",
    "        response = ollama.generate(\n",
    "            model=MODEL,\n",
    "            prompt=prompt,\n",
    "            options={\n",
    "                'temperature': 0.1,\n",
    "                'num_predict': 500,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        llm_response = response['response']\n",
    "        \n",
    "        # Tentar extrair JSON da resposta\n",
    "        import re\n",
    "        \n",
    "        # Remover markdown se existir\n",
    "        llm_response = llm_response.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        # Procurar por JSON\n",
    "        json_match = re.search(r'\\{.*\\}', llm_response, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            parsed_json = json.loads(json_str)\n",
    "            parsed_json['par_id'] = par_id\n",
    "            parsed_json['id_projeto_1'] = id_proj1\n",
    "            parsed_json['id_projeto_2'] = id_proj2\n",
    "            return parsed_json\n",
    "        else:\n",
    "            return {\n",
    "                \"erro\": \"JSON n√£o encontrado na resposta do LLM\", \n",
    "                \"par_id\": par_id,\n",
    "                \"id_projeto_1\": id_proj1,\n",
    "                \"id_projeto_2\": id_proj2,\n",
    "                \"resposta_raw\": llm_response[:200]\n",
    "            }\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"erro\": f\"Erro ao decodificar JSON: {str(e)}\", \n",
    "            \"par_id\": par_id,\n",
    "            \"id_projeto_1\": id_proj1,\n",
    "            \"id_projeto_2\": id_proj2,\n",
    "            \"resposta_raw\": llm_response[:200] if 'llm_response' in locals() else \"N/A\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"erro\": f\"Exce√ß√£o: {str(e)}\", \n",
    "            \"par_id\": par_id,\n",
    "            \"id_projeto_1\": id_proj1,\n",
    "            \"id_projeto_2\": id_proj2\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# PROCESSAR LOTES DE PARES COM THREADING\n",
    "# ============================================================\n",
    "\n",
    "def processar_lote(lote_pares, eletr_2021_proc, executor):\n",
    "    \"\"\"\n",
    "    Processa um lote de pares usando ThreadPoolExecutor\n",
    "    \"\"\"\n",
    "    tarefas = []\n",
    "    \n",
    "    for idx, row in lote_pares.iterrows():\n",
    "        try:\n",
    "            # Buscar dados completos dos projetos\n",
    "            id_proj1 = row['IdProjeto_1']\n",
    "            id_proj2 = row['IdProjeto_2']\n",
    "            \n",
    "            if 'id_projeto' in eletr_2021_proc.index.names:\n",
    "                proj1_data = eletr_2021_proc.loc[id_proj1]\n",
    "                proj2_data = eletr_2021_proc.loc[id_proj2]\n",
    "            else:\n",
    "                proj1_data = eletr_2021_proc[eletr_2021_proc['nome_projeto'] == row['NomeProjeto_1']].iloc[0]\n",
    "                proj2_data = eletr_2021_proc[eletr_2021_proc['nome_projeto'] == row['NomeProjeto_2']].iloc[0]\n",
    "            \n",
    "            empresa1 = row.get('Empresa_1', 'Empresa 1')[:50] if 'Empresa_1' in row else 'Empresa 1'\n",
    "            empresa2 = row.get('Empresa_2', 'Empresa 2')[:50] if 'Empresa_2' in row else 'Empresa 2'\n",
    "            \n",
    "            # Criar tarefa para o executor\n",
    "            future = executor.submit(\n",
    "                analisar_par_projetos,\n",
    "                proj1_data, proj2_data, \n",
    "                empresa1, empresa2, idx, id_proj1, id_proj2\n",
    "            )\n",
    "            tarefas.append((idx, row, id_proj1, id_proj2, future))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao preparar par {idx}: {e}\")\n",
    "    \n",
    "    # Coletar resultados\n",
    "    resultados = []\n",
    "    for idx, row, id_proj1, id_proj2, future in tarefas:\n",
    "        resultado = future.result()\n",
    "        \n",
    "        # Adicionar informa√ß√µes do par\n",
    "        resultado.update({\n",
    "            'nome_projeto_1': row['NomeProjeto_1'],\n",
    "            'nome_projeto_2': row['NomeProjeto_2'],\n",
    "            'similaridade_coseno': row['Similaridade_score'],\n",
    "            'mesma_empresa': row.get('Mesma_Empresa', False)\n",
    "        })\n",
    "        resultados.append(resultado)\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def processar_todos_pares():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal para processar todos os pares em lotes\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO AN√ÅLISE DOS PARES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar √≠ndice para busca\n",
    "    if 'id_projeto' in eletr_2021_proc.columns:\n",
    "        eletr_2021_proc.set_index('id_projeto', inplace=True)\n",
    "    \n",
    "    # Processar todos os pares\n",
    "    pares_para_analisar = eletr_2021_proc_similar\n",
    "    total_pares = len(pares_para_analisar)\n",
    "    \n",
    "    print(f\"\\nüìä Total de pares para analisar: {total_pares}\")\n",
    "    print(f\"‚öôÔ∏è  Processando em lotes de {BATCH_SIZE}...\")\n",
    "    \n",
    "    # Dividir em lotes\n",
    "    n_lotes = (total_pares + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    todos_resultados = []\n",
    "    \n",
    "    # Usar ThreadPoolExecutor para paraleliza√ß√£o\n",
    "    with ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:\n",
    "        # Processar cada lote\n",
    "        for i in range(n_lotes):\n",
    "            inicio = i * BATCH_SIZE\n",
    "            fim = min(inicio + BATCH_SIZE, total_pares)\n",
    "            lote = pares_para_analisar.iloc[inicio:fim]\n",
    "            \n",
    "            print(\"=\"*80)\n",
    "            print(f\"Processando lote {i+1}/{n_lotes} (pares {inicio+1}-{fim})...\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Processar lote\n",
    "            resultados_lote = processar_lote(lote, eletr_2021_proc, executor)\n",
    "            todos_resultados.extend(resultados_lote)\n",
    "            \n",
    "            # Output detalhado com IDs dos projetos\n",
    "            for res in resultados_lote:\n",
    "                id1 = res.get('id_projeto_1', 'N/A')\n",
    "                id2 = res.get('id_projeto_2', 'N/A')\n",
    "                \n",
    "                if 'erro' not in res:\n",
    "                    classif = res.get('classificacao', 'N/A')\n",
    "                    print(f\"  ‚úì Par Id {id1} e Id {id2}: {classif}\")\n",
    "                else:\n",
    "                    erro = res.get('erro', 'Erro desconhecido')\n",
    "                    print(f\"  ‚ùå Par Id {id1} e Id {id2}: ERRO - {erro[:50]}\")\n",
    "            \n",
    "            # Estat√≠sticas parciais a cada 10 lotes\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == n_lotes:\n",
    "                processados = len(todos_resultados)\n",
    "                com_sucesso = sum(1 for r in todos_resultados if 'erro' not in r)\n",
    "                com_erro = processados - com_sucesso\n",
    "                \n",
    "                print(\"\\n\" + \"-\"*80)\n",
    "                print(f\"üìä PROGRESSO: {processados}/{total_pares} pares processados\")\n",
    "                print(f\"   ‚úì Sucessos: {com_sucesso} ({com_sucesso/processados*100:.1f}%)\")\n",
    "                print(f\"   ‚ùå Erros: {com_erro} ({com_erro/processados*100:.1f}%)\")\n",
    "                print(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            # Pequena pausa entre lotes\n",
    "            if i < n_lotes - 1:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return todos_resultados\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTAR AN√ÅLISE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nIniciando processamento...\")\n",
    "inicio_total = time.time()\n",
    "\n",
    "resultados_analise = processar_todos_pares()\n",
    "\n",
    "tempo_total = time.time() - inicio_total\n",
    "\n",
    "# ============================================================\n",
    "# AN√ÅLISE DOS RESULTADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE DOS RESULTADOS DA VALIDA√á√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if resultados_analise:\n",
    "    # Converter para DataFrame\n",
    "    df_resultados = pd.DataFrame(resultados_analise)\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    total_processado = len(df_resultados)\n",
    "    com_erro = (df_resultados['erro'].notna()).sum() if 'erro' in df_resultados.columns else 0\n",
    "    sem_erro = total_processado - com_erro\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS GERAIS:\")\n",
    "    print(f\"  Total processado: {total_processado}\")\n",
    "    print(f\"  Processamento bem-sucedido: {sem_erro} ({sem_erro/total_processado*100:.1f}%)\")\n",
    "    print(f\"  Erros: {com_erro} ({com_erro/total_processado*100:.1f}%)\")\n",
    "    print(f\"  Tempo total: {tempo_total/60:.1f} minutos\")\n",
    "    print(f\"  Tempo m√©dio por par: {tempo_total/total_processado:.2f} segundos\")\n",
    "    \n",
    "    # An√°lise se tivermos resultados v√°lidos\n",
    "    if 'classificacao' in df_resultados.columns:\n",
    "        # Remover linhas com erro\n",
    "        df_validos = df_resultados[~df_resultados['classificacao'].isna()]\n",
    "        \n",
    "        print(f\"\\n‚úì Resultados v√°lidos para an√°lise: {len(df_validos)}\")\n",
    "        \n",
    "        # Estat√≠sticas de classifica√ß√£o\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DISTRIBUI√á√ÉO DE CLASSIFICA√á√ïES\")\n",
    "        print(\"=\"*80)\n",
    "        classificacao_counts = df_validos['classificacao'].value_counts()\n",
    "        for classif, count in classificacao_counts.items():\n",
    "            print(f\"  {classif:20s}: {count:4d} ({count/len(df_validos)*100:5.1f}%)\")\n",
    "        \n",
    "        # An√°lise de tratamento similar\n",
    "        if 'mesmo_tratamento' in df_validos.columns:\n",
    "            mesmo_trat = df_validos['mesmo_tratamento'].sum()\n",
    "            print(f\"\\nüìã Projetos que devem ter MESMO tratamento: {mesmo_trat}/{len(df_validos)} ({mesmo_trat/len(df_validos)*100:.1f}%)\")\n",
    "        \n",
    "        # Alertas de duplica√ß√£o\n",
    "        if 'alerta_duplicacao' in df_validos.columns:\n",
    "            alertas = df_validos['alerta_duplicacao'].sum()\n",
    "            print(f\"‚ö†Ô∏è  Alertas de poss√≠vel duplica√ß√£o: {alertas}\")\n",
    "        \n",
    "        # Top 10 pares cr√≠ticos\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TOP 10 PARES MAIS CR√çTICOS\")\n",
    "        print(\"=\"*80)\n",
    "        criticos = df_validos[\n",
    "            (df_validos.get('classificacao', '') == 'ID√äNTICOS') | \n",
    "            (df_validos.get('alerta_duplicacao', False) == True)\n",
    "        ].sort_values('similaridade_coseno', ascending=False)\n",
    "        \n",
    "        for i, (_, row) in enumerate(criticos.head(10).iterrows(), 1):\n",
    "            print(f\"\\n{i}. Par: Id {row['id_projeto_1']} ‚Üî Id {row['id_projeto_2']}\")\n",
    "            print(f\"   Projeto 1: {row['nome_projeto_1'][:60]}...\")\n",
    "            print(f\"   Projeto 2: {row['nome_projeto_2'][:60]}...\")\n",
    "            print(f\"   Classifica√ß√£o: {row.get('classificacao', 'N/A')}\")\n",
    "            print(f\"   Similaridade: {row['similaridade_coseno']:.3f}\")\n",
    "            if 'justificativa' in row:\n",
    "                print(f\"   Justificativa: {row['justificativa'][:100]}...\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # SALVAR RESULTADOS\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SALVANDO RESULTADOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    arquivo_validacao = 'validacao_llm_pares_similares.csv'\n",
    "    df_resultados.to_csv(arquivo_validacao, index=False, encoding='utf-8-sig', sep=';')\n",
    "    print(f\"‚úì Resultados salvos em: {arquivo_validacao}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum resultado obtido.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE CONCLU√çDA\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
