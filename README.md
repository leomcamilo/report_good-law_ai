# AnÃ¡lise e ClusterizaÃ§Ã£o de Projetos da Lei do Bem

Este projeto extrai, processa e analisa dados de projetos da Lei do Bem. Ele opera em um pipeline de dois estÃ¡gios para primeiro consolidar os dados de um banco de dados e, em seguida, aplicar tÃ©cnicas de Machine Learning para agrupar projetos similares.

## ğŸ“‹ PrÃ©-requisitos

- Python 3.9+
- PostgreSQL rodando localmente na porta 5432
- Banco de dados `dbs_mctic2` configurado
- Credenciais: usuÃ¡rio `ia_budy`, senha `ia_budy`
- [uv](https://docs.astral.sh/uv/) - Gerenciador de pacotes Python moderno

## ğŸš€ InstalaÃ§Ã£o

### 1. **Instalar uv (se ainda nÃ£o tiver):**

```bash
# macOS / Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. **Configurar o projeto:**

```bash
# Clonar/navegar para o diretÃ³rio do projeto
cd /home/leomcamilo/projects/test_pgai

# Instalar dependÃªncias e criar ambiente virtual
# Isso instalarÃ¡ pandas, sqlalchemy, sentence-transformers, umap-learn, hdbscan, etc.
uv sync

# Ativar ambiente virtual
source .venv/bin/activate  # Linux/macOS
# ou
.venv\Scripts\activate     # Windows
```

## ğŸ—ï¸ Estrutura do Projeto

```
test_pgai/
â”œâ”€â”€ pyproject.toml          # ConfiguraÃ§Ã£o e dependÃªncias
â”œâ”€â”€ .venv/                  # Ambiente virtual (criado pelo uv)
â”œâ”€â”€ analise_projetos.py     # Etapa 1: ExtraÃ§Ã£o de dados do DB
â”œâ”€â”€ criar_resumo.py         # Etapa 2: ClusterizaÃ§Ã£o com ML
â”œâ”€â”€ tabelas_csv_xlsx/       # DiretÃ³rio para os dados extraÃ­dos
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ“Š Fluxo de Trabalho e Uso

O processo Ã© dividido em duas etapas principais, que devem ser executadas em ordem.

### Etapa 1: Extrair Dados do Banco de Dados

O script `analise_projetos.py` conecta ao PostgreSQL, executa uma consulta consolidada e salva os dados brutos em um arquivo CSV.

```bash
# Ativar ambiente (se nÃ£o estiver ativo)
source .venv/bin/activate

# Executar o script de extraÃ§Ã£o
python analise_projetos.py
```

Isso criarÃ¡ um arquivo CSV dentro da pasta `tabelas_csv_xlsx/`, que serÃ¡ usado na prÃ³xima etapa.

### Etapa 2: Clusterizar Projetos com Machine Learning

O script `criar_resumo.py` lÃª o arquivo CSV gerado, aplica um modelo de linguagem para entender o conteÃºdo dos projetos e os agrupa por similaridade.

```bash
# Executar o script de clusterizaÃ§Ã£o
python criar_resumo.py
```

## ğŸ¤– Pipeline de Machine Learning

A clusterizaÃ§Ã£o realizada pelo `criar_resumo.py` segue os seguintes passos:

1.  **CriaÃ§Ã£o de Embeddings**: Textos de cada projeto sÃ£o convertidos em vetores numÃ©ricos (embeddings) usando o modelo `neuralmind/bert-base-portuguese-cased`.
2.  **ReduÃ§Ã£o de Dimensionalidade**: O `UMAP` Ã© usado para reduzir a complexidade dos vetores, otimizando a performance do clustering.
3.  **ClusterizaÃ§Ã£o**: O `HDBSCAN` Ã© aplicado para agrupar os projetos em clusters com base na proximidade de seus vetores.

## ğŸ“ Arquivos de SaÃ­da

Ao final do processo, os seguintes arquivos serÃ£o gerados:

-   **Da Etapa 1:**
    -   `tabelas_csv_xlsx/projetos_lei_do_bem_2023_TODAS_AS_EMPRESAS.csv`: Dados brutos extraÃ­dos do banco de dados.
-   **Da Etapa 2:**
    -   `projetos_com_clusters.csv`: Arquivo final com uma coluna adicional `cluster` que identifica o grupo de cada projeto.
    -   `embeddings_reduced.npy`: Arquivo NumPy com os vetores de embeddings de dimensionalidade reduzida.

## ğŸ†˜ Troubleshooting

### Erro de ConexÃ£o com Banco
```
psycopg2.OperationalError: could not connect to server
```
**SoluÃ§Ã£o**: Verifique se o serviÃ§o do PostgreSQL estÃ¡ ativo e se as credenciais no script `analise_projetos.py` estÃ£o corretas.

### Erro de `ParserError` em `criar_resumo.py`
```
pandas.errors.ParserError: Error tokenizing data.
```
**SoluÃ§Ã£o**: Verifique se o separador no `pd.read_csv()` em `criar_resumo.py` (ex: `sep=';'`) corresponde ao separador usado para salvar o arquivo em `analise_projetos.py`.

### Problemas com `uv`

```bash
# Recriar ambiente virtual do zero
rm -rf .venv
uv sync

# Limpar cache do uv
uv clean
```

## ğŸ”„ Desenvolvimento

### Adicionando Novas DependÃªncias

```bash
# Ativar ambiente
source .venv/bin/activate

# Adicionar nova dependÃªncia
uv add matplotlib

# Sincronizar apÃ³s mudanÃ§as manuais no pyproject.toml
uv sync
```
