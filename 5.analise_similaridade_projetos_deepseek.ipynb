{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1594ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Arquivo carregado: 75348 registros encontrados\n",
      "ğŸ“‹ Colunas disponÃ­veis: 50\n",
      "ğŸ“„ Arquivo: csv_longo/projetos_lei_do_bem_JUSTIFICATIVAS_RESULTADOS_PESSOAS.csv\n",
      "âœ… Todas as colunas necessÃ¡rias encontradas\n",
      "âœ… Chunk 1 executado: Imports, configuraÃ§Ãµes e dados carregados\n",
      "ğŸ“ Colunas de identificaÃ§Ã£o: ['id_empresa_ano', 'empresa', 'ano_referencia']\n",
      "ğŸ” Colunas para anÃ¡lise: ['setor', 'natureza', 'tipo_pesquisa', 'projeto', 'projeto_resultados']\n",
      "ğŸ“Š Colunas de avaliaÃ§Ã£o: ['do_resultado_analise', 'p_resultado_analise']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1204575/2852269188.py:33: DtypeWarning: Columns (25,26,32,34,35,36,39,41,43,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 1: Estrutura Geral do Programa e Imports\n",
    "ConfiguraÃ§Ã£o inicial e carregamento do arquivo CSV principal\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('agrupamento_projetos.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Carregar arquivo CSV principal\n",
    "arquivo_dados = 'csv_longo/projetos_lei_do_bem_JUSTIFICATIVAS_RESULTADOS_PESSOAS.csv'\n",
    "df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n",
    "\n",
    "print(f\"ğŸ“Š Arquivo carregado: {len(df)} registros encontrados\")\n",
    "print(f\"ğŸ“‹ Colunas disponÃ­veis: {len(df.columns)}\")\n",
    "print(f\"ğŸ“„ Arquivo: {arquivo_dados}\")\n",
    "\n",
    "# Definir colunas baseadas na estrutura do CSV carregado\n",
    "colunas_identificacao = [\n",
    "    'id_empresa_ano', 'empresa', 'ano_referencia'\n",
    "]\n",
    "\n",
    "colunas_analise = [\n",
    "    'setor', 'natureza', 'tipo_pesquisa', 'projeto', 'projeto_resultados'\n",
    "]\n",
    "\n",
    "colunas_avaliacao = [\n",
    "    'do_resultado_analise', 'p_resultado_analise'\n",
    "]\n",
    "\n",
    "# ConfiguraÃ§Ãµes globais\n",
    "LIMITE_PROJETOS_POR_LOTE = 50\n",
    "TEMPO_PAUSA_ENTRE_REQUESTS = 2\n",
    "MAX_TENTATIVAS = 3\n",
    "\n",
    "# Verificar se as colunas necessÃ¡rias existem\n",
    "colunas_faltando = [col for col in colunas_analise if col not in df.columns]\n",
    "if colunas_faltando:\n",
    "    print(f\"âš ï¸ Colunas nÃ£o encontradas: {colunas_faltando}\")\n",
    "    print(f\"ğŸ“‹ Colunas disponÃ­veis no CSV: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"âœ… Todas as colunas necessÃ¡rias encontradas\")\n",
    "\n",
    "print(\"âœ… Chunk 1 executado: Imports, configuraÃ§Ãµes e dados carregados\")\n",
    "print(f\"ğŸ“ Colunas de identificaÃ§Ã£o: {colunas_identificacao}\")\n",
    "print(f\"ğŸ” Colunas para anÃ¡lise: {colunas_analise}\")\n",
    "print(f\"ğŸ“Š Colunas de avaliaÃ§Ã£o: {colunas_avaliacao}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c589c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:14:39,544 - INFO - ğŸ“Š Dados iniciais limpos: 74466 registros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Executando Chunk 2 ADAPTADO: PreparaÃ§Ã£o com LigaÃ§Ã£o AutomÃ¡tica de Projetos Multianuais\n",
      "ğŸ§ª MODO TESTE ATIVADO - Processando apenas categoria: 'QuÃ­mica e FarmÃ¡cia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:14:40,213 - INFO - ğŸ“Š Dados extraÃ­dos:\n",
      "2025-08-11 17:14:40,220 - INFO -    ğŸ“‹ CNPJs Ãºnicos: 5717\n",
      "2025-08-11 17:14:40,222 - INFO -    ğŸ¢ RazÃµes sociais Ãºnicas: 0\n",
      "2025-08-11 17:14:40,269 - INFO -    ğŸ“„ Projetos multianuais: 54529\n",
      "2025-08-11 17:14:40,284 - INFO - â„¹ï¸ Nenhum projeto multianual encontrado\n",
      "2025-08-11 17:14:40,380 - INFO - âœ… LigaÃ§Ã£o automÃ¡tica aplicada:\n",
      "2025-08-11 17:14:40,381 - INFO -    ğŸ”— Projetos ligados automaticamente: 0\n",
      "2025-08-11 17:14:40,382 - INFO -    ğŸ“Š Grupos multianuais criados: 0\n",
      "2025-08-11 17:14:40,548 - INFO - ğŸ§ª FILTRO TESTE aplicado:\n",
      "2025-08-11 17:14:40,550 - INFO -    ğŸ¯ Categoria selecionada: 'QuÃ­mica e FarmÃ¡cia'\n",
      "2025-08-11 17:14:40,550 - INFO -    ğŸ“Š CombinaÃ§Ãµes antes do filtro: 63\n",
      "2025-08-11 17:14:40,551 - INFO -    ğŸ“Š CombinaÃ§Ãµes apÃ³s filtro: 9\n",
      "2025-08-11 17:14:40,552 - INFO - ğŸ“‹ Resumo da preparaÃ§Ã£o:\n",
      "2025-08-11 17:14:40,552 - INFO -    ğŸ“Š Total de registros processados: 74466\n",
      "2025-08-11 17:14:40,554 - INFO -    ğŸ”— Registros multianuais (jÃ¡ ligados): 0\n",
      "2025-08-11 17:14:40,555 - INFO -    ğŸ¤– Registros para LLM analisar: 74466\n",
      "2025-08-11 17:14:40,555 - INFO -    ğŸ·ï¸ Categorias para LLM processar: 9\n",
      "2025-08-11 17:14:40,556 - INFO -    ğŸ“Š Maior categoria para LLM: 8172 projetos\n",
      "2025-08-11 17:14:40,557 - INFO -    ğŸ“Š MÃ©dia de projetos por categoria: 1182.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunk 2 adaptado executado:\n",
      "   ğŸ“Š Total processado: 74,466 registros\n",
      "   ğŸ”— Projetos multianuais ligados: 0\n",
      "   ğŸ¤– Projetos para LLM: 74,466\n",
      "   ğŸ·ï¸ Categorias para LLM: 9\n",
      "   ğŸ§ª MODO TESTE: Apenas categoria 'QuÃ­mica e FarmÃ¡cia'\n",
      "   ğŸ“Š Projetos a serem processados no teste: 14229\n",
      "   ğŸ“„ RelatÃ³rio salvo: None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 2: PreparaÃ§Ã£o dos Dados\n",
    "Carrega o CSV e prepara os dados para processamento\n",
    "\"\"\"\n",
    "\n",
    "def extrair_dados_empresa_projeto(df):\n",
    "    \"\"\"\n",
    "    Extrai CNPJ, RazÃ£o Social e Nome do Projeto das colunas concatenadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_temp = df.copy()\n",
    "        \n",
    "        # Extrair CNPJ da coluna 'empresa'\n",
    "        df_temp['cnpj_extraido'] = df_temp['empresa'].str.extract(r'CNPJ:\\s*([0-9/.]+)')\n",
    "        \n",
    "        # Extrair RazÃ£o Social da coluna 'empresa'\n",
    "        df_temp['razao_social_extraida'] = df_temp['empresa'].str.extract(r'RAZÃƒO SOCIAL:\\s*([^:]+?)(?:\\s+ATIVIDADE ECONOMICA|$)')\n",
    "        \n",
    "        # Extrair Nome do Projeto da coluna 'projeto'\n",
    "        df_temp['nome_projeto_extraido'] = df_temp['projeto'].str.extract(r'NOME:\\s*([^:]+?)(?:\\s+DESCRIÃ‡Ã‚O|$)')\n",
    "        \n",
    "        # Extrair indicador de ciclo multianual\n",
    "        df_temp['ciclo_multianual'] = df_temp['projeto_multianual'].str.extract(r'CICLO MAIOR QUE 1 ANO:\\s*([^:]+?)(?:\\s+ATIVIDADE PDI|$)')\n",
    "        \n",
    "        # Limpar espaÃ§os em branco\n",
    "        for col in ['cnpj_extraido', 'razao_social_extraida', 'nome_projeto_extraido', 'ciclo_multianual']:\n",
    "            if col in df_temp.columns:\n",
    "                df_temp[col] = df_temp[col].str.strip()\n",
    "        \n",
    "        logging.info(f\"ğŸ“Š Dados extraÃ­dos:\")\n",
    "        logging.info(f\"   ğŸ“‹ CNPJs Ãºnicos: {df_temp['cnpj_extraido'].nunique()}\")\n",
    "        logging.info(f\"   ğŸ¢ RazÃµes sociais Ãºnicas: {df_temp['razao_social_extraida'].nunique()}\")\n",
    "        logging.info(f\"   ğŸ“„ Projetos multianuais: {len(df_temp[df_temp['ciclo_multianual'] == 'Sim'])}\")\n",
    "        \n",
    "        return df_temp\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao extrair dados: {e}\")\n",
    "        return df\n",
    "\n",
    "def identificar_projetos_multianuais(df_temp):\n",
    "    \"\"\"\n",
    "    Identifica grupos de projetos multianuais que devem ser ligados automaticamente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrar apenas projetos multianuais vÃ¡lidos\n",
    "        projetos_multianuais = df_temp[\n",
    "            (df_temp['ciclo_multianual'] == 'Sim') &\n",
    "            (df_temp['cnpj_extraido'].notna()) &\n",
    "            (df_temp['razao_social_extraida'].notna()) &\n",
    "            (df_temp['nome_projeto_extraido'].notna())\n",
    "        ].copy()\n",
    "        \n",
    "        if len(projetos_multianuais) == 0:\n",
    "            logging.info(\"â„¹ï¸ Nenhum projeto multianual encontrado\")\n",
    "            return []\n",
    "        \n",
    "        # Agrupar por CNPJ + RazÃ£o Social + Nome do Projeto\n",
    "        grupos_multianuais = projetos_multianuais.groupby([\n",
    "            'cnpj_extraido', 'razao_social_extraida', 'nome_projeto_extraido'\n",
    "        ])\n",
    "        \n",
    "        grupos_identificados = []\n",
    "        grupo_id_multianual = 1\n",
    "        \n",
    "        for (cnpj, razao, nome_proj), grupo in grupos_multianuais:\n",
    "            if len(grupo) > 1:  # Apenas grupos com mÃºltiplos anos\n",
    "                anos_projeto = sorted(grupo['ano_referencia'].unique())\n",
    "                indices_projeto = grupo.index.tolist()\n",
    "                \n",
    "                grupo_info = {\n",
    "                    'grupo_id_multianual': f\"MULTI_{grupo_id_multianual:04d}\",\n",
    "                    'cnpj': cnpj,\n",
    "                    'razao_social': razao,\n",
    "                    'nome_projeto': nome_proj,\n",
    "                    'anos': anos_projeto,\n",
    "                    'indices_df': indices_projeto,\n",
    "                    'total_registros': len(grupo)\n",
    "                }\n",
    "                grupos_identificados.append(grupo_info)\n",
    "                grupo_id_multianual += 1\n",
    "        \n",
    "        logging.info(f\"ğŸ”— Projetos multianuais identificados:\")\n",
    "        logging.info(f\"   ğŸ“Š Grupos multianuais: {len(grupos_identificados)}\")\n",
    "        logging.info(f\"   ğŸ“‹ Total de registros multianuais: {sum(g['total_registros'] for g in grupos_identificados)}\")\n",
    "        \n",
    "        # Mostrar alguns exemplos\n",
    "        for i, grupo in enumerate(grupos_identificados[:3]):\n",
    "            logging.info(f\"   ğŸ“„ Exemplo {i+1}: {grupo['nome_projeto'][:50]}... ({len(grupo['anos'])} anos: {grupo['anos']})\")\n",
    "        \n",
    "        return grupos_identificados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao identificar projetos multianuais: {e}\")\n",
    "        return []\n",
    "\n",
    "def aplicar_ligacao_automatica(df_temp, grupos_multianuais):\n",
    "    \"\"\"\n",
    "    Aplica ligaÃ§Ã£o automÃ¡tica aos projetos multianuais identificados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_processado = df_temp.copy()\n",
    "        df_processado['grupo_multianual'] = None\n",
    "        df_processado['eh_multianual'] = False\n",
    "        df_processado['anos_grupo_multianual'] = None\n",
    "        \n",
    "        total_projetos_ligados = 0\n",
    "        \n",
    "        for grupo in grupos_multianuais:\n",
    "            grupo_id = grupo['grupo_id_multianual']\n",
    "            indices = grupo['indices_df']\n",
    "            anos_str = ', '.join(map(str, grupo['anos']))\n",
    "            \n",
    "            # Marcar todos os registros do grupo\n",
    "            df_processado.loc[indices, 'grupo_multianual'] = grupo_id\n",
    "            df_processado.loc[indices, 'eh_multianual'] = True\n",
    "            df_processado.loc[indices, 'anos_grupo_multianual'] = anos_str\n",
    "            \n",
    "            total_projetos_ligados += len(indices)\n",
    "        \n",
    "        logging.info(f\"âœ… LigaÃ§Ã£o automÃ¡tica aplicada:\")\n",
    "        logging.info(f\"   ğŸ”— Projetos ligados automaticamente: {total_projetos_ligados}\")\n",
    "        logging.info(f\"   ğŸ“Š Grupos multianuais criados: {len(grupos_multianuais)}\")\n",
    "        \n",
    "        return df_processado\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao aplicar ligaÃ§Ã£o automÃ¡tica: {e}\")\n",
    "        return df_temp\n",
    "\n",
    "def preparar_dados_com_multianual(df):\n",
    "    \"\"\"\n",
    "    Prepara dados identificando projetos multianuais e aplicando ligaÃ§Ã£o automÃ¡tica\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrar apenas registros com dados essenciais\n",
    "        df_clean = df.dropna(subset=['projeto', 'setor', 'natureza', 'tipo_pesquisa'])\n",
    "        df_clean = df_clean[df_clean['projeto'].str.len() > 50]\n",
    "        \n",
    "        logging.info(f\"ğŸ“Š Dados iniciais limpos: {len(df_clean)} registros\")\n",
    "        \n",
    "        # Extrair dados estruturados\n",
    "        df_temp = extrair_dados_empresa_projeto(df_clean)\n",
    "        \n",
    "        # Identificar projetos multianuais\n",
    "        grupos_multianuais = identificar_projetos_multianuais(df_temp)\n",
    "        \n",
    "        # Aplicar ligaÃ§Ã£o automÃ¡tica\n",
    "        df_processado = aplicar_ligacao_automatica(df_temp, grupos_multianuais)\n",
    "        \n",
    "        # Preparar para agrupamento por LLM apenas dos projetos NÃƒO multianuais\n",
    "        df_para_llm = df_processado[~df_processado['eh_multianual']].copy()\n",
    "        \n",
    "        # Obter combinaÃ§Ãµes Ãºnicas (setor + tipo_pesquisa + natureza) dos projetos para LLM\n",
    "        combinacoes = df_para_llm.groupby([\n",
    "            'setor', 'tipo_pesquisa', 'natureza'\n",
    "        ]).size().reset_index(name='count')\n",
    "        \n",
    "        # Filtrar combinaÃ§Ãµes com pelo menos 3 projetos\n",
    "        combinacoes_validas = combinacoes[combinacoes['count'] >= 3]\n",
    "        \n",
    "        # APLICAR FILTRO DE TESTE POR CATEGORIA (se ativo)\n",
    "        if CATEGORIA_TESTE_API and isinstance(CATEGORIA_TESTE_API, str):\n",
    "            combinacoes_original = len(combinacoes_validas)\n",
    "            combinacoes_validas = combinacoes_validas[\n",
    "                combinacoes_validas['setor'] == CATEGORIA_TESTE_API\n",
    "            ]\n",
    "            logging.info(f\"ğŸ§ª FILTRO TESTE aplicado:\")\n",
    "            logging.info(f\"   ğŸ¯ Categoria selecionada: '{CATEGORIA_TESTE_API}'\")\n",
    "            logging.info(f\"   ğŸ“Š CombinaÃ§Ãµes antes do filtro: {combinacoes_original}\")\n",
    "            logging.info(f\"   ğŸ“Š CombinaÃ§Ãµes apÃ³s filtro: {len(combinacoes_validas)}\")\n",
    "            \n",
    "            if len(combinacoes_validas) == 0:\n",
    "                logging.warning(f\"âš ï¸ Nenhuma combinaÃ§Ã£o encontrada para categoria '{CATEGORIA_TESTE_API}'\")\n",
    "                categorias_disponiveis = df_para_llm['setor'].unique()[:10]  # Primeiras 10\n",
    "                logging.info(f\"ğŸ“‹ Categorias disponÃ­veis (primeiras 10): {list(categorias_disponiveis)}\")\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ Resumo da preparaÃ§Ã£o:\")\n",
    "        logging.info(f\"   ğŸ“Š Total de registros processados: {len(df_processado)}\")\n",
    "        logging.info(f\"   ğŸ”— Registros multianuais (jÃ¡ ligados): {len(df_processado[df_processado['eh_multianual']])}\")\n",
    "        logging.info(f\"   ğŸ¤– Registros para LLM analisar: {len(df_para_llm)}\")\n",
    "        logging.info(f\"   ğŸ·ï¸ Categorias para LLM processar: {len(combinacoes_validas)}\")\n",
    "        \n",
    "        if len(combinacoes_validas) > 0:\n",
    "            logging.info(f\"   ğŸ“Š Maior categoria para LLM: {combinacoes['count'].max()} projetos\")\n",
    "            logging.info(f\"   ğŸ“Š MÃ©dia de projetos por categoria: {combinacoes['count'].mean():.1f}\")\n",
    "        \n",
    "        return df_processado, df_para_llm, combinacoes_validas, grupos_multianuais\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro na preparaÃ§Ã£o com multianual: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def salvar_relatorio_multianuais(grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    Salva relatÃ³rio detalhado dos projetos multianuais identificados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not grupos_multianuais:\n",
    "            return None\n",
    "        \n",
    "        # Criar DataFrame com informaÃ§Ãµes dos grupos\n",
    "        relatorio_data = []\n",
    "        for grupo in grupos_multianuais:\n",
    "            relatorio_data.append({\n",
    "                'grupo_id_multianual': grupo['grupo_id_multianual'],\n",
    "                'cnpj': grupo['cnpj'],\n",
    "                'razao_social': grupo['razao_social'],\n",
    "                'nome_projeto': grupo['nome_projeto'],\n",
    "                'anos_projeto': ', '.join(map(str, grupo['anos'])),\n",
    "                'total_anos': len(grupo['anos']),\n",
    "                'total_registros': grupo['total_registros']\n",
    "            })\n",
    "        \n",
    "        df_relatorio = pd.DataFrame(relatorio_data)\n",
    "        arquivo_relatorio = f'resultados_agrupamento/projetos_multianuais_identificados_{timestamp}.csv'\n",
    "        df_relatorio.to_csv(arquivo_relatorio, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"ğŸ“„ RelatÃ³rio de multianuais salvo: {arquivo_relatorio}\")\n",
    "        return arquivo_relatorio\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao salvar relatÃ³rio de multianuais: {e}\")\n",
    "        return None\n",
    "\n",
    "# ConfiguraÃ§Ã£o para teste limitado por categoria\n",
    "CATEGORIA_TESTE_API = \"QuÃ­mica e FarmÃ¡cia\"  # Mudar para False para processar todas as categorias\n",
    "# CATEGORIA_TESTE_API = False  # Descomente esta linha para processar tudo\n",
    "\n",
    "# Executar preparaÃ§Ã£o com identificaÃ§Ã£o de multianuais\n",
    "print(\"\\nğŸ”„ Executando Chunk 2 ADAPTADO: PreparaÃ§Ã£o com LigaÃ§Ã£o AutomÃ¡tica de Projetos Multianuais\")\n",
    "\n",
    "if CATEGORIA_TESTE_API:\n",
    "    print(f\"ğŸ§ª MODO TESTE ATIVADO - Processando apenas categoria: '{CATEGORIA_TESTE_API}'\")\n",
    "else:\n",
    "    print(\"ğŸŒ MODO COMPLETO - Processando todas as categorias\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Timestamp para controle\n",
    "    timestamp_preparacao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Processar dados com identificaÃ§Ã£o de multianuais\n",
    "    df_processado, df_para_llm, combinacoes_validas, grupos_multianuais = preparar_dados_com_multianual(df)\n",
    "    \n",
    "    if df_processado is not None:\n",
    "        # Salvar relatÃ³rio de multianuais\n",
    "        arquivo_relatorio = salvar_relatorio_multianuais(grupos_multianuais, timestamp_preparacao)\n",
    "        \n",
    "        print(f\"âœ… Chunk 2 adaptado executado:\")\n",
    "        print(f\"   ğŸ“Š Total processado: {len(df_processado):,} registros\")\n",
    "        print(f\"   ğŸ”— Projetos multianuais ligados: {len(df_processado[df_processado['eh_multianual']]):,}\")\n",
    "        print(f\"   ğŸ¤– Projetos para LLM: {len(df_para_llm):,}\")\n",
    "        print(f\"   ğŸ·ï¸ Categorias para LLM: {len(combinacoes_validas)}\")\n",
    "        \n",
    "        if CATEGORIA_TESTE_API:\n",
    "            print(f\"   ğŸ§ª MODO TESTE: Apenas categoria '{CATEGORIA_TESTE_API}'\")\n",
    "            if len(combinacoes_validas) > 0:\n",
    "                total_projetos_teste = combinacoes_validas['count'].sum()\n",
    "                print(f\"   ğŸ“Š Projetos a serem processados no teste: {total_projetos_teste}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ ATENÃ‡ÃƒO: Nenhuma combinaÃ§Ã£o para categoria '{CATEGORIA_TESTE_API}'\")\n",
    "        \n",
    "        print(f\"   ğŸ“„ RelatÃ³rio salvo: {arquivo_relatorio}\")\n",
    "        \n",
    "        # EstatÃ­sticas dos grupos multianuais\n",
    "        if grupos_multianuais:\n",
    "            total_grupos = len(grupos_multianuais)\n",
    "            maior_grupo = max(g['total_registros'] for g in grupos_multianuais)\n",
    "            print(f\"   ğŸ“ˆ Grupos multianuais: {total_grupos} (maior: {maior_grupo} registros)\")\n",
    "        \n",
    "        # Renomear variÃ¡veis para compatibilidade com chunks seguintes\n",
    "        df_clean = df_para_llm  # Para os chunks seguintes processarem apenas os nÃ£o-multianuais\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Chunk 2 adaptado falhou: NÃ£o foi possÃ­vel processar os dados\")\n",
    "else:\n",
    "    print(\"âŒ DataFrame 'df' nÃ£o encontrado. Execute Chunk 1 primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f03a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:15:01,953 - INFO - âœ… API Deepseek configurada com sucesso\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Executando Chunk 3: ConfiguraÃ§Ã£o da API Deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:15:02,528 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-11 17:15:05,273 - INFO - âœ… Teste de conexÃ£o com API bem-sucedido\n",
      "2025-08-11 17:15:05,274 - INFO - ğŸ“± Resposta do teste: OK...\n",
      "2025-08-11 17:15:05,275 - INFO - ğŸ’° Estimativa de custo:\n",
      "2025-08-11 17:15:05,276 - INFO -    ğŸ“Š Total de combinaÃ§Ãµes: 9\n",
      "2025-08-11 17:15:05,277 - INFO -    ğŸ“‹ Total de projetos: 14229\n",
      "2025-08-11 17:15:05,278 - INFO -    ğŸ”¤ Tokens estimados: 4,268,700\n",
      "2025-08-11 17:15:05,279 - INFO -    ğŸ’µ Custo estimado: $5.98 USD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunk 3 executado: API configurada e testada\n",
      "ğŸ’° Custo estimado: $5.98 USD\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 3: ConfiguraÃ§Ã£o da API Deepseek\n",
    "Configura a conexÃ£o com a API Deepseek usando LangChain\n",
    "\"\"\"\n",
    "\n",
    "def configurar_api_deepseek():\n",
    "    \"\"\"\n",
    "    Configura o cliente da API Deepseek\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obter chave da API\n",
    "        api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"A chave da API do DeepSeek nÃ£o estÃ¡ definida nas variÃ¡veis de ambiente.\")\n",
    "        \n",
    "        # Configurar o modelo\n",
    "        model = ChatOpenAI(\n",
    "            model=\"deepseek-chat\",\n",
    "            temperature=0.3,  # Baixa temperatura para resultados mais consistentes\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        \n",
    "        logging.info(\"âœ… API Deepseek configurada com sucesso\")\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao configurar API Deepseek: {e}\")\n",
    "        return None\n",
    "\n",
    "def testar_conexao_api(model):\n",
    "    \"\"\"\n",
    "    Testa a conexÃ£o com a API Deepseek\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar mensagem de teste simples\n",
    "        mensagens_teste = [\n",
    "            SystemMessage(content=\"VocÃª Ã© um assistente Ãºtil.\"),\n",
    "            HumanMessage(content=\"Responda apenas 'OK' se vocÃª conseguir me ouvir.\")\n",
    "        ]\n",
    "        \n",
    "        # Fazer chamada de teste\n",
    "        resposta = model.invoke(mensagens_teste)\n",
    "        \n",
    "        if resposta and resposta.content:\n",
    "            logging.info(\"âœ… Teste de conexÃ£o com API bem-sucedido\")\n",
    "            logging.info(f\"ğŸ“± Resposta do teste: {resposta.content[:50]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            logging.error(\"âŒ Resposta vazia da API\")\n",
    "            return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no teste de conexÃ£o: {e}\")\n",
    "        return False\n",
    "\n",
    "def estimar_custo_processamento(combinacoes_validas):\n",
    "    \"\"\"\n",
    "    Estima o custo aproximado do processamento\n",
    "    \"\"\"\n",
    "    if combinacoes_validas is None:\n",
    "        return\n",
    "    \n",
    "    total_combinacoes = len(combinacoes_validas)\n",
    "    total_projetos = combinacoes_validas['count'].sum()\n",
    "    \n",
    "    # Estimativas (valores aproximados para Deepseek)\n",
    "    tokens_por_projeto = 300  # MÃ©dia de tokens por projeto\n",
    "    tokens_totais = total_projetos * tokens_por_projeto\n",
    "    custo_por_1k_tokens = 0.0014  # USD por 1k tokens (aproximado Deepseek)\n",
    "    custo_estimado = (tokens_totais / 1000) * custo_por_1k_tokens\n",
    "    \n",
    "    logging.info(f\"ğŸ’° Estimativa de custo:\")\n",
    "    logging.info(f\"   ğŸ“Š Total de combinaÃ§Ãµes: {total_combinacoes}\")\n",
    "    logging.info(f\"   ğŸ“‹ Total de projetos: {total_projetos}\")\n",
    "    logging.info(f\"   ğŸ”¤ Tokens estimados: {tokens_totais:,}\")\n",
    "    logging.info(f\"   ğŸ’µ Custo estimado: ${custo_estimado:.2f} USD\")\n",
    "    \n",
    "    return custo_estimado\n",
    "\n",
    "# Executar configuraÃ§Ã£o\n",
    "print(\"\\nğŸ”„ Executando Chunk 3: ConfiguraÃ§Ã£o da API Deepseek\")\n",
    "\n",
    "# Configurar API\n",
    "model_deepseek = configurar_api_deepseek()\n",
    "\n",
    "if model_deepseek:\n",
    "    # Testar conexÃ£o\n",
    "    conexao_ok = testar_conexao_api(model_deepseek)\n",
    "    \n",
    "    if conexao_ok and 'combinacoes_validas' in locals():\n",
    "        # Estimar custo\n",
    "        custo_estimado = estimar_custo_processamento(combinacoes_validas)\n",
    "        \n",
    "        print(f\"âœ… Chunk 3 executado: API configurada e testada\")\n",
    "        print(f\"ğŸ’° Custo estimado: ${custo_estimado:.2f} USD\" if custo_estimado else \"Custo nÃ£o calculado\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Chunk 3 parcial: API configurada mas teste falhou\")\n",
    "else:\n",
    "    print(\"âŒ Chunk 3 falhou: NÃ£o foi possÃ­vel configurar a API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec63b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:25:41,959 - INFO - ğŸ“‹ Formatados 3 projetos para anÃ¡lise\n",
      "2025-08-11 17:25:41,961 - INFO - âœ… Tamanho do prompt OK: 1180 tokens estimados\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Executando Chunk 4: PreparaÃ§Ã£o do Template de Prompt\n",
      "âœ… Chunk 4 executado: Template criado e validado\n",
      "ğŸ“ Prompt vÃ¡lido: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 4: PreparaÃ§Ã£o do Template de Prompt para IA\n",
    "Cria os templates de SystemMessage e HumanMessage para o Deepseek\n",
    "\"\"\"\n",
    "\n",
    "def criar_system_message():\n",
    "    \"\"\"\n",
    "    Cria a mensagem do sistema com instruÃ§Ãµes para agrupamento\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"VocÃª Ã© um especialista em anÃ¡lise de projetos de Pesquisa & Desenvolvimento (P&D) da Lei do Bem brasileira.\n",
    "\n",
    "Sua tarefa Ã© analisar projetos e agrupÃ¡-los por alta similaridade tÃ©cnica e temÃ¡tica.\n",
    "\n",
    "CRITÃ‰RIOS DE AGRUPAMENTO:\n",
    "1. Projetos devem ter ALTA SIMILARIDADE (>75%) em:\n",
    "   - Objeto/tema principal do projeto\n",
    "   - Tecnologias utilizadas\n",
    "   - Metodologia aplicada\n",
    "   - Resultados esperados\n",
    "\n",
    "2. GRUPOS VÃLIDOS:\n",
    "   - MÃ­nimo: 2 projetos por grupo\n",
    "   - MÃ¡ximo: 8 projetos por grupo\n",
    "   - Projetos Ãºnicos ficam sem grupo (grupo_id = 0)\n",
    "\n",
    "3. CRITÃ‰RIOS DE SIMILARIDADE:\n",
    "   - Mesmo domÃ­nio tecnolÃ³gico (ex: IoT, sensores, automaÃ§Ã£o)\n",
    "   - Mesma aplicaÃ§Ã£o (ex: monitoramento, controle, otimizaÃ§Ã£o)\n",
    "   - Metodologias similares (ex: machine learning, anÃ¡lise de dados)\n",
    "   - Resultados comparÃ¡veis (ex: produtos, processos, softwares)\n",
    "\n",
    "FORMATO DE SAÃDA:\n",
    "Retorne APENAS um CSV com as colunas:\n",
    "grupo_id,projeto_id,similaridade_score,justificativa_agrupamento\n",
    "\n",
    "EXEMPLO:\n",
    "1,ID123,0.85,\"Ambos desenvolvem sensores IoT para automaÃ§Ã£o industrial\"\n",
    "1,ID456,0.82,\"Projetos focam em sensores para controle de processos\"\n",
    "2,ID789,0.90,\"Desenvolvimento de algoritmos de machine learning\"\n",
    "2,ID012,0.88,\"AplicaÃ§Ã£o de IA para anÃ¡lise preditiva\"\n",
    "0,ID345,0.00,\"Projeto Ãºnico sem similaridade suficiente\"\n",
    "\n",
    "IMPORTANTE:\n",
    "- Seja rigoroso na similaridade\n",
    "- Prefira menos grupos com alta qualidade\n",
    "- Justifique cada agrupamento brevemente\n",
    "- Analise todo o contexto do projeto, nÃ£o apenas palavras-chave\"\"\"\n",
    "\n",
    "    return SystemMessage(content=system_prompt)\n",
    "\n",
    "def formatar_projetos_para_analise(df_subset):\n",
    "    \"\"\"\n",
    "    Formata os projetos de um subset para anÃ¡lise pela IA\n",
    "    \"\"\"\n",
    "    try:\n",
    "        projetos_formatados = []\n",
    "        \n",
    "        for idx, row in df_subset.iterrows():\n",
    "            # Extrair ID Ãºnico do projeto da coluna 'projeto'\n",
    "            projeto_texto = str(row['projeto'])\n",
    "            \n",
    "            # Buscar ID Ãºnico entre ' ID ÃšNICO: ' e ' NOME: '\n",
    "            import re\n",
    "            match_id = re.search(r'ID ÃšNICO:\\s*([^:]+?)\\s+NOME:', projeto_texto)\n",
    "            \n",
    "            if match_id:\n",
    "                projeto_id = match_id.group(1).strip()\n",
    "            else:\n",
    "                # Fallback caso nÃ£o encontre o padrÃ£o\n",
    "                projeto_id = f\"PROJ_{row.get('id_empresa_ano', idx)}_{idx}\"\n",
    "                logging.warning(f\"âš ï¸ ID Ãºnico nÃ£o encontrado para linha {idx}, usando fallback: {projeto_id}\")\n",
    "            \n",
    "            # FormataÃ§Ã£o limpa do projeto\n",
    "            projeto_formatado = f\"\"\"\n",
    "ID: {projeto_id}\n",
    "PROJETO: {row['projeto'][:500]}...\n",
    "SETOR: {row['setor']}\n",
    "NATUREZA: {row['natureza']}\n",
    "TIPO: {row['tipo_pesquisa']}\n",
    "RESULTADOS: {row['projeto_resultados'][:300] if pd.notna(row['projeto_resultados']) else 'NÃ£o informado'}...\n",
    "\"\"\"\n",
    "            projetos_formatados.append(projeto_formatado.strip())\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ Formatados {len(projetos_formatados)} projetos para anÃ¡lise\")\n",
    "        return projetos_formatados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao formatar projetos: {e}\")\n",
    "        return []\n",
    "\n",
    "def criar_human_message(projetos_formatados, combinacao_info):\n",
    "    \"\"\"\n",
    "    Cria a mensagem humana com os projetos para anÃ¡lise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # CabeÃ§alho da anÃ¡lise\n",
    "        cabecalho = f\"\"\"Analise os projetos abaixo e agrupe-os por alta similaridade tÃ©cnica.\n",
    "\n",
    "CONTEXTO DA ANÃLISE:\n",
    "- Ano: {combinacao_info['ano_referencia']}\n",
    "- Setor: {combinacao_info['setor']}\n",
    "- Tipo de Pesquisa: {combinacao_info['tipo_pesquisa']}\n",
    "- Natureza: {combinacao_info['natureza']}\n",
    "- Total de Projetos: {len(projetos_formatados)}\n",
    "\n",
    "PROJETOS PARA ANÃLISE:\n",
    "{'='*50}\"\"\"\n",
    "\n",
    "        # Adicionar projetos formatados\n",
    "        projetos_texto = '\\n\\n'.join(projetos_formatados)\n",
    "        \n",
    "        # InstruÃ§Ã£o final\n",
    "        instrucao_final = f\"\"\"\n",
    "{'='*50}\n",
    "\n",
    "Retorne APENAS o CSV com o agrupamento, seguindo o formato especificado no system prompt.\n",
    "Analise cuidadosamente a similaridade tÃ©cnica entre os projetos.\"\"\"\n",
    "\n",
    "        mensagem_completa = f\"{cabecalho}\\n\\n{projetos_texto}\\n{instrucao_final}\"\n",
    "        \n",
    "        return HumanMessage(content=mensagem_completa)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao criar human message: {e}\")\n",
    "        return None\n",
    "\n",
    "def validar_tamanho_prompt(system_msg, human_msg, limite_tokens=30000):\n",
    "    \"\"\"\n",
    "    Valida se o prompt nÃ£o excede o limite de tokens\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Estimativa simples: ~4 caracteres por token\n",
    "        total_chars = len(system_msg.content) + len(human_msg.content)\n",
    "        tokens_estimados = total_chars // 4\n",
    "        \n",
    "        if tokens_estimados > limite_tokens:\n",
    "            logging.warning(f\"âš ï¸ Prompt muito longo: {tokens_estimados} tokens estimados\")\n",
    "            return False\n",
    "        \n",
    "        logging.info(f\"âœ… Tamanho do prompt OK: {tokens_estimados} tokens estimados\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao validar tamanho do prompt: {e}\")\n",
    "        return False\n",
    "\n",
    "# Executar preparaÃ§Ã£o do template\n",
    "print(\"\\nğŸ”„ Executando Chunk 4: PreparaÃ§Ã£o do Template de Prompt\")\n",
    "\n",
    "# Criar system message\n",
    "system_message_template = criar_system_message()\n",
    "\n",
    "# Teste com dados dummy se disponÃ­vel\n",
    "if 'df_clean' in locals() and df_clean is not None and len(df_clean) > 0:\n",
    "    # Pegar uma amostra pequena para teste\n",
    "    df_teste = df_clean.head(3)\n",
    "    projetos_teste = formatar_projetos_para_analise(df_teste)\n",
    "    \n",
    "    combinacao_teste = {\n",
    "        'ano_referencia': df_teste.iloc[0]['ano_referencia'],\n",
    "        'setor': df_teste.iloc[0]['setor'],\n",
    "        'tipo_pesquisa': df_teste.iloc[0]['tipo_pesquisa'],\n",
    "        'natureza': df_teste.iloc[0]['natureza']\n",
    "    }\n",
    "    \n",
    "    human_message_teste = criar_human_message(projetos_teste, combinacao_teste)\n",
    "    \n",
    "    if human_message_teste:\n",
    "        prompt_valido = validar_tamanho_prompt(system_message_template, human_message_teste)\n",
    "        print(f\"âœ… Chunk 4 executado: Template criado e validado\")\n",
    "        print(f\"ğŸ“ Prompt vÃ¡lido: {prompt_valido}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Chunk 4 parcial: Template criado mas teste falhou\")\n",
    "else:\n",
    "    print(\"âœ… Chunk 4 executado: Template criado (sem teste - dados nÃ£o disponÃ­veis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac6f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:26:00,263 - INFO - ğŸ” Categoria filtrada: 1887 projetos\n",
      "2025-08-11 17:26:00,264 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,266 - INFO - ğŸ“¦ Categoria dividida: 1887 projetos â†’ 27 sub-lotes\n",
      "2025-08-11 17:26:00,266 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,304 - INFO - ğŸ” Categoria filtrada: 8172 projetos\n",
      "2025-08-11 17:26:00,305 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,308 - INFO - ğŸ“¦ Categoria dividida: 8172 projetos â†’ 116 sub-lotes\n",
      "2025-08-11 17:26:00,308 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,326 - INFO - ğŸ” Categoria filtrada: 165 projetos\n",
      "2025-08-11 17:26:00,327 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,328 - INFO - ğŸ“¦ Categoria dividida: 165 projetos â†’ 3 sub-lotes\n",
      "2025-08-11 17:26:00,329 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,346 - INFO - ğŸ” Categoria filtrada: 797 projetos\n",
      "2025-08-11 17:26:00,347 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,348 - INFO - ğŸ“¦ Categoria dividida: 797 projetos â†’ 12 sub-lotes\n",
      "2025-08-11 17:26:00,348 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,369 - INFO - ğŸ” Categoria filtrada: 2449 projetos\n",
      "2025-08-11 17:26:00,370 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,371 - INFO - ğŸ“¦ Categoria dividida: 2449 projetos â†’ 35 sub-lotes\n",
      "2025-08-11 17:26:00,371 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,388 - INFO - ğŸ” Categoria filtrada: 61 projetos\n",
      "2025-08-11 17:26:00,389 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,406 - INFO - ğŸ” Categoria filtrada: 81 projetos\n",
      "2025-08-11 17:26:00,406 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,407 - INFO - ğŸ“¦ Categoria dividida: 81 projetos â†’ 2 sub-lotes\n",
      "2025-08-11 17:26:00,407 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Executando Chunk 5 ADAPTADO: Processamento por Categoria\n",
      "ğŸ¯ Nova estratÃ©gia: Categorias completas com sub-lotes inteligentes\n",
      "ğŸ“Š Limite por sub-lote: 71 projetos (~25,000 tokens)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:26:00,425 - INFO - ğŸ” Categoria filtrada: 575 projetos\n",
      "2025-08-11 17:26:00,426 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,427 - INFO - ğŸ“¦ Categoria dividida: 575 projetos â†’ 9 sub-lotes\n",
      "2025-08-11 17:26:00,427 - INFO -    ğŸ”— SobreposiÃ§Ã£o: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,444 - INFO - ğŸ” Categoria filtrada: 42 projetos\n",
      "2025-08-11 17:26:00,444 - INFO - ğŸ“… Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,445 - INFO - ğŸ“‹ Plano por categoria criado: 206 itens\n",
      "2025-08-11 17:26:00,446 - INFO -    ğŸŸ¢ Categorias processadas completas: 2\n",
      "2025-08-11 17:26:00,446 - INFO -    ğŸŸ¡ Sub-lotes para merge posterior: 204\n",
      "2025-08-11 17:26:00,450 - ERROR - âŒ Erro ao salvar plano categoria: Cannot save file into a non-existent directory: 'resultados_agrupamento'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunk 5 adaptado executado:\n",
      "   ğŸ“Š Total de itens para processar: 206\n",
      "   ğŸ·ï¸ Categorias Ãºnicas: 9\n",
      "   ğŸ“‹ Total de projetos: 16199\n",
      "   ğŸ“„ Plano salvo: None\n",
      "   ğŸ”— EstratÃ©gia: ComparaÃ§Ã£o completa dentro de cada categoria\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 5 ADAPTADO: Processamento por Categoria com Sub-lotes Inteligentes\n",
    "Organiza processamento garantindo que todos os projetos de uma categoria sejam comparados\n",
    "\"\"\"\n",
    "\n",
    "# Novo limite baseado em tokens, nÃ£o quantidade arbitrÃ¡ria\n",
    "LIMITE_TOKENS_SEGUROS = 25000  # Deixa margem para resposta\n",
    "TOKENS_POR_PROJETO = 350      # Estimativa conservadora\n",
    "LIMITE_PROJETOS_POR_SUBLOTE = int(LIMITE_TOKENS_SEGUROS / TOKENS_POR_PROJETO)  # ~71 projetos\n",
    "\n",
    "def dividir_categoria_em_sublotes(df_categoria, limite_projetos=LIMITE_PROJETOS_POR_SUBLOTE):\n",
    "    \"\"\"\n",
    "    Divide uma categoria grande em sub-lotes, mantendo sobreposiÃ§Ã£o para merge posterior\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_projetos = len(df_categoria)\n",
    "        \n",
    "        if total_projetos <= limite_projetos:\n",
    "            # Categoria pequena: processar tudo de uma vez\n",
    "            return [{\n",
    "                'dados': df_categoria,\n",
    "                'sublote_num': 1,\n",
    "                'total_sublotes': 1,\n",
    "                'tipo': 'categoria_completa',\n",
    "                'sobreposicao': None\n",
    "            }]\n",
    "        \n",
    "        # Categoria grande: dividir com sobreposiÃ§Ã£o para merge posterior\n",
    "        sublotes = []\n",
    "        overlap_size = min(10, limite_projetos // 4)  # 25% de sobreposiÃ§Ã£o, mÃ¡ximo 10\n",
    "        \n",
    "        inicio = 0\n",
    "        sublote_num = 1\n",
    "        \n",
    "        while inicio < total_projetos:\n",
    "            fim = min(inicio + limite_projetos, total_projetos)\n",
    "            \n",
    "            # Adicionar sobreposiÃ§Ã£o (exceto no primeiro sub-lote)\n",
    "            if sublote_num > 1:\n",
    "                inicio_real = max(0, inicio - overlap_size)\n",
    "            else:\n",
    "                inicio_real = inicio\n",
    "            \n",
    "            sublote_dados = df_categoria.iloc[inicio_real:fim]\n",
    "            \n",
    "            sublote = {\n",
    "                'dados': sublote_dados,\n",
    "                'sublote_num': sublote_num,\n",
    "                'total_sublotes': None,  # SerÃ¡ calculado depois\n",
    "                'tipo': 'sublote_categoria',\n",
    "                'sobreposicao': {\n",
    "                    'inicio_original': inicio,\n",
    "                    'fim_original': fim,\n",
    "                    'overlap_inicio': overlap_size if sublote_num > 1 else 0,\n",
    "                    'projetos_sobrepostos': overlap_size if sublote_num > 1 else 0\n",
    "                }\n",
    "            }\n",
    "            sublotes.append(sublote)\n",
    "            \n",
    "            inicio = fim\n",
    "            sublote_num += 1\n",
    "        \n",
    "        # Atualizar total de sub-lotes\n",
    "        for sublote in sublotes:\n",
    "            sublote['total_sublotes'] = len(sublotes)\n",
    "        \n",
    "        logging.info(f\"ğŸ“¦ Categoria dividida: {total_projetos} projetos â†’ {len(sublotes)} sub-lotes\")\n",
    "        logging.info(f\"   ğŸ”— SobreposiÃ§Ã£o: {overlap_size} projetos entre sub-lotes\")\n",
    "        \n",
    "        return sublotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao dividir categoria: {e}\")\n",
    "        return []\n",
    "\n",
    "def filtrar_categoria_especifica(df_clean, combinacao):\n",
    "    \"\"\"\n",
    "    Filtra TODOS os projetos de uma categoria especÃ­fica (incluindo anos diferentes)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_categoria = df_clean[\n",
    "            (df_clean['setor'] == combinacao['setor']) &\n",
    "            (df_clean['tipo_pesquisa'] == combinacao['tipo_pesquisa']) &\n",
    "            (df_clean['natureza'] == combinacao['natureza'])\n",
    "        ].copy()\n",
    "        \n",
    "        # Adicionar informaÃ§Ã£o de ano para controle\n",
    "        anos_encontrados = df_categoria['ano_referencia'].unique()\n",
    "        \n",
    "        logging.info(f\"ğŸ” Categoria filtrada: {len(df_categoria)} projetos\")\n",
    "        logging.info(f\"ğŸ“… Anos encontrados: {sorted(anos_encontrados)}\")\n",
    "        \n",
    "        return df_categoria\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao filtrar categoria: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def criar_nome_arquivo_categoria(combinacao, sublote_info=None):\n",
    "    \"\"\"\n",
    "    Cria nome padronizado para arquivos por categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Limpar caracteres especiais\n",
    "        setor = re.sub(r'[^\\w\\s-]', '', str(combinacao['setor'])).strip()[:25]\n",
    "        tipo = re.sub(r'[^\\w\\s-]', '', str(combinacao['tipo_pesquisa'])).strip()[:25]\n",
    "        natureza = re.sub(r'[^\\w\\s-]', '', str(combinacao['natureza'])).strip()[:20]\n",
    "        \n",
    "        # Substituir espaÃ§os por underscores\n",
    "        setor = setor.replace(' ', '_')\n",
    "        tipo = tipo.replace(' ', '_')\n",
    "        natureza = natureza.replace(' ', '_')\n",
    "        \n",
    "        if sublote_info and sublote_info['tipo'] == 'sublote_categoria':\n",
    "            nome = f\"grupos_categoria_{setor}_{tipo}_{natureza}_sublote{sublote_info['sublote_num']}.csv\"\n",
    "        else:\n",
    "            nome = f\"grupos_categoria_{setor}_{tipo}_{natureza}_completa.csv\"\n",
    "        \n",
    "        return nome\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao criar nome do arquivo: {e}\")\n",
    "        return f\"grupos_categoria_erro_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "def preparar_plano_processamento_categoria(df_clean, combinacoes_validas):\n",
    "    \"\"\"\n",
    "    Prepara plano de processamento focado em categorias completas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plano_processamento = []\n",
    "        \n",
    "        for idx, row in combinacoes_validas.iterrows():\n",
    "            combinacao = {\n",
    "                'setor': row['setor'],\n",
    "                'tipo_pesquisa': row['tipo_pesquisa'],\n",
    "                'natureza': row['natureza'],\n",
    "                'count': row['count']\n",
    "            }\n",
    "            \n",
    "            # Filtrar TODOS os projetos da categoria\n",
    "            df_categoria = filtrar_categoria_especifica(df_clean, combinacao)\n",
    "            \n",
    "            if len(df_categoria) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Dividir em sub-lotes se necessÃ¡rio\n",
    "            sublotes = dividir_categoria_em_sublotes(df_categoria)\n",
    "            \n",
    "            for sublote in sublotes:\n",
    "                plano_item = {\n",
    "                    'combinacao': combinacao,\n",
    "                    'dados': sublote['dados'],\n",
    "                    'sublote_info': sublote,\n",
    "                    'arquivo_saida': criar_nome_arquivo_categoria(combinacao, sublote),\n",
    "                    'requer_merge': sublote['tipo'] == 'sublote_categoria'\n",
    "                }\n",
    "                plano_processamento.append(plano_item)\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ Plano por categoria criado: {len(plano_processamento)} itens\")\n",
    "        \n",
    "        # EstatÃ­sticas do plano\n",
    "        categorias_completas = sum(1 for item in plano_processamento if not item['requer_merge'])\n",
    "        categorias_sublotes = len(plano_processamento) - categorias_completas\n",
    "        \n",
    "        logging.info(f\"   ğŸŸ¢ Categorias processadas completas: {categorias_completas}\")\n",
    "        logging.info(f\"   ğŸŸ¡ Sub-lotes para merge posterior: {categorias_sublotes}\")\n",
    "        \n",
    "        return plano_processamento\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao preparar plano por categoria: {e}\")\n",
    "        return []\n",
    "\n",
    "def salvar_plano_categoria(plano_processamento):\n",
    "    \"\"\"\n",
    "    Salva o plano de processamento por categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plano_resumo = []\n",
    "        for item in plano_processamento:\n",
    "            resumo = {\n",
    "                'setor': item['combinacao']['setor'],\n",
    "                'tipo_pesquisa': item['combinacao']['tipo_pesquisa'],\n",
    "                'natureza': item['combinacao']['natureza'],\n",
    "                'total_projetos': len(item['dados']),\n",
    "                'sublote_num': item['sublote_info']['sublote_num'],\n",
    "                'total_sublotes': item['sublote_info']['total_sublotes'],\n",
    "                'tipo_processamento': item['sublote_info']['tipo'],\n",
    "                'requer_merge': item['requer_merge'],\n",
    "                'arquivo_saida': item['arquivo_saida']\n",
    "            }\n",
    "            plano_resumo.append(resumo)\n",
    "        \n",
    "        df_plano = pd.DataFrame(plano_resumo)\n",
    "        arquivo_plano = 'resultados_agrupamento/plano_processamento_categoria.csv'\n",
    "        df_plano.to_csv(arquivo_plano, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"ğŸ“„ Plano por categoria salvo: {arquivo_plano}\")\n",
    "        return arquivo_plano\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao salvar plano categoria: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar preparaÃ§Ã£o por categoria\n",
    "print(\"\\nğŸ”„ Executando Chunk 5 ADAPTADO: Processamento por Categoria\")\n",
    "\n",
    "if 'df_clean' in locals() and 'combinacoes_validas' in locals() and df_clean is not None:\n",
    "    print(f\"ğŸ¯ Nova estratÃ©gia: Categorias completas com sub-lotes inteligentes\")\n",
    "    print(f\"ğŸ“Š Limite por sub-lote: {LIMITE_PROJETOS_POR_SUBLOTE} projetos (~{LIMITE_TOKENS_SEGUROS:,} tokens)\")\n",
    "    \n",
    "    # Criar plano por categoria\n",
    "    plano_processamento = preparar_plano_processamento_categoria(df_clean, combinacoes_validas)\n",
    "    \n",
    "    if plano_processamento:\n",
    "        # Salvar plano\n",
    "        arquivo_plano = salvar_plano_categoria(plano_processamento)\n",
    "        \n",
    "        # EstatÃ­sticas finais\n",
    "        total_projetos = sum(len(item['dados']) for item in plano_processamento)\n",
    "        categorias_unicas = len(set((item['combinacao']['setor'], \n",
    "                                   item['combinacao']['tipo_pesquisa'], \n",
    "                                   item['combinacao']['natureza']) \n",
    "                                  for item in plano_processamento))\n",
    "        \n",
    "        print(f\"âœ… Chunk 5 adaptado executado:\")\n",
    "        print(f\"   ğŸ“Š Total de itens para processar: {len(plano_processamento)}\")\n",
    "        print(f\"   ğŸ·ï¸ Categorias Ãºnicas: {categorias_unicas}\")\n",
    "        print(f\"   ğŸ“‹ Total de projetos: {total_projetos}\")\n",
    "        print(f\"   ğŸ“„ Plano salvo: {arquivo_plano}\")\n",
    "        print(f\"   ğŸ”— EstratÃ©gia: ComparaÃ§Ã£o completa dentro de cada categoria\")\n",
    "    else:\n",
    "        print(\"âŒ Chunk 5 adaptado falhou: NÃ£o foi possÃ­vel criar plano de categoria\")\n",
    "else:\n",
    "    print(\"âš ï¸ Chunk 5 adaptado ignorado: Dados nÃ£o disponÃ­veis dos chunks anteriores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a9ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Executando Chunk 6 ADAPTADO: Loop Principal com Processamento AssÃ­ncrono\n",
      "âš ï¸ Chunk 6 adaptado ignorado: DependÃªncias nÃ£o disponÃ­veis\n",
      "ğŸ” VariÃ¡veis faltando: []\n",
      "\n",
      "ğŸ’¡ DICA: Instale nest_asyncio se houver problemas com loops de eventos:\n",
      "pip install nest-asyncio\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 6 ADAPTADO: Loop Principal de IteraÃ§Ã£o com RequisiÃ§Ãµes AssÃ­ncronas\n",
    "Implementa processamento assÃ­ncrono para acelerar requisiÃ§Ãµes Ã  API\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "\n",
    "def configurar_api_deepseek_async():\n",
    "    \"\"\"\n",
    "    Configura o cliente da API Deepseek (usando ChatOpenAI normal)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obter chave da API\n",
    "        api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"A chave da API do DeepSeek nÃ£o estÃ¡ definida nas variÃ¡veis de ambiente.\")\n",
    "        \n",
    "        # Configurar o modelo (usar o ChatOpenAI normal)\n",
    "        model = ChatOpenAI(\n",
    "            model=\"deepseek-chat\",\n",
    "            temperature=0.3,\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=4000,\n",
    "            max_retries=3,\n",
    "            request_timeout=60.0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"âœ… API Deepseek configurada para uso assÃ­ncrono\")\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao configurar API Deepseek: {e}\")\n",
    "        return None\n",
    "\n",
    "async def processar_item_plano_async(item_plano, model_deepseek, system_message_template, executor, semaforo):\n",
    "    \"\"\"\n",
    "    Processa um item individual do plano de processamento de forma assÃ­ncrona usando ThreadPoolExecutor\n",
    "    \"\"\"\n",
    "    async with semaforo:  # Limitar nÃºmero de requisiÃ§Ãµes simultÃ¢neas\n",
    "        try:\n",
    "            combinacao = item_plano['combinacao']\n",
    "            dados = item_plano['dados']\n",
    "            arquivo_saida = item_plano['arquivo_saida']\n",
    "            \n",
    "            logging.info(f\"ğŸ”„ Processando async: {combinacao['setor']} - {len(dados)} projetos\")\n",
    "            \n",
    "            # Formatar projetos para anÃ¡lise\n",
    "            projetos_formatados = formatar_projetos_para_analise(dados)\n",
    "            \n",
    "            if not projetos_formatados:\n",
    "                logging.error(\"âŒ Falha ao formatar projetos\")\n",
    "                return None\n",
    "            \n",
    "            # Criar mensagem humana\n",
    "            human_message = criar_human_message(projetos_formatados, combinacao)\n",
    "            \n",
    "            if not human_message:\n",
    "                logging.error(\"âŒ Falha ao criar human message\")\n",
    "                return None\n",
    "            \n",
    "            # Validar tamanho do prompt\n",
    "            if not validar_tamanho_prompt(system_message_template, human_message):\n",
    "                logging.error(\"âŒ Prompt excede limite de tokens\")\n",
    "                return None\n",
    "            \n",
    "            # Preparar mensagens para a API\n",
    "            mensagens = [system_message_template, human_message]\n",
    "            \n",
    "            logging.info(f\"ğŸ“¤ Enviando para API Deepseek (async via thread)...\")\n",
    "            \n",
    "            # Executar chamada da API em thread separada para nÃ£o bloquear\n",
    "            loop = asyncio.get_event_loop()\n",
    "            resposta = await loop.run_in_executor(\n",
    "                executor, \n",
    "                partial(model_deepseek.invoke, mensagens)\n",
    "            )\n",
    "            \n",
    "            if resposta and resposta.content:\n",
    "                logging.info(f\"âœ… Resposta assÃ­ncrona recebida para {combinacao['setor']}\")\n",
    "                return {\n",
    "                    'resposta': resposta.content,\n",
    "                    'combinacao': combinacao,\n",
    "                    'arquivo_saida': arquivo_saida,\n",
    "                    'total_projetos': len(dados),\n",
    "                    'requer_merge': item_plano.get('requer_merge', False)\n",
    "                }\n",
    "            else:\n",
    "                logging.error(\"âŒ Resposta vazia da API\")\n",
    "                return None\n",
    "        \n",
    "        except asyncio.TimeoutError:\n",
    "            logging.error(f\"â±ï¸ Timeout na requisiÃ§Ã£o para {combinacao['setor']}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"âŒ Erro ao processar item async: {e}\")\n",
    "            return None\n",
    "\n",
    "async def executar_lote_async(lote_itens, model_deepseek, system_message_template, executor, max_concurrent=3):\n",
    "    \"\"\"\n",
    "    Executa um lote de itens de forma assÃ­ncrona\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # SemÃ¡foro para limitar requisiÃ§Ãµes simultÃ¢neas\n",
    "        semaforo = asyncio.Semaphore(max_concurrent)\n",
    "        \n",
    "        # Criar tarefas assÃ­ncronas\n",
    "        tarefas = []\n",
    "        for item in lote_itens:\n",
    "            tarefa = processar_item_plano_async(item, model_deepseek, system_message_template, executor, semaforo)\n",
    "            tarefas.append(tarefa)\n",
    "        \n",
    "        # Executar todas as tarefas em paralelo\n",
    "        resultados = await asyncio.gather(*tarefas, return_exceptions=True)\n",
    "        \n",
    "        # Filtrar resultados vÃ¡lidos\n",
    "        resultados_validos = []\n",
    "        for resultado in resultados:\n",
    "            if isinstance(resultado, Exception):\n",
    "                logging.error(f\"âŒ ExceÃ§Ã£o no processamento assÃ­ncrono: {resultado}\")\n",
    "            elif resultado is not None:\n",
    "                resultados_validos.append(resultado)\n",
    "        \n",
    "        logging.info(f\"âœ… Lote assÃ­ncrono concluÃ­do: {len(resultados_validos)}/{len(lote_itens)} sucessos\")\n",
    "        return resultados_validos\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no lote assÃ­ncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def dividir_em_lotes_async(plano_processamento, tamanho_lote=5):\n",
    "    \"\"\"\n",
    "    Divide o plano em lotes menores para processamento assÃ­ncrono\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lotes = []\n",
    "        total_itens = len(plano_processamento)\n",
    "        \n",
    "        for i in range(0, total_itens, tamanho_lote):\n",
    "            lote = plano_processamento[i:i+tamanho_lote]\n",
    "            lotes.append(lote)\n",
    "        \n",
    "        logging.info(f\"ğŸ“¦ DivisÃ£o para processamento assÃ­ncrono: {total_itens} itens â†’ {len(lotes)} lotes\")\n",
    "        return lotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao dividir em lotes async: {e}\")\n",
    "        return [plano_processamento]  # Retorna como um lote Ãºnico\n",
    "\n",
    "async def executar_loop_principal_async(plano_processamento, model_deepseek, system_message_template, \n",
    "                                       modo_teste=False, limite_teste=3, max_concurrent=3, tamanho_lote=5):\n",
    "    \"\"\"\n",
    "    Executa o loop principal de processamento de forma assÃ­ncrona\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resultados = []\n",
    "        total_itens = len(plano_processamento)\n",
    "        \n",
    "        # Limitar para teste se necessÃ¡rio\n",
    "        if modo_teste:\n",
    "            plano_processamento = plano_processamento[:limite_teste]\n",
    "            logging.info(f\"ğŸ§ª Modo teste ativado: processando apenas {len(plano_processamento)} itens\")\n",
    "        \n",
    "        logging.info(f\"ğŸš€ Iniciando processamento assÃ­ncrono de {len(plano_processamento)} itens...\")\n",
    "        logging.info(f\"âš¡ ConfiguraÃ§Ã£o: {max_concurrent} requisiÃ§Ãµes simultÃ¢neas, lotes de {tamanho_lote}\")\n",
    "        \n",
    "        # Criar ThreadPoolExecutor para requisiÃ§Ãµes HTTP\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent) as executor:\n",
    "            # Dividir em lotes para gerenciar melhor o processamento\n",
    "            lotes = dividir_em_lotes_async(plano_processamento, tamanho_lote)\n",
    "            \n",
    "            for idx_lote, lote in enumerate(lotes, 1):\n",
    "                try:\n",
    "                    logging.info(f\"\\n{'='*60}\")\n",
    "                    logging.info(f\"ğŸ“¦ Processando lote {idx_lote}/{len(lotes)} ({len(lote)} itens)\")\n",
    "                    \n",
    "                    # Executar lote assÃ­ncrono\n",
    "                    resultados_lote = await executar_lote_async(\n",
    "                        lote, model_deepseek, system_message_template, executor, max_concurrent\n",
    "                    )\n",
    "                    \n",
    "                    resultados.extend(resultados_lote)\n",
    "                    \n",
    "                    logging.info(f\"âœ… Lote {idx_lote} concluÃ­do: {len(resultados_lote)} sucessos\")\n",
    "                    \n",
    "                    # Pausa entre lotes (exceto no Ãºltimo)\n",
    "                    if idx_lote < len(lotes):\n",
    "                        pausa_entre_lotes = min(TEMPO_PAUSA_ENTRE_REQUESTS, 3)  # MÃ¡ximo 3s entre lotes\n",
    "                        logging.info(f\"â¸ï¸ Pausando {pausa_entre_lotes}s entre lotes...\")\n",
    "                        await asyncio.sleep(pausa_entre_lotes)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"âŒ Erro no lote {idx_lote}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        logging.info(f\"\\nğŸ‰ Processamento assÃ­ncrono concluÃ­do!\")\n",
    "        logging.info(f\"âœ… Sucessos: {len(resultados)}/{total_itens}\")\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no loop principal assÃ­ncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def executar_processamento_sincronizado(plano_processamento, system_message_template, \n",
    "                                      modo_teste=True, limite_teste=3):\n",
    "    \"\"\"\n",
    "    FunÃ§Ã£o wrapper que gerencia a execuÃ§Ã£o assÃ­ncrona usando ThreadPoolExecutor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configurar cliente (ChatOpenAI normal)\n",
    "        model_deepseek = configurar_api_deepseek_async()\n",
    "        if not model_deepseek:\n",
    "            raise Exception(\"Falha na configuraÃ§Ã£o da API\")\n",
    "        \n",
    "        # Verificar se jÃ¡ hÃ¡ um loop de eventos rodando\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            logging.info(\"ğŸ“¡ Loop de eventos jÃ¡ ativo, usando nest_asyncio\")\n",
    "            \n",
    "            # Se jÃ¡ hÃ¡ um loop, usar nest_asyncio\n",
    "            try:\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "            except ImportError:\n",
    "                logging.warning(\"âš ï¸ nest_asyncio nÃ£o instalado, tentando execuÃ§Ã£o alternativa\")\n",
    "                # Fallback: executar de forma sÃ­ncrona\n",
    "                return executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste)\n",
    "            \n",
    "            # Executar de forma assÃ­ncrona no loop existente\n",
    "            resultado = asyncio.run(executar_loop_principal_async(\n",
    "                plano_processamento, model_deepseek, system_message_template,\n",
    "                modo_teste, limite_teste, max_concurrent=3, tamanho_lote=5\n",
    "            ))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            # NÃ£o hÃ¡ loop rodando, criar um novo\n",
    "            logging.info(\"ğŸ“¡ Criando novo loop de eventos\")\n",
    "            resultado = asyncio.run(executar_loop_principal_async(\n",
    "                plano_processamento, model_deepseek, system_message_template,\n",
    "                modo_teste, limite_teste, max_concurrent=3, tamanho_lote=5\n",
    "            ))\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro na execuÃ§Ã£o sincronizada: {e}\")\n",
    "        # Fallback para processamento sÃ­ncrono\n",
    "        return executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste)\n",
    "\n",
    "def executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste):\n",
    "    \"\"\"\n",
    "    Fallback para processamento sÃ­ncrono caso asyncio falhe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"ğŸ”„ Executando fallback sÃ­ncrono...\")\n",
    "        resultados = []\n",
    "        \n",
    "        # Limitar para teste se necessÃ¡rio\n",
    "        if modo_teste:\n",
    "            plano_processamento = plano_processamento[:limite_teste]\n",
    "        \n",
    "        for idx, item in enumerate(plano_processamento, 1):\n",
    "            try:\n",
    "                logging.info(f\"ğŸ“‹ Processando item {idx}/{len(plano_processamento)} (sÃ­ncrono)\")\n",
    "                \n",
    "                # Processar item de forma sÃ­ncrona\n",
    "                combinacao = item['combinacao']\n",
    "                dados = item['dados']\n",
    "                arquivo_saida = item['arquivo_saida']\n",
    "                \n",
    "                projetos_formatados = formatar_projetos_para_analise(dados)\n",
    "                if not projetos_formatados:\n",
    "                    continue\n",
    "                \n",
    "                human_message = criar_human_message(projetos_formatados, combinacao)\n",
    "                if not human_message:\n",
    "                    continue\n",
    "                \n",
    "                mensagens = [system_message_template, human_message]\n",
    "                resposta = model_deepseek.invoke(mensagens)\n",
    "                \n",
    "                if resposta and resposta.content:\n",
    "                    resultado = {\n",
    "                        'resposta': resposta.content,\n",
    "                        'combinacao': combinacao,\n",
    "                        'arquivo_saida': arquivo_saida,\n",
    "                        'total_projetos': len(dados),\n",
    "                        'requer_merge': item.get('requer_merge', False)\n",
    "                    }\n",
    "                    resultados.append(resultado)\n",
    "                    logging.info(f\"âœ… Item {idx} processado (sÃ­ncrono)\")\n",
    "                \n",
    "                # Pausa entre requisiÃ§Ãµes\n",
    "                if idx < len(plano_processamento):\n",
    "                    time.sleep(TEMPO_PAUSA_ENTRE_REQUESTS)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"âŒ Erro no item {idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no fallback sÃ­ncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def salvar_progresso_intermediario(resultados, timestamp):\n",
    "    \"\"\"\n",
    "    Salva progresso intermediÃ¡rio durante o processamento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        arquivo_progresso = f'resultados_agrupamento/progresso_{timestamp}.json'\n",
    "        \n",
    "        # Converter para formato serializÃ¡vel\n",
    "        progresso_data = []\n",
    "        for resultado in resultados:\n",
    "            item = {\n",
    "                'combinacao': resultado['combinacao'],\n",
    "                'arquivo_saida': resultado['arquivo_saida'],\n",
    "                'total_projetos': resultado['total_projetos'],\n",
    "                'resposta_length': len(resultado['resposta']),\n",
    "                'requer_merge': resultado.get('requer_merge', False),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            progresso_data.append(item)\n",
    "        \n",
    "        with open(arquivo_progresso, 'w', encoding='utf-8') as f:\n",
    "            json.dump(progresso_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"ğŸ’¾ Progresso salvo: {arquivo_progresso}\")\n",
    "        return arquivo_progresso\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao salvar progresso: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar loop principal assÃ­ncrono\n",
    "print(\"\\nğŸ”„ Executando Chunk 6 ADAPTADO: Loop Principal com Processamento AssÃ­ncrono\")\n",
    "\n",
    "if all(var in locals() for var in ['plano_processamento', 'system_message_template']):\n",
    "    # Timestamp para controle\n",
    "    timestamp_execucao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    print(\"âš¡ PROCESSAMENTO ASSÃNCRONO ATIVADO\")\n",
    "    print(\"ğŸ§ª Executando em MODO TESTE (3 primeiros itens)\")\n",
    "    print(\"ğŸ“Š ConfiguraÃ§Ã£o: 3 requisiÃ§Ãµes simultÃ¢neas, lotes de 5 itens\")\n",
    "    print(\"Para executar completo, mude modo_teste=False\")\n",
    "    \n",
    "    # Executar processamento assÃ­ncrono\n",
    "    resultados_processamento = executar_processamento_sincronizado(\n",
    "        plano_processamento, \n",
    "        system_message_template,\n",
    "        modo_teste=True,  # Mudar para False para execuÃ§Ã£o completa\n",
    "        limite_teste=3\n",
    "    )\n",
    "    \n",
    "    if resultados_processamento:\n",
    "        # Salvar progresso\n",
    "        arquivo_progresso = salvar_progresso_intermediario(resultados_processamento, timestamp_execucao)\n",
    "        \n",
    "        print(f\"âœ… Chunk 6 adaptado executado: {len(resultados_processamento)} itens processados\")\n",
    "        print(f\"âš¡ Vantagem assÃ­ncrona: ~3x mais rÃ¡pido que processamento sequencial\")\n",
    "        print(f\"ğŸ’¾ Progresso salvo: {arquivo_progresso}\")\n",
    "    else:\n",
    "        print(\"âŒ Chunk 6 adaptado falhou: Nenhum item foi processado com sucesso\")\n",
    "else:\n",
    "    print(\"âš ï¸ Chunk 6 adaptado ignorado: DependÃªncias nÃ£o disponÃ­veis\")\n",
    "    missing_vars = [var for var in ['plano_processamento', 'system_message_template'] \n",
    "                    if var not in locals()]\n",
    "    print(f\"ğŸ” VariÃ¡veis faltando: {missing_vars}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ DICA: Instale nest_asyncio se houver problemas com loops de eventos:\")\n",
    "print(\"pip install nest-asyncio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea74cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 7: Tratamento de Erros e Controle\n",
    "Implementa retry logic, rate limiting e controle de erros\n",
    "\"\"\"\n",
    "\n",
    "def processar_item_com_retry(item_plano, model_deepseek, system_message_template, max_tentativas=MAX_TENTATIVAS):\n",
    "    \"\"\"\n",
    "    Processa um item com lÃ³gica de retry em caso de erro\n",
    "    \"\"\"\n",
    "    for tentativa in range(1, max_tentativas + 1):\n",
    "        try:\n",
    "            logging.info(f\"ğŸ”„ Tentativa {tentativa}/{max_tentativas}\")\n",
    "            \n",
    "            resultado = processar_item_plano(item_plano, model_deepseek, system_message_template)\n",
    "            \n",
    "            if resultado:\n",
    "                if tentativa > 1:\n",
    "                    logging.info(f\"âœ… Sucesso na tentativa {tentativa}\")\n",
    "                return resultado\n",
    "            else:\n",
    "                logging.warning(f\"âš ï¸ Tentativa {tentativa} falhou - resultado vazio\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"âŒ Tentativa {tentativa} falhou: {e}\")\n",
    "            \n",
    "            # Pausa crescente entre tentativas (backoff exponencial)\n",
    "            if tentativa < max_tentativas:\n",
    "                pausa = TEMPO_PAUSA_ENTRE_REQUESTS * (2 ** (tentativa - 1))\n",
    "                logging.info(f\"â¸ï¸ Pausando {pausa}s antes da prÃ³xima tentativa...\")\n",
    "                time.sleep(pausa)\n",
    "    \n",
    "    logging.error(f\"âŒ Todas as {max_tentativas} tentativas falharam\")\n",
    "    return None\n",
    "\n",
    "def validar_resposta_api(resposta_content):\n",
    "    \"\"\"\n",
    "    Valida se a resposta da API estÃ¡ no formato esperado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not resposta_content:\n",
    "            return False, \"Resposta vazia\"\n",
    "        \n",
    "        # Verificar se contÃ©m formato CSV bÃ¡sico\n",
    "        linhas = resposta_content.strip().split('\\n')\n",
    "        \n",
    "        if len(linhas) < 2:\n",
    "            return False, \"Resposta muito curta - esperado formato CSV\"\n",
    "        \n",
    "        # Verificar se primeira linha parece um cabeÃ§alho CSV\n",
    "        primeira_linha = linhas[0].strip()\n",
    "        if not any(campo in primeira_linha.lower() for campo in ['grupo', 'projeto', 'id']):\n",
    "            return False, \"CabeÃ§alho CSV nÃ£o reconhecido\"\n",
    "        \n",
    "        # Verificar se hÃ¡ pelo menos uma linha de dados\n",
    "        segunda_linha = linhas[1].strip()\n",
    "        if len(segunda_linha.split(',')) < 3:\n",
    "            return False, \"Formato de dados invÃ¡lido\"\n",
    "        \n",
    "        logging.info(f\"âœ… Resposta validada: {len(linhas)} linhas encontradas\")\n",
    "        return True, \"VÃ¡lida\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return False, f\"Erro na validaÃ§Ã£o: {e}\"\n",
    "\n",
    "def limpar_resposta_csv(resposta_content):\n",
    "    \"\"\"\n",
    "    Limpa a resposta para extrair apenas o CSV vÃ¡lido\n",
    "    \"\"\"\n",
    "    try:\n",
    "        linhas = resposta_content.strip().split('\\n')\n",
    "        linhas_csv = []\n",
    "        \n",
    "        # Procurar inÃ­cio do CSV\n",
    "        inicio_csv = -1\n",
    "        for i, linha in enumerate(linhas):\n",
    "            if any(campo in linha.lower() for campo in ['grupo_id', 'projeto_id', 'similaridade']):\n",
    "                inicio_csv = i\n",
    "                break\n",
    "        \n",
    "        if inicio_csv == -1:\n",
    "            # Se nÃ£o encontrar cabeÃ§alho especÃ­fico, usar primeira linha que parece CSV\n",
    "            for i, linha in enumerate(linhas):\n",
    "                if linha.count(',') >= 2:\n",
    "                    inicio_csv = i\n",
    "                    break\n",
    "        \n",
    "        if inicio_csv >= 0:\n",
    "            for linha in linhas[inicio_csv:]:\n",
    "                linha_limpa = linha.strip()\n",
    "                if linha_limpa and not linha_limpa.startswith('#'):\n",
    "                    linhas_csv.append(linha_limpa)\n",
    "        \n",
    "        csv_limpo = '\\n'.join(linhas_csv)\n",
    "        logging.info(f\"ğŸ§¹ CSV limpo: {len(linhas_csv)} linhas\")\n",
    "        return csv_limpo\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao limpar CSV: {e}\")\n",
    "        return resposta_content\n",
    "\n",
    "def salvar_erro_detalhado(item_plano, erro, timestamp):\n",
    "    \"\"\"\n",
    "    Salva detalhes de erros para debug\n",
    "    \"\"\"\n",
    "    try:\n",
    "        arquivo_erro = f'resultados_agrupamento/logs/erro_{timestamp}.json'\n",
    "        \n",
    "        erro_data = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'combinacao': item_plano['combinacao'],\n",
    "            'arquivo_saida': item_plano['arquivo_saida'],\n",
    "            'total_projetos': len(item_plano['dados']),\n",
    "            'erro': str(erro),\n",
    "            'dados_amostra': {\n",
    "                'primeiros_3_projetos': [\n",
    "                    {\n",
    "                        'setor': row['setor'],\n",
    "                        'tipo_pesquisa': row['tipo_pesquisa'],\n",
    "                        'projeto_preview': row['projeto'][:100] + '...' if len(row['projeto']) > 100 else row['projeto']\n",
    "                    }\n",
    "                    for _, row in item_plano['dados'].head(3).iterrows()\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(arquivo_erro, 'w', encoding='utf-8') as f:\n",
    "            json.dump(erro_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ Erro detalhado salvo: {arquivo_erro}\")\n",
    "        return arquivo_erro\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao salvar detalhes do erro: {e}\")\n",
    "        return None\n",
    "\n",
    "def monitorar_uso_api(resultados_processamento):\n",
    "    \"\"\"\n",
    "    Monitora uso da API e custos aproximados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_requisicoes = len(resultados_processamento)\n",
    "        total_projetos = sum(r['total_projetos'] for r in resultados_processamento)\n",
    "        \n",
    "        # Estimativas de tokens e custo\n",
    "        tokens_estimados = total_projetos * 300  # mÃ©dia por projeto\n",
    "        custo_estimado = (tokens_estimados / 1000) * 0.0014  # preÃ§o aproximado Deepseek\n",
    "        \n",
    "        log_uso = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_requisicoes': total_requisicoes,\n",
    "            'total_projetos': total_projetos,\n",
    "            'tokens_estimados': tokens_estimados,\n",
    "            'custo_estimado_usd': custo_estimado\n",
    "        }\n",
    "        \n",
    "        arquivo_uso = 'resultados_agrupamento/logs/uso_api.json'\n",
    "        with open(arquivo_uso, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log_uso, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"ğŸ’° Uso da API monitorado: {total_requisicoes} requests, ~${custo_estimado:.2f}\")\n",
    "        return log_uso\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao monitorar uso da API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar tratamento de erros\n",
    "print(\"\\nğŸ”„ Executando Chunk 7: Tratamento de Erros e Controle\")\n",
    "\n",
    "# Verificar se hÃ¡ resultados para validar\n",
    "if 'resultados_processamento' in locals() and resultados_processamento:\n",
    "    print(f\"ğŸ” Validando {len(resultados_processamento)} resultados...\")\n",
    "    \n",
    "    resultados_validos = []\n",
    "    resultados_invalidos = []\n",
    "    \n",
    "    for resultado in resultados_processamento:\n",
    "        valida, motivo = validar_resposta_api(resultado['resposta'])\n",
    "        \n",
    "        if valida:\n",
    "            # Limpar CSV\n",
    "            csv_limpo = limpar_resposta_csv(resultado['resposta'])\n",
    "            resultado['resposta_limpa'] = csv_limpo\n",
    "            resultados_validos.append(resultado)\n",
    "        else:\n",
    "            logging.warning(f\"âš ï¸ Resposta invÃ¡lida: {motivo}\")\n",
    "            resultados_invalidos.append(resultado)\n",
    "    \n",
    "    # Monitorar uso da API\n",
    "    if resultados_validos:\n",
    "        uso_api = monitorar_uso_api(resultados_validos)\n",
    "    \n",
    "    print(f\"âœ… Chunk 7 executado:\")\n",
    "    print(f\"   âœ… Respostas vÃ¡lidas: {len(resultados_validos)}\")\n",
    "    print(f\"   âŒ Respostas invÃ¡lidas: {len(resultados_invalidos)}\")\n",
    "    \n",
    "    if uso_api:\n",
    "        print(f\"   ğŸ’° Custo estimado: ${uso_api['custo_estimado_usd']:.2f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Chunk 7 ignorado: Nenhum resultado para validar\")\n",
    "    resultados_validos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 8: ConsolidaÃ§Ã£o Final integrando Multianuais + Merge de Sub-lotes\n",
    "Une os grupos automÃ¡ticos (multianuais) com os grupos da LLM e faz merge inteligente\n",
    "\"\"\"\n",
    "\n",
    "def identificar_categorias_para_merge(resultados_processados):\n",
    "    \"\"\"\n",
    "    Identifica quais categorias foram divididas em sub-lotes e precisam de merge\n",
    "    \"\"\"\n",
    "    try:\n",
    "        categorias_sublotes = {}\n",
    "        \n",
    "        for resultado in resultados_processados:\n",
    "            if resultado.get('requer_merge', False):\n",
    "                combinacao = resultado['combinacao']\n",
    "                categoria_key = f\"{combinacao['setor']}_{combinacao['tipo_pesquisa']}_{combinacao['natureza']}\"\n",
    "                \n",
    "                if categoria_key not in categorias_sublotes:\n",
    "                    categorias_sublotes[categoria_key] = []\n",
    "                \n",
    "                categorias_sublotes[categoria_key].append(resultado)\n",
    "        \n",
    "        logging.info(f\"ğŸ”— Categorias que precisam merge: {len(categorias_sublotes)}\")\n",
    "        return categorias_sublotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao identificar categorias para merge: {e}\")\n",
    "        return {}\n",
    "\n",
    "def processar_merge_completo(resultados_processados):\n",
    "    \"\"\"\n",
    "    Processa merge completo de todas as categorias que precisam\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Separar resultados que precisam de merge vs. categorias completas\n",
    "        resultados_finais = []\n",
    "        \n",
    "        # Identificar categorias para merge\n",
    "        categorias_sublotes = identificar_categorias_para_merge(resultados_processados)\n",
    "        \n",
    "        # Processar categorias que foram divididas em sub-lotes\n",
    "        for categoria_key, sublotes in categorias_sublotes.items():\n",
    "            resultado_merge = fazer_merge_sublotes_categoria(sublotes, categoria_key)\n",
    "            if resultado_merge:\n",
    "                resultados_finais.append(resultado_merge)\n",
    "        \n",
    "        # Adicionar categorias que foram processadas completas (sem sub-lotes)\n",
    "        for resultado in resultados_processados:\n",
    "            if not resultado.get('requer_merge', False):\n",
    "                resultados_finais.append(resultado)\n",
    "        \n",
    "        logging.info(f\"ğŸ”— Merge completo finalizado:\")\n",
    "        logging.info(f\"   ğŸ·ï¸ Categorias processadas: {len(resultados_finais)}\")\n",
    "        logging.info(f\"   ğŸ“¦ Categorias que passaram por merge: {len(categorias_sublotes)}\")\n",
    "        \n",
    "        return resultados_finais\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no merge completo: {e}\")\n",
    "        return resultados_processados  # Retorna originais em caso de erro\n",
    "\n",
    "def fazer_merge_sublotes_categoria(sublotes_categoria, categoria_key):\n",
    "    \"\"\"\n",
    "    Faz merge inteligente de todos os sub-lotes de uma categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"ğŸ”— Fazendo merge da categoria: {categoria_key}\")\n",
    "        logging.info(f\"   ğŸ“¦ Sub-lotes a processar: {len(sublotes_categoria)}\")\n",
    "        \n",
    "        # Consolidar todos os DataFrames dos sub-lotes\n",
    "        dfs_sublotes = []\n",
    "        for sublote in sublotes_categoria:\n",
    "            if 'dataframe' in sublote and sublote['dataframe'] is not None:\n",
    "                df_temp = sublote['dataframe'].copy()\n",
    "                df_temp['sublote_origem'] = sublote['arquivo_saida']\n",
    "                dfs_sublotes.append(df_temp)\n",
    "        \n",
    "        if not dfs_sublotes:\n",
    "            logging.error(f\"âŒ Nenhum DataFrame vÃ¡lido para categoria {categoria_key}\")\n",
    "            return None\n",
    "        \n",
    "        # Concatenar todos os sub-lotes\n",
    "        df_categoria_completa = pd.concat(dfs_sublotes, ignore_index=True)\n",
    "        \n",
    "        # Renumerar grupos para evitar conflitos\n",
    "        df_categoria_completa['grupo_id_original'] = df_categoria_completa['grupo_id']\n",
    "        df_categoria_completa['grupo_id_global'] = 0\n",
    "        \n",
    "        # LÃ³gica de merge simples: manter grupos Ãºnicos por sub-lote\n",
    "        grupo_contador = 1\n",
    "        \n",
    "        for sublote_idx, sublote in enumerate(sublotes_categoria):\n",
    "            df_sublote = dfs_sublotes[sublote_idx]\n",
    "            grupos_sublote = df_sublote[df_sublote['grupo_id'] > 0]['grupo_id'].unique()\n",
    "            \n",
    "            for grupo_id in grupos_sublote:\n",
    "                # Atribuir novo ID global\n",
    "                mask = (df_categoria_completa['sublote_origem'] == sublote['arquivo_saida']) & \\\n",
    "                       (df_categoria_completa['grupo_id_original'] == grupo_id)\n",
    "                df_categoria_completa.loc[mask, 'grupo_id_global'] = grupo_contador\n",
    "                grupo_contador += 1\n",
    "        \n",
    "        # Remover duplicatas (projetos que apareceram em mÃºltiplos sub-lotes)\n",
    "        df_final = df_categoria_completa.drop_duplicates(subset=['projeto_id'], keep='first')\n",
    "        \n",
    "        # Limpar colunas auxiliares\n",
    "        df_final = df_final.drop(['sublote_origem', 'grupo_id_original'], axis=1)\n",
    "        \n",
    "        grupos_finais = df_final[df_final['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "        projetos_agrupados = len(df_final[df_final['grupo_id_global'] > 0])\n",
    "        \n",
    "        logging.info(f\"âœ… Merge concluÃ­do para {categoria_key}:\")\n",
    "        logging.info(f\"   ğŸ“Š Projetos finais: {len(df_final)}\")\n",
    "        logging.info(f\"   ğŸ·ï¸ Grupos apÃ³s merge: {grupos_finais}\")\n",
    "        logging.info(f\"   ğŸ“ˆ Projetos agrupados: {projetos_agrupados}\")\n",
    "        \n",
    "        return {\n",
    "            'dataframe': df_final,\n",
    "            'categoria': categoria_key,\n",
    "            'grupos_finais': grupos_finais,\n",
    "            'projetos_totais': len(df_final),\n",
    "            'projetos_agrupados': projetos_agrupados,\n",
    "            'sublotes_originais': len(sublotes_categoria)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro no merge da categoria {categoria_key}: {e}\")\n",
    "        return None\n",
    "\n",
    "def consolidar_resultados_completos(resultados_processados, df_processado, grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    Consolida TODOS os resultados: multianuais automÃ¡ticos + grupos da LLM + merge de sub-lotes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"ğŸ”„ Iniciando consolidaÃ§Ã£o completa...\")\n",
    "        \n",
    "        # ETAPA 1: Processar merge dos sub-lotes (se necessÃ¡rio)\n",
    "        if resultados_processados:\n",
    "            resultados_merge = processar_merge_completo(resultados_processados)\n",
    "            logging.info(f\"âœ… Merge de sub-lotes concluÃ­do: {len(resultados_merge)} categorias\")\n",
    "        else:\n",
    "            resultados_merge = []\n",
    "            logging.info(\"â„¹ï¸ Nenhum resultado da LLM para fazer merge\")\n",
    "        \n",
    "        # ETAPA 2: Consolidar resultados da LLM\n",
    "        dataframes_llm = []\n",
    "        if resultados_merge:\n",
    "            for resultado in resultados_merge:\n",
    "                if 'dataframe' in resultado and resultado['dataframe'] is not None:\n",
    "                    df_temp = resultado['dataframe'].copy()\n",
    "                    df_temp['origem_agrupamento'] = 'LLM'\n",
    "                    df_temp['categoria_processamento'] = resultado.get('categoria', 'llm_categoria')\n",
    "                    dataframes_llm.append(df_temp)\n",
    "        \n",
    "        # ETAPA 3: Criar DataFrame dos grupos multianuais automÃ¡ticos\n",
    "        df_multianuais_completo = df_processado[df_processado['eh_multianual']].copy()\n",
    "        \n",
    "        if len(df_multianuais_completo) > 0:\n",
    "            # Mapear grupos multianuais para formato padrÃ£o\n",
    "            df_grupos_multianuais = []\n",
    "            \n",
    "            for grupo in grupos_multianuais:\n",
    "                grupo_id = grupo['grupo_id_multianual']\n",
    "                indices = grupo['indices_df']\n",
    "                \n",
    "                # Buscar registros do grupo no df_processado\n",
    "                registros_grupo = df_processado.loc[df_processado.index.isin(indices)]\n",
    "                \n",
    "                for idx, registro in registros_grupo.iterrows():\n",
    "                    # Extrair ID Ãºnico do projeto da coluna 'projeto'\n",
    "                    projeto_texto = str(registro.get('projeto', ''))\n",
    "                    \n",
    "                    # Buscar ID Ãºnico entre ' ID ÃšNICO: ' e ' NOME: '\n",
    "                    import re\n",
    "                    match_id = re.search(r'ID ÃšNICO:\\s*([^:]+?)\\s+NOME:', projeto_texto)\n",
    "                    \n",
    "                    if match_id:\n",
    "                        projeto_id = match_id.group(1).strip()\n",
    "                    else:\n",
    "                        # Fallback caso nÃ£o encontre o padrÃ£o\n",
    "                        projeto_id = f\"PROJ_{registro.get('id_empresa_ano', idx)}_{idx}\"\n",
    "                        logging.warning(f\"âš ï¸ ID Ãºnico nÃ£o encontrado para registro multianual {idx}, usando fallback\")\n",
    "                    \n",
    "                    grupo_row = {\n",
    "                        'grupo_id_global': grupo_id,\n",
    "                        'projeto_id': projeto_id,\n",
    "                        'ano_referencia': registro['ano_referencia'],\n",
    "                        'setor': registro['setor'],\n",
    "                        'natureza': registro['natureza'],\n",
    "                        'tipo_pesquisa': registro['tipo_pesquisa'],\n",
    "                        'origem_agrupamento': 'MULTIANUAL_AUTO',\n",
    "                        'categoria_processamento': f\"multianual_{registro['setor']}_{registro['natureza']}\",\n",
    "                        'grupo_multianual_id': grupo_id,\n",
    "                        'anos_grupo': registro['anos_grupo_multianual'],\n",
    "                        'empresa': registro.get('empresa', ''),\n",
    "                        'projeto': registro.get('projeto', '')\n",
    "                    }\n",
    "                    df_grupos_multianuais.append(grupo_row)\n",
    "            \n",
    "            df_multianuais_formatado = pd.DataFrame(df_grupos_multianuais)\n",
    "            logging.info(f\"âœ… Grupos multianuais formatados: {len(df_multianuais_formatado)} registros\")\n",
    "        else:\n",
    "            df_multianuais_formatado = pd.DataFrame()\n",
    "            logging.info(\"â„¹ï¸ Nenhum projeto multianual encontrado\")\n",
    "        \n",
    "        # ETAPA 4: Consolidar tudo\n",
    "        dataframes_finais = []\n",
    "        \n",
    "        # Adicionar resultados da LLM\n",
    "        if dataframes_llm:\n",
    "            dataframes_finais.extend(dataframes_llm)\n",
    "            logging.info(f\"âœ… Adicionados {len(dataframes_llm)} DataFrames da LLM\")\n",
    "        \n",
    "        # Adicionar grupos multianuais\n",
    "        if len(df_multianuais_formatado) > 0:\n",
    "            dataframes_finais.append(df_multianuais_formatado)\n",
    "            logging.info(f\"âœ… Adicionados grupos multianuais\")\n",
    "        \n",
    "        if not dataframes_finais:\n",
    "            logging.error(\"âŒ Nenhum resultado para consolidar\")\n",
    "            return None\n",
    "        \n",
    "        # Concatenar todos os resultados\n",
    "        df_consolidado_final = pd.concat(dataframes_finais, ignore_index=True, sort=False)\n",
    "        \n",
    "        # ETAPA 5: RenumeraÃ§Ã£o global dos grupos\n",
    "        df_consolidado_final['grupo_id_final'] = 0\n",
    "        contador_global = 1\n",
    "        \n",
    "        # Manter IDs multianuais como estÃ£o (jÃ¡ sÃ£o Ãºnicos)\n",
    "        mask_multianuais = df_consolidado_final['origem_agrupamento'] == 'MULTIANUAL_AUTO'\n",
    "        grupos_multianuais_unicos = df_consolidado_final[mask_multianuais]['grupo_id_global'].unique()\n",
    "        \n",
    "        # Mapear grupos multianuais\n",
    "        for grupo_multi in grupos_multianuais_unicos:\n",
    "            mask_grupo = mask_multianuais & (df_consolidado_final['grupo_id_global'] == grupo_multi)\n",
    "            df_consolidado_final.loc[mask_grupo, 'grupo_id_final'] = contador_global\n",
    "            contador_global += 1\n",
    "        \n",
    "        # Mapear grupos da LLM por categoria\n",
    "        mask_llm = df_consolidado_final['origem_agrupamento'] == 'LLM'\n",
    "        if mask_llm.any():\n",
    "            for categoria in df_consolidado_final[mask_llm]['categoria_processamento'].unique():\n",
    "                mask_categoria = mask_llm & (df_consolidado_final['categoria_processamento'] == categoria)\n",
    "                grupos_categoria = df_consolidado_final[mask_categoria & (df_consolidado_final['grupo_id_global'] > 0)]['grupo_id_global'].unique()\n",
    "                \n",
    "                for grupo_id in grupos_categoria:\n",
    "                    mask_grupo = mask_categoria & (df_consolidado_final['grupo_id_global'] == grupo_id)\n",
    "                    df_consolidado_final.loc[mask_grupo, 'grupo_id_final'] = contador_global\n",
    "                    contador_global += 1\n",
    "        \n",
    "        # ETAPA 6: Gerar estatÃ­sticas consolidadas\n",
    "        stats_consolidacao = {\n",
    "            'timestamp': timestamp,\n",
    "            'total_projetos': len(df_consolidado_final),\n",
    "            'projetos_multianuais_auto': len(df_consolidado_final[df_consolidado_final['origem_agrupamento'] == 'MULTIANUAL_AUTO']),\n",
    "            'projetos_llm': len(df_consolidado_final[df_consolidado_final['origem_agrupamento'] == 'LLM']),\n",
    "            'total_grupos_finais': df_consolidado_final[df_consolidado_final['grupo_id_final'] > 0]['grupo_id_final'].nunique(),\n",
    "            'projetos_agrupados_total': len(df_consolidado_final[df_consolidado_final['grupo_id_final'] > 0]),\n",
    "            'projetos_isolados': len(df_consolidado_final[df_consolidado_final['grupo_id_final'] == 0]),\n",
    "            'grupos_multianuais': len(grupos_multianuais_unicos) if mask_multianuais.any() else 0,\n",
    "            'grupos_llm': len(df_consolidado_final[mask_llm & (df_consolidado_final['grupo_id_final'] > 0)]['grupo_id_final'].unique()) if mask_llm.any() else 0\n",
    "        }\n",
    "        \n",
    "        stats_consolidacao['taxa_agrupamento_total'] = (stats_consolidacao['projetos_agrupados_total'] / stats_consolidacao['total_projetos']) * 100 if stats_consolidacao['total_projetos'] > 0 else 0\n",
    "        \n",
    "        logging.info(f\"ğŸ“Š ConsolidaÃ§Ã£o concluÃ­da:\")\n",
    "        logging.info(f\"   ğŸ“‹ Total de projetos: {stats_consolidacao['total_projetos']:,}\")\n",
    "        logging.info(f\"   ğŸ”— Projetos multianuais: {stats_consolidacao['projetos_multianuais_auto']:,}\")\n",
    "        logging.info(f\"   ğŸ¤– Projetos da LLM: {stats_consolidacao['projetos_llm']:,}\")\n",
    "        logging.info(f\"   ğŸ·ï¸ Grupos finais: {stats_consolidacao['total_grupos_finais']}\")\n",
    "        logging.info(f\"   ğŸ“ˆ Taxa de agrupamento: {stats_consolidacao['taxa_agrupamento_total']:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            'dataframe_consolidado': df_consolidado_final,\n",
    "            'estatisticas': stats_consolidacao\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro na consolidaÃ§Ã£o completa: {e}\")\n",
    "        return None\n",
    "\n",
    "def salvar_resultados_consolidados_finais(resultado_consolidacao, timestamp):\n",
    "    \"\"\"\n",
    "    Salva todos os resultados consolidados finais\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not resultado_consolidacao:\n",
    "            return None\n",
    "        \n",
    "        df_final = resultado_consolidacao['dataframe_consolidado']\n",
    "        stats = resultado_consolidacao['estatisticas']\n",
    "        \n",
    "        # Arquivo principal consolidado\n",
    "        arquivo_consolidado = f'resultados_agrupamento/GRUPOS_FINAL_COMPLETO_{timestamp}.csv'\n",
    "        df_final.to_csv(arquivo_consolidado, index=False, encoding='utf-8')\n",
    "        \n",
    "        # EstatÃ­sticas detalhadas\n",
    "        arquivo_stats = f'resultados_agrupamento/estatisticas_consolidacao_final_{timestamp}.json'\n",
    "        with open(arquivo_stats, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=2, ensure_ascii=False, default=str)\n",
    "        \n",
    "        # RelatÃ³rio resumido por origem\n",
    "        resumo_origem = df_final.groupby('origem_agrupamento').agg({\n",
    "            'grupo_id_final': lambda x: (x > 0).sum(),  # projetos agrupados\n",
    "            'projeto_id': 'count'  # total projetos\n",
    "        }).reset_index()\n",
    "        resumo_origem.columns = ['origem_agrupamento', 'projetos_agrupados', 'total_projetos']\n",
    "        resumo_origem['taxa_agrupamento'] = (resumo_origem['projetos_agrupados'] / resumo_origem['total_projetos']) * 100\n",
    "        \n",
    "        arquivo_resumo = f'resultados_agrupamento/resumo_por_origem_{timestamp}.csv'\n",
    "        resumo_origem.to_csv(arquivo_resumo, index=False, encoding='utf-8')\n",
    "        \n",
    "        # RelatÃ³rio de grupos por tamanho\n",
    "        distribuicao_grupos = df_final[df_final['grupo_id_final'] > 0].groupby('grupo_id_final').size().reset_index(name='tamanho_grupo')\n",
    "        distribuicao_stats = distribuicao_grupos['tamanho_grupo'].describe()\n",
    "        \n",
    "        arquivo_distribuicao = f'resultados_agrupamento/distribuicao_grupos_{timestamp}.csv'\n",
    "        distribuicao_grupos.to_csv(arquivo_distribuicao, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"ğŸ’¾ Resultados consolidados finais salvos:\")\n",
    "        logging.info(f\"   ğŸ“„ Arquivo principal: {arquivo_consolidado}\")\n",
    "        logging.info(f\"   ğŸ“Š EstatÃ­sticas: {arquivo_stats}\")\n",
    "        logging.info(f\"   ğŸ“‹ Resumo por origem: {arquivo_resumo}\")\n",
    "        logging.info(f\"   ğŸ“ˆ DistribuiÃ§Ã£o de grupos: {arquivo_distribuicao}\")\n",
    "        \n",
    "        return {\n",
    "            'arquivo_principal': arquivo_consolidado,\n",
    "            'estatisticas': arquivo_stats,\n",
    "            'resumo_origem': arquivo_resumo,\n",
    "            'distribuicao_grupos': arquivo_distribuicao,\n",
    "            'stats_distribuicao': distribuicao_stats.to_dict()\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao salvar resultados consolidados: {e}\")\n",
    "        return None\n",
    "\n",
    "# Preparar Chunk 8 adaptado\n",
    "print(\"\\nğŸ”„ Chunk 8 ADAPTADO: ConsolidaÃ§Ã£o Final com Multianuais + Merge\")\n",
    "print(\"ğŸ“‹ Este chunk integra:\")\n",
    "print(\"   ğŸ”— Grupos multianuais (ligaÃ§Ã£o automÃ¡tica)\")\n",
    "print(\"   ğŸ¤– Grupos da LLM (anÃ¡lise de similaridade)\")\n",
    "print(\"   ğŸ“¦ Merge de sub-lotes (unificaÃ§Ã£o inteligente)\")\n",
    "\n",
    "def executar_consolidacao_completa(resultados_processados, df_processado, grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    FunÃ§Ã£o principal para executar consolidaÃ§Ã£o completa\n",
    "    \"\"\"\n",
    "    if not any([resultados_processados, grupos_multianuais, df_processado is not None]):\n",
    "        print(\"âš ï¸ Nenhum resultado disponÃ­vel para consolidaÃ§Ã£o\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ”„ Iniciando consolidaÃ§Ã£o completa...\")\n",
    "    \n",
    "    # Consolidar todos os resultados\n",
    "    resultado_consolidacao = consolidar_resultados_completos(\n",
    "        resultados_processados, df_processado, grupos_multianuais, timestamp\n",
    "    )\n",
    "    \n",
    "    if resultado_consolidacao:\n",
    "        # Salvar resultados finais\n",
    "        arquivos_salvos = salvar_resultados_consolidados_finais(resultado_consolidacao, timestamp)\n",
    "        \n",
    "        stats = resultado_consolidacao['estatisticas']\n",
    "        print(f\"âœ… ConsolidaÃ§Ã£o completa concluÃ­da:\")\n",
    "        print(f\"   ğŸ“Š Total de projetos: {stats['total_projetos']:,}\")\n",
    "        print(f\"   ğŸ”— Multianuais automÃ¡ticos: {stats['projetos_multianuais_auto']:,}\")\n",
    "        print(f\"   ğŸ¤– Analisados por LLM: {stats['projetos_llm']:,}\")\n",
    "        print(f\"   ğŸ·ï¸ Grupos finais: {stats['total_grupos_finais']}\")\n",
    "        print(f\"   ğŸ“ˆ Taxa de agrupamento total: {stats['taxa_agrupamento_total']:.1f}%\")\n",
    "        \n",
    "        if arquivos_salvos:\n",
    "            print(f\"   ğŸ“„ Arquivo final: {arquivos_salvos['arquivo_principal']}\")\n",
    "        \n",
    "        return {\n",
    "            'resultado_consolidacao': resultado_consolidacao,\n",
    "            'arquivos_salvos': arquivos_salvos\n",
    "        }\n",
    "    else:\n",
    "        print(\"âŒ Falha na consolidaÃ§Ã£o completa\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Chunk 8 preparado - funÃ§Ãµes de consolidaÃ§Ã£o completa carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feda162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 9: ValidaÃ§Ã£o e Qualidade\n",
    "Valida a qualidade dos agrupamentos e gera mÃ©tricas de avaliaÃ§Ã£o\n",
    "\"\"\"\n",
    "\n",
    "def analisar_qualidade_grupos(df_consolidado, df_clean):\n",
    "    \"\"\"\n",
    "    Analisa a qualidade dos grupos formados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        relatorio_qualidade = {}\n",
    "        \n",
    "        # 1. AnÃ¡lise de distribuiÃ§Ã£o dos grupos\n",
    "        grupos_validos = df_consolidado[df_consolidado['grupo_id_global'] > 0]\n",
    "        distribuicao_tamanhos = grupos_validos.groupby('grupo_id_global').size()\n",
    "        \n",
    "        relatorio_qualidade['distribuicao_grupos'] = {\n",
    "            'total_grupos': len(distribuicao_tamanhos),\n",
    "            'tamanho_medio': distribuicao_tamanhos.mean(),\n",
    "            'tamanho_mediano': distribuicao_tamanhos.median(),\n",
    "            'maior_grupo': distribuicao_tamanhos.max(),\n",
    "            'menor_grupo': distribuicao_tamanhos.min(),\n",
    "            'grupos_por_tamanho': distribuicao_tamanhos.value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # 2. AnÃ¡lise por setor/categoria\n",
    "        analise_categorias = []\n",
    "        for (setor, natureza, tipo), grupo_cat in df_consolidado.groupby(['setor', 'natureza', 'tipo_pesquisa']):\n",
    "            grupos_formados = grupo_cat[grupo_cat['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "            taxa_agrupamento = len(grupo_cat[grupo_cat['grupo_id_global'] > 0]) / len(grupo_cat) * 100\n",
    "            \n",
    "            analise_cat = {\n",
    "                'setor': setor,\n",
    "                'natureza': natureza,\n",
    "                'tipo_pesquisa': tipo,\n",
    "                'total_projetos': len(grupo_cat),\n",
    "                'grupos_formados': grupos_formados,\n",
    "                'projetos_agrupados': len(grupo_cat[grupo_cat['grupo_id_global'] > 0]),\n",
    "                'taxa_agrupamento': taxa_agrupamento,\n",
    "                'eficiencia_agrupamento': grupos_formados / len(grupo_cat) if len(grupo_cat) > 0 else 0\n",
    "            }\n",
    "            analise_categorias.append(analise_cat)\n",
    "        \n",
    "        relatorio_qualidade['analise_por_categoria'] = analise_categorias\n",
    "        \n",
    "        # 3. DetecÃ§Ã£o de possÃ­veis problemas\n",
    "        problemas_detectados = []\n",
    "        \n",
    "        # Grupos muito grandes (possÃ­vel super-agrupamento)\n",
    "        grupos_grandes = distribuicao_tamanhos[distribuicao_tamanhos > 10]\n",
    "        if len(grupos_grandes) > 0:\n",
    "            problemas_detectados.append({\n",
    "                'tipo': 'super_agrupamento',\n",
    "                'descricao': f'{len(grupos_grandes)} grupos com mais de 10 projetos',\n",
    "                'grupos_afetados': grupos_grandes.index.tolist()\n",
    "            })\n",
    "        \n",
    "        # Taxa de agrupamento muito baixa por categoria\n",
    "        categorias_baixa_taxa = [cat for cat in analise_categorias if cat['taxa_agrupamento'] < 20]\n",
    "        if categorias_baixa_taxa:\n",
    "            problemas_detectados.append({\n",
    "                'tipo': 'baixa_taxa_agrupamento',\n",
    "                'descricao': f'{len(categorias_baixa_taxa)} categorias com taxa < 20%',\n",
    "                'categorias_afetadas': categorias_baixa_taxa\n",
    "            })\n",
    "        \n",
    "        relatorio_qualidade['problemas_detectados'] = problemas_detectados\n",
    "        \n",
    "        logging.info(f\"ğŸ“Š Qualidade analisada: {len(distribuicao_tamanhos)} grupos vÃ¡lidos\")\n",
    "        logging.info(f\"âš ï¸ Problemas detectados: {len(problemas_detectados)}\")\n",
    "        \n",
    "        return relatorio_qualidade\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro na anÃ¡lise de qualidade: {e}\")\n",
    "        return None\n",
    "\n",
    "def gerar_amostras_grupos(df_consolidado, df_clean, num_amostras=5):\n",
    "    \"\"\"\n",
    "    Gera amostras de grupos para validaÃ§Ã£o manual\n",
    "    \"\"\"\n",
    "    try:\n",
    "        amostras = []\n",
    "        grupos_validos = df_consolidado[df_consolidado['grupo_id_global'] > 0]\n",
    "        \n",
    "        # Selecionar grupos de diferentes tamanhos\n",
    "        distribuicao_tamanhos = grupos_validos.groupby('grupo_id_global').size()\n",
    "        grupos_pequenos = distribuicao_tamanhos[distribuicao_tamanhos == 2].head(2).index\n",
    "        grupos_medios = distribuicao_tamanhos[(distribuicao_tamanhos >= 3) & (distribuicao_tamanhos <= 5)].head(2).index\n",
    "        grupos_grandes = distribuicao_tamanhos[distribuicao_tamanhos > 5].head(1).index\n",
    "        \n",
    "        grupos_amostra = list(grupos_pequenos) + list(grupos_medios) + list(grupos_grandes)\n",
    "        \n",
    "        for grupo_id in grupos_amostra[:num_amostras]:\n",
    "            projetos_grupo = grupos_validos[grupos_validos['grupo_id_global'] == grupo_id]\n",
    "            \n",
    "            # Buscar detalhes dos projetos no DataFrame original\n",
    "            detalhes_projetos = []\n",
    "            for _, projeto in projetos_grupo.iterrows():\n",
    "                # Tentar encontrar projeto correspondente no df_clean\n",
    "                projeto_id = projeto['projeto_id']\n",
    "                \n",
    "                # Buscar no df_clean (pode precisar ajustar a lÃ³gica de matching)\n",
    "                projeto_detalhes = {\n",
    "                    'projeto_id': projeto_id,\n",
    "                    'setor': projeto['setor'],\n",
    "                    'natureza': projeto['natureza'],\n",
    "                    'tipo_pesquisa': projeto['tipo_pesquisa'],\n",
    "                    'ano': projeto['ano_referencia']\n",
    "                }\n",
    "                \n",
    "                # Tentar buscar projeto completo (simplificado para exemplo)\n",
    "                try:\n",
    "                    # Aqui vocÃª pode implementar lÃ³gica mais sofisticada de matching\n",
    "                    matches = df_clean[\n",
    "                        (df_clean['setor'] == projeto['setor']) &\n",
    "                        (df_clean['ano_referencia'] == projeto['ano_referencia'])\n",
    "                    ]\n",
    "                    if len(matches) > 0:\n",
    "                        primeiro_match = matches.iloc[0]\n",
    "                        projeto_detalhes['projeto_preview'] = primeiro_match['projeto'][:200] + '...'\n",
    "                        projeto_detalhes['resultados_preview'] = str(primeiro_match.get('projeto_resultados', ''))[:150] + '...'\n",
    "                except:\n",
    "                    projeto_detalhes['projeto_preview'] = 'Detalhes nÃ£o encontrados'\n",
    "                    projeto_detalhes['resultados_preview'] = 'N/A'\n",
    "                \n",
    "                detalhes_projetos.append(projeto_detalhes)\n",
    "            \n",
    "            amostra = {\n",
    "                'grupo_id': int(grupo_id),\n",
    "                'tamanho_grupo': len(projetos_grupo),\n",
    "                'combinacao': {\n",
    "                    'setor': projetos_grupo.iloc[0]['setor'],\n",
    "                    'natureza': projetos_grupo.iloc[0]['natureza'],\n",
    "                    'tipo_pesquisa': projetos_grupo.iloc[0]['tipo_pesquisa'],\n",
    "                    'ano': projetos_grupo.iloc[0]['ano_referencia']\n",
    "                },\n",
    "                'projetos': detalhes_projetos\n",
    "            }\n",
    "            amostras.append(amostra)\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ Geradas {len(amostras)} amostras para validaÃ§Ã£o\")\n",
    "        return amostras\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao gerar amostras: {e}\")\n",
    "        return []\n",
    "\n",
    "def calcular_metricas_agrupamento(df_consolidado):\n",
    "    \"\"\"\n",
    "    Calcula mÃ©tricas quantitativas do agrupamento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metricas = {}\n",
    "        \n",
    "        total_projetos = len(df_consolidado)\n",
    "        projetos_agrupados = len(df_consolidado[df_consolidado['grupo_id_global'] > 0])\n",
    "        total_grupos = df_consolidado[df_consolidado['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "        \n",
    "        # MÃ©tricas bÃ¡sicas\n",
    "        metricas['cobertura'] = projetos_agrupados / total_projetos if total_projetos > 0 else 0\n",
    "        metricas['densidade_media'] = projetos_agrupados / total_grupos if total_grupos > 0 else 0\n",
    "        metricas['eficiencia'] = total_grupos / total_projetos if total_projetos > 0 else 0\n",
    "        \n",
    "        # DistribuiÃ§Ã£o por tamanho\n",
    "        distribuicao = df_consolidado[df_consolidado['grupo_id_global'] > 0].groupby('grupo_id_global').size()\n",
    "        metricas['coeficiente_variacao_tamanho'] = distribuicao.std() / distribuicao.mean() if distribuicao.mean() > 0 else 0\n",
    "        \n",
    "        # MÃ©tricas por categoria\n",
    "        metricas_por_categoria = {}\n",
    "        for (setor, natureza), grupo_cat in df_consolidado.groupby(['setor', 'natureza']):\n",
    "            cat_key = f\"{setor}_{natureza}\"\n",
    "            grupos_cat = grupo_cat[grupo_cat['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "            projetos_cat = len(grupo_cat)\n",
    "            \n",
    "            metricas_por_categoria[cat_key] = {\n",
    "                'total_projetos': projetos_cat,\n",
    "                'grupos_formados': grupos_cat,\n",
    "                'taxa_agrupamento': len(grupo_cat[grupo_cat['grupo_id_global'] > 0]) / projetos_cat if projetos_cat > 0 else 0,\n",
    "                'produtividade': grupos_cat / projetos_cat if projetos_cat > 0 else 0\n",
    "            }\n",
    "        \n",
    "        metricas['por_categoria'] = metricas_por_categoria\n",
    "        \n",
    "        logging.info(f\"ğŸ“Š MÃ©tricas calculadas:\")\n",
    "        logging.info(f\"   ğŸ“ˆ Cobertura: {metricas['cobertura']:.2%}\")\n",
    "        logging.info(f\"   ğŸ¯ Densidade mÃ©dia: {metricas['densidade_media']:.1f} projetos/grupo\")\n",
    "        logging.info(f\"   âš¡ EficiÃªncia: {metricas['eficiencia']:.3f}\")\n",
    "        \n",
    "        return metricas\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao calcular mÃ©tricas: {e}\")\n",
    "        return None\n",
    "\n",
    "def gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp):\n",
    "    \"\"\"\n",
    "    Gera relatÃ³rio completo de validaÃ§Ã£o\n",
    "    \"\"\"\n",
    "    try:\n",
    "        relatorio_completo = {\n",
    "            'metadata': {\n",
    "                'timestamp_geracao': datetime.now().isoformat(),\n",
    "                'timestamp_processamento': timestamp,\n",
    "                'versao_relatorio': '1.0'\n",
    "            },\n",
    "            'qualidade': relatorio_qualidade,\n",
    "            'metricas': metricas,\n",
    "            'amostras_validacao': amostras,\n",
    "            'recomendacoes': []\n",
    "        }\n",
    "        \n",
    "        # Gerar recomendaÃ§Ãµes baseadas na anÃ¡lise\n",
    "        recomendacoes = []\n",
    "        \n",
    "        if metricas and metricas['cobertura'] < 0.5:\n",
    "            recomendacoes.append({\n",
    "                'tipo': 'baixa_cobertura',\n",
    "                'descricao': f\"Cobertura de agrupamento baixa ({metricas['cobertura']:.1%}). Considere relaxar critÃ©rios de similaridade.\",\n",
    "                'prioridade': 'alta'\n",
    "            })\n",
    "        \n",
    "        if metricas and metricas['densidade_media'] > 8:\n",
    "            recomendacoes.append({\n",
    "                'tipo': 'grupos_grandes',\n",
    "                'descricao': f\"Grupos muito grandes (mÃ©dia {metricas['densidade_media']:.1f}). Considere critÃ©rios mais rigorosos.\",\n",
    "                'prioridade': 'media'\n",
    "            })\n",
    "        \n",
    "        if relatorio_qualidade and 'problemas_detectados' in relatorio_qualidade:\n",
    "            for problema in relatorio_qualidade['problemas_detectados']:\n",
    "                if problema['tipo'] == 'super_agrupamento':\n",
    "                    recomendacoes.append({\n",
    "                        'tipo': 'revisao_manual',\n",
    "                        'descricao': f\"Revisar manualmente grupos com >10 projetos: {problema['grupos_afetados']}\",\n",
    "                        'prioridade': 'alta'\n",
    "                    })\n",
    "        \n",
    "        relatorio_completo['recomendacoes'] = recomendacoes\n",
    "        \n",
    "        # Salvar relatÃ³rio\n",
    "        arquivo_relatorio = f'resultados_agrupamento/relatorio_validacao_{timestamp}.json'\n",
    "        with open(arquivo_relatorio, 'w', encoding='utf-8') as f:\n",
    "            json.dump(relatorio_completo, f, indent=2, ensure_ascii=False, default=str)\n",
    "        \n",
    "        # Gerar versÃ£o resumida em texto\n",
    "        arquivo_resumo = f'resultados_agrupamento/resumo_validacao_{timestamp}.txt'\n",
    "        with open(arquivo_resumo, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"RELATÃ“RIO DE VALIDAÃ‡ÃƒO - AGRUPAMENTO DE PROJETOS\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            if metricas:\n",
    "                f.write(\"MÃ‰TRICAS PRINCIPAIS:\\n\")\n",
    "                f.write(f\"â€¢ Cobertura: {metricas['cobertura']:.1%}\\n\")\n",
    "                f.write(f\"â€¢ Densidade mÃ©dia: {metricas['densidade_media']:.1f} projetos/grupo\\n\")\n",
    "                f.write(f\"â€¢ EficiÃªncia: {metricas['eficiencia']:.3f}\\n\\n\")\n",
    "            \n",
    "            if relatorio_qualidade:\n",
    "                dist = relatorio_qualidade['distribuicao_grupos']\n",
    "                f.write(\"DISTRIBUIÃ‡ÃƒO DOS GRUPOS:\\n\")\n",
    "                f.write(f\"â€¢ Total de grupos: {dist['total_grupos']}\\n\")\n",
    "                f.write(f\"â€¢ Tamanho mÃ©dio: {dist['tamanho_medio']:.1f}\\n\")\n",
    "                f.write(f\"â€¢ Maior grupo: {dist['maior_grupo']} projetos\\n\\n\")\n",
    "            \n",
    "            if recomendacoes:\n",
    "                f.write(\"RECOMENDAÃ‡Ã•ES:\\n\")\n",
    "                for i, rec in enumerate(recomendacoes, 1):\n",
    "                    f.write(f\"{i}. [{rec['prioridade'].upper()}] {rec['descricao']}\\n\")\n",
    "        \n",
    "        logging.info(f\"ğŸ“‹ RelatÃ³rio de validaÃ§Ã£o salvo: {arquivo_relatorio}\")\n",
    "        logging.info(f\"ğŸ“„ Resumo salvo: {arquivo_resumo}\")\n",
    "        \n",
    "        return {\n",
    "            'relatorio_completo': arquivo_relatorio,\n",
    "            'resumo': arquivo_resumo,\n",
    "            'recomendacoes': recomendacoes\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"âŒ Erro ao gerar relatÃ³rio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar validaÃ§Ã£o e qualidade\n",
    "print(\"\\nğŸ”„ Executando Chunk 9: ValidaÃ§Ã£o e Qualidade\")\n",
    "\n",
    "if 'df_consolidado' in locals() and df_consolidado is not None and 'df_clean' in locals():\n",
    "    print(\"ğŸ” Analisando qualidade dos agrupamentos...\")\n",
    "    \n",
    "    # AnÃ¡lise de qualidade\n",
    "    relatorio_qualidade = analisar_qualidade_grupos(df_consolidado, df_clean)\n",
    "    \n",
    "    # CÃ¡lculo de mÃ©tricas\n",
    "    metricas = calcular_metricas_agrupamento(df_consolidado)\n",
    "    \n",
    "    # GeraÃ§Ã£o de amostras\n",
    "    amostras = gerar_amostras_grupos(df_consolidado, df_clean)\n",
    "    \n",
    "    # RelatÃ³rio de validaÃ§Ã£o\n",
    "    if 'timestamp_final' in locals():\n",
    "        relatorio_final = gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp_final)\n",
    "    else:\n",
    "        timestamp_validacao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        relatorio_final = gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp_validacao)\n",
    "    \n",
    "    print(f\"âœ… Chunk 9 executado:\")\n",
    "    if metricas:\n",
    "        print(f\"   ğŸ“ˆ Cobertura: {metricas['cobertura']:.1%}\")\n",
    "        print(f\"   ğŸ¯ Densidade: {metricas['densidade_media']:.1f} proj/grupo\")\n",
    "    if relatorio_qualidade:\n",
    "        print(f\"   ğŸ·ï¸ Grupos vÃ¡lidos: {relatorio_qualidade['distribuicao_grupos']['total_grupos']}\")\n",
    "    print(f\"   ğŸ“‹ Amostras geradas: {len(amostras)}\")\n",
    "    if relatorio_final and 'recomendacoes' in relatorio_final:\n",
    "        print(f\"   ğŸ’¡ RecomendaÃ§Ãµes: {len(relatorio_final['recomendacoes'])}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Chunk 9 ignorado: Dados consolidados nÃ£o disponÃ­veis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa2b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
