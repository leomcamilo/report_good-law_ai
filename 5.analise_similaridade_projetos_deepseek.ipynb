{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1594ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Arquivo carregado: 75348 registros encontrados\n",
      "📋 Colunas disponíveis: 50\n",
      "📄 Arquivo: csv_longo/projetos_lei_do_bem_JUSTIFICATIVAS_RESULTADOS_PESSOAS.csv\n",
      "✅ Todas as colunas necessárias encontradas\n",
      "✅ Chunk 1 executado: Imports, configurações e dados carregados\n",
      "📁 Colunas de identificação: ['id_empresa_ano', 'empresa', 'ano_referencia']\n",
      "🔍 Colunas para análise: ['setor', 'natureza', 'tipo_pesquisa', 'projeto', 'projeto_resultados']\n",
      "📊 Colunas de avaliação: ['do_resultado_analise', 'p_resultado_analise']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1204575/2852269188.py:33: DtypeWarning: Columns (25,26,32,34,35,36,39,41,43,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 1: Estrutura Geral do Programa e Imports\n",
    "Configuração inicial e carregamento do arquivo CSV principal\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('agrupamento_projetos.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Carregar arquivo CSV principal\n",
    "arquivo_dados = 'csv_longo/projetos_lei_do_bem_JUSTIFICATIVAS_RESULTADOS_PESSOAS.csv'\n",
    "df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n",
    "\n",
    "print(f\"📊 Arquivo carregado: {len(df)} registros encontrados\")\n",
    "print(f\"📋 Colunas disponíveis: {len(df.columns)}\")\n",
    "print(f\"📄 Arquivo: {arquivo_dados}\")\n",
    "\n",
    "# Definir colunas baseadas na estrutura do CSV carregado\n",
    "colunas_identificacao = [\n",
    "    'id_empresa_ano', 'empresa', 'ano_referencia'\n",
    "]\n",
    "\n",
    "colunas_analise = [\n",
    "    'setor', 'natureza', 'tipo_pesquisa', 'projeto', 'projeto_resultados'\n",
    "]\n",
    "\n",
    "colunas_avaliacao = [\n",
    "    'do_resultado_analise', 'p_resultado_analise'\n",
    "]\n",
    "\n",
    "# Configurações globais\n",
    "LIMITE_PROJETOS_POR_LOTE = 50\n",
    "TEMPO_PAUSA_ENTRE_REQUESTS = 2\n",
    "MAX_TENTATIVAS = 3\n",
    "\n",
    "# Verificar se as colunas necessárias existem\n",
    "colunas_faltando = [col for col in colunas_analise if col not in df.columns]\n",
    "if colunas_faltando:\n",
    "    print(f\"⚠️ Colunas não encontradas: {colunas_faltando}\")\n",
    "    print(f\"📋 Colunas disponíveis no CSV: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"✅ Todas as colunas necessárias encontradas\")\n",
    "\n",
    "print(\"✅ Chunk 1 executado: Imports, configurações e dados carregados\")\n",
    "print(f\"📁 Colunas de identificação: {colunas_identificacao}\")\n",
    "print(f\"🔍 Colunas para análise: {colunas_analise}\")\n",
    "print(f\"📊 Colunas de avaliação: {colunas_avaliacao}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c589c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:14:39,544 - INFO - 📊 Dados iniciais limpos: 74466 registros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executando Chunk 2 ADAPTADO: Preparação com Ligação Automática de Projetos Multianuais\n",
      "🧪 MODO TESTE ATIVADO - Processando apenas categoria: 'Química e Farmácia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:14:40,213 - INFO - 📊 Dados extraídos:\n",
      "2025-08-11 17:14:40,220 - INFO -    📋 CNPJs únicos: 5717\n",
      "2025-08-11 17:14:40,222 - INFO -    🏢 Razões sociais únicas: 0\n",
      "2025-08-11 17:14:40,269 - INFO -    📄 Projetos multianuais: 54529\n",
      "2025-08-11 17:14:40,284 - INFO - ℹ️ Nenhum projeto multianual encontrado\n",
      "2025-08-11 17:14:40,380 - INFO - ✅ Ligação automática aplicada:\n",
      "2025-08-11 17:14:40,381 - INFO -    🔗 Projetos ligados automaticamente: 0\n",
      "2025-08-11 17:14:40,382 - INFO -    📊 Grupos multianuais criados: 0\n",
      "2025-08-11 17:14:40,548 - INFO - 🧪 FILTRO TESTE aplicado:\n",
      "2025-08-11 17:14:40,550 - INFO -    🎯 Categoria selecionada: 'Química e Farmácia'\n",
      "2025-08-11 17:14:40,550 - INFO -    📊 Combinações antes do filtro: 63\n",
      "2025-08-11 17:14:40,551 - INFO -    📊 Combinações após filtro: 9\n",
      "2025-08-11 17:14:40,552 - INFO - 📋 Resumo da preparação:\n",
      "2025-08-11 17:14:40,552 - INFO -    📊 Total de registros processados: 74466\n",
      "2025-08-11 17:14:40,554 - INFO -    🔗 Registros multianuais (já ligados): 0\n",
      "2025-08-11 17:14:40,555 - INFO -    🤖 Registros para LLM analisar: 74466\n",
      "2025-08-11 17:14:40,555 - INFO -    🏷️ Categorias para LLM processar: 9\n",
      "2025-08-11 17:14:40,556 - INFO -    📊 Maior categoria para LLM: 8172 projetos\n",
      "2025-08-11 17:14:40,557 - INFO -    📊 Média de projetos por categoria: 1182.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 2 adaptado executado:\n",
      "   📊 Total processado: 74,466 registros\n",
      "   🔗 Projetos multianuais ligados: 0\n",
      "   🤖 Projetos para LLM: 74,466\n",
      "   🏷️ Categorias para LLM: 9\n",
      "   🧪 MODO TESTE: Apenas categoria 'Química e Farmácia'\n",
      "   📊 Projetos a serem processados no teste: 14229\n",
      "   📄 Relatório salvo: None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 2: Preparação dos Dados\n",
    "Carrega o CSV e prepara os dados para processamento\n",
    "\"\"\"\n",
    "\n",
    "def extrair_dados_empresa_projeto(df):\n",
    "    \"\"\"\n",
    "    Extrai CNPJ, Razão Social e Nome do Projeto das colunas concatenadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_temp = df.copy()\n",
    "        \n",
    "        # Extrair CNPJ da coluna 'empresa'\n",
    "        df_temp['cnpj_extraido'] = df_temp['empresa'].str.extract(r'CNPJ:\\s*([0-9/.]+)')\n",
    "        \n",
    "        # Extrair Razão Social da coluna 'empresa'\n",
    "        df_temp['razao_social_extraida'] = df_temp['empresa'].str.extract(r'RAZÃO SOCIAL:\\s*([^:]+?)(?:\\s+ATIVIDADE ECONOMICA|$)')\n",
    "        \n",
    "        # Extrair Nome do Projeto da coluna 'projeto'\n",
    "        df_temp['nome_projeto_extraido'] = df_temp['projeto'].str.extract(r'NOME:\\s*([^:]+?)(?:\\s+DESCRIÇÂO|$)')\n",
    "        \n",
    "        # Extrair indicador de ciclo multianual\n",
    "        df_temp['ciclo_multianual'] = df_temp['projeto_multianual'].str.extract(r'CICLO MAIOR QUE 1 ANO:\\s*([^:]+?)(?:\\s+ATIVIDADE PDI|$)')\n",
    "        \n",
    "        # Limpar espaços em branco\n",
    "        for col in ['cnpj_extraido', 'razao_social_extraida', 'nome_projeto_extraido', 'ciclo_multianual']:\n",
    "            if col in df_temp.columns:\n",
    "                df_temp[col] = df_temp[col].str.strip()\n",
    "        \n",
    "        logging.info(f\"📊 Dados extraídos:\")\n",
    "        logging.info(f\"   📋 CNPJs únicos: {df_temp['cnpj_extraido'].nunique()}\")\n",
    "        logging.info(f\"   🏢 Razões sociais únicas: {df_temp['razao_social_extraida'].nunique()}\")\n",
    "        logging.info(f\"   📄 Projetos multianuais: {len(df_temp[df_temp['ciclo_multianual'] == 'Sim'])}\")\n",
    "        \n",
    "        return df_temp\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao extrair dados: {e}\")\n",
    "        return df\n",
    "\n",
    "def identificar_projetos_multianuais(df_temp):\n",
    "    \"\"\"\n",
    "    Identifica grupos de projetos multianuais que devem ser ligados automaticamente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrar apenas projetos multianuais válidos\n",
    "        projetos_multianuais = df_temp[\n",
    "            (df_temp['ciclo_multianual'] == 'Sim') &\n",
    "            (df_temp['cnpj_extraido'].notna()) &\n",
    "            (df_temp['razao_social_extraida'].notna()) &\n",
    "            (df_temp['nome_projeto_extraido'].notna())\n",
    "        ].copy()\n",
    "        \n",
    "        if len(projetos_multianuais) == 0:\n",
    "            logging.info(\"ℹ️ Nenhum projeto multianual encontrado\")\n",
    "            return []\n",
    "        \n",
    "        # Agrupar por CNPJ + Razão Social + Nome do Projeto\n",
    "        grupos_multianuais = projetos_multianuais.groupby([\n",
    "            'cnpj_extraido', 'razao_social_extraida', 'nome_projeto_extraido'\n",
    "        ])\n",
    "        \n",
    "        grupos_identificados = []\n",
    "        grupo_id_multianual = 1\n",
    "        \n",
    "        for (cnpj, razao, nome_proj), grupo in grupos_multianuais:\n",
    "            if len(grupo) > 1:  # Apenas grupos com múltiplos anos\n",
    "                anos_projeto = sorted(grupo['ano_referencia'].unique())\n",
    "                indices_projeto = grupo.index.tolist()\n",
    "                \n",
    "                grupo_info = {\n",
    "                    'grupo_id_multianual': f\"MULTI_{grupo_id_multianual:04d}\",\n",
    "                    'cnpj': cnpj,\n",
    "                    'razao_social': razao,\n",
    "                    'nome_projeto': nome_proj,\n",
    "                    'anos': anos_projeto,\n",
    "                    'indices_df': indices_projeto,\n",
    "                    'total_registros': len(grupo)\n",
    "                }\n",
    "                grupos_identificados.append(grupo_info)\n",
    "                grupo_id_multianual += 1\n",
    "        \n",
    "        logging.info(f\"🔗 Projetos multianuais identificados:\")\n",
    "        logging.info(f\"   📊 Grupos multianuais: {len(grupos_identificados)}\")\n",
    "        logging.info(f\"   📋 Total de registros multianuais: {sum(g['total_registros'] for g in grupos_identificados)}\")\n",
    "        \n",
    "        # Mostrar alguns exemplos\n",
    "        for i, grupo in enumerate(grupos_identificados[:3]):\n",
    "            logging.info(f\"   📄 Exemplo {i+1}: {grupo['nome_projeto'][:50]}... ({len(grupo['anos'])} anos: {grupo['anos']})\")\n",
    "        \n",
    "        return grupos_identificados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao identificar projetos multianuais: {e}\")\n",
    "        return []\n",
    "\n",
    "def aplicar_ligacao_automatica(df_temp, grupos_multianuais):\n",
    "    \"\"\"\n",
    "    Aplica ligação automática aos projetos multianuais identificados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_processado = df_temp.copy()\n",
    "        df_processado['grupo_multianual'] = None\n",
    "        df_processado['eh_multianual'] = False\n",
    "        df_processado['anos_grupo_multianual'] = None\n",
    "        \n",
    "        total_projetos_ligados = 0\n",
    "        \n",
    "        for grupo in grupos_multianuais:\n",
    "            grupo_id = grupo['grupo_id_multianual']\n",
    "            indices = grupo['indices_df']\n",
    "            anos_str = ', '.join(map(str, grupo['anos']))\n",
    "            \n",
    "            # Marcar todos os registros do grupo\n",
    "            df_processado.loc[indices, 'grupo_multianual'] = grupo_id\n",
    "            df_processado.loc[indices, 'eh_multianual'] = True\n",
    "            df_processado.loc[indices, 'anos_grupo_multianual'] = anos_str\n",
    "            \n",
    "            total_projetos_ligados += len(indices)\n",
    "        \n",
    "        logging.info(f\"✅ Ligação automática aplicada:\")\n",
    "        logging.info(f\"   🔗 Projetos ligados automaticamente: {total_projetos_ligados}\")\n",
    "        logging.info(f\"   📊 Grupos multianuais criados: {len(grupos_multianuais)}\")\n",
    "        \n",
    "        return df_processado\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao aplicar ligação automática: {e}\")\n",
    "        return df_temp\n",
    "\n",
    "def preparar_dados_com_multianual(df):\n",
    "    \"\"\"\n",
    "    Prepara dados identificando projetos multianuais e aplicando ligação automática\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrar apenas registros com dados essenciais\n",
    "        df_clean = df.dropna(subset=['projeto', 'setor', 'natureza', 'tipo_pesquisa'])\n",
    "        df_clean = df_clean[df_clean['projeto'].str.len() > 50]\n",
    "        \n",
    "        logging.info(f\"📊 Dados iniciais limpos: {len(df_clean)} registros\")\n",
    "        \n",
    "        # Extrair dados estruturados\n",
    "        df_temp = extrair_dados_empresa_projeto(df_clean)\n",
    "        \n",
    "        # Identificar projetos multianuais\n",
    "        grupos_multianuais = identificar_projetos_multianuais(df_temp)\n",
    "        \n",
    "        # Aplicar ligação automática\n",
    "        df_processado = aplicar_ligacao_automatica(df_temp, grupos_multianuais)\n",
    "        \n",
    "        # Preparar para agrupamento por LLM apenas dos projetos NÃO multianuais\n",
    "        df_para_llm = df_processado[~df_processado['eh_multianual']].copy()\n",
    "        \n",
    "        # Obter combinações únicas (setor + tipo_pesquisa + natureza) dos projetos para LLM\n",
    "        combinacoes = df_para_llm.groupby([\n",
    "            'setor', 'tipo_pesquisa', 'natureza'\n",
    "        ]).size().reset_index(name='count')\n",
    "        \n",
    "        # Filtrar combinações com pelo menos 3 projetos\n",
    "        combinacoes_validas = combinacoes[combinacoes['count'] >= 3]\n",
    "        \n",
    "        # APLICAR FILTRO DE TESTE POR CATEGORIA (se ativo)\n",
    "        if CATEGORIA_TESTE_API and isinstance(CATEGORIA_TESTE_API, str):\n",
    "            combinacoes_original = len(combinacoes_validas)\n",
    "            combinacoes_validas = combinacoes_validas[\n",
    "                combinacoes_validas['setor'] == CATEGORIA_TESTE_API\n",
    "            ]\n",
    "            logging.info(f\"🧪 FILTRO TESTE aplicado:\")\n",
    "            logging.info(f\"   🎯 Categoria selecionada: '{CATEGORIA_TESTE_API}'\")\n",
    "            logging.info(f\"   📊 Combinações antes do filtro: {combinacoes_original}\")\n",
    "            logging.info(f\"   📊 Combinações após filtro: {len(combinacoes_validas)}\")\n",
    "            \n",
    "            if len(combinacoes_validas) == 0:\n",
    "                logging.warning(f\"⚠️ Nenhuma combinação encontrada para categoria '{CATEGORIA_TESTE_API}'\")\n",
    "                categorias_disponiveis = df_para_llm['setor'].unique()[:10]  # Primeiras 10\n",
    "                logging.info(f\"📋 Categorias disponíveis (primeiras 10): {list(categorias_disponiveis)}\")\n",
    "        \n",
    "        logging.info(f\"📋 Resumo da preparação:\")\n",
    "        logging.info(f\"   📊 Total de registros processados: {len(df_processado)}\")\n",
    "        logging.info(f\"   🔗 Registros multianuais (já ligados): {len(df_processado[df_processado['eh_multianual']])}\")\n",
    "        logging.info(f\"   🤖 Registros para LLM analisar: {len(df_para_llm)}\")\n",
    "        logging.info(f\"   🏷️ Categorias para LLM processar: {len(combinacoes_validas)}\")\n",
    "        \n",
    "        if len(combinacoes_validas) > 0:\n",
    "            logging.info(f\"   📊 Maior categoria para LLM: {combinacoes['count'].max()} projetos\")\n",
    "            logging.info(f\"   📊 Média de projetos por categoria: {combinacoes['count'].mean():.1f}\")\n",
    "        \n",
    "        return df_processado, df_para_llm, combinacoes_validas, grupos_multianuais\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro na preparação com multianual: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def salvar_relatorio_multianuais(grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    Salva relatório detalhado dos projetos multianuais identificados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not grupos_multianuais:\n",
    "            return None\n",
    "        \n",
    "        # Criar DataFrame com informações dos grupos\n",
    "        relatorio_data = []\n",
    "        for grupo in grupos_multianuais:\n",
    "            relatorio_data.append({\n",
    "                'grupo_id_multianual': grupo['grupo_id_multianual'],\n",
    "                'cnpj': grupo['cnpj'],\n",
    "                'razao_social': grupo['razao_social'],\n",
    "                'nome_projeto': grupo['nome_projeto'],\n",
    "                'anos_projeto': ', '.join(map(str, grupo['anos'])),\n",
    "                'total_anos': len(grupo['anos']),\n",
    "                'total_registros': grupo['total_registros']\n",
    "            })\n",
    "        \n",
    "        df_relatorio = pd.DataFrame(relatorio_data)\n",
    "        arquivo_relatorio = f'resultados_agrupamento/projetos_multianuais_identificados_{timestamp}.csv'\n",
    "        df_relatorio.to_csv(arquivo_relatorio, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"📄 Relatório de multianuais salvo: {arquivo_relatorio}\")\n",
    "        return arquivo_relatorio\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao salvar relatório de multianuais: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configuração para teste limitado por categoria\n",
    "CATEGORIA_TESTE_API = \"Química e Farmácia\"  # Mudar para False para processar todas as categorias\n",
    "# CATEGORIA_TESTE_API = False  # Descomente esta linha para processar tudo\n",
    "\n",
    "# Executar preparação com identificação de multianuais\n",
    "print(\"\\n🔄 Executando Chunk 2 ADAPTADO: Preparação com Ligação Automática de Projetos Multianuais\")\n",
    "\n",
    "if CATEGORIA_TESTE_API:\n",
    "    print(f\"🧪 MODO TESTE ATIVADO - Processando apenas categoria: '{CATEGORIA_TESTE_API}'\")\n",
    "else:\n",
    "    print(\"🌐 MODO COMPLETO - Processando todas as categorias\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Timestamp para controle\n",
    "    timestamp_preparacao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Processar dados com identificação de multianuais\n",
    "    df_processado, df_para_llm, combinacoes_validas, grupos_multianuais = preparar_dados_com_multianual(df)\n",
    "    \n",
    "    if df_processado is not None:\n",
    "        # Salvar relatório de multianuais\n",
    "        arquivo_relatorio = salvar_relatorio_multianuais(grupos_multianuais, timestamp_preparacao)\n",
    "        \n",
    "        print(f\"✅ Chunk 2 adaptado executado:\")\n",
    "        print(f\"   📊 Total processado: {len(df_processado):,} registros\")\n",
    "        print(f\"   🔗 Projetos multianuais ligados: {len(df_processado[df_processado['eh_multianual']]):,}\")\n",
    "        print(f\"   🤖 Projetos para LLM: {len(df_para_llm):,}\")\n",
    "        print(f\"   🏷️ Categorias para LLM: {len(combinacoes_validas)}\")\n",
    "        \n",
    "        if CATEGORIA_TESTE_API:\n",
    "            print(f\"   🧪 MODO TESTE: Apenas categoria '{CATEGORIA_TESTE_API}'\")\n",
    "            if len(combinacoes_validas) > 0:\n",
    "                total_projetos_teste = combinacoes_validas['count'].sum()\n",
    "                print(f\"   📊 Projetos a serem processados no teste: {total_projetos_teste}\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ ATENÇÃO: Nenhuma combinação para categoria '{CATEGORIA_TESTE_API}'\")\n",
    "        \n",
    "        print(f\"   📄 Relatório salvo: {arquivo_relatorio}\")\n",
    "        \n",
    "        # Estatísticas dos grupos multianuais\n",
    "        if grupos_multianuais:\n",
    "            total_grupos = len(grupos_multianuais)\n",
    "            maior_grupo = max(g['total_registros'] for g in grupos_multianuais)\n",
    "            print(f\"   📈 Grupos multianuais: {total_grupos} (maior: {maior_grupo} registros)\")\n",
    "        \n",
    "        # Renomear variáveis para compatibilidade com chunks seguintes\n",
    "        df_clean = df_para_llm  # Para os chunks seguintes processarem apenas os não-multianuais\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Chunk 2 adaptado falhou: Não foi possível processar os dados\")\n",
    "else:\n",
    "    print(\"❌ DataFrame 'df' não encontrado. Execute Chunk 1 primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f03a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:15:01,953 - INFO - ✅ API Deepseek configurada com sucesso\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executando Chunk 3: Configuração da API Deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:15:02,528 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-11 17:15:05,273 - INFO - ✅ Teste de conexão com API bem-sucedido\n",
      "2025-08-11 17:15:05,274 - INFO - 📱 Resposta do teste: OK...\n",
      "2025-08-11 17:15:05,275 - INFO - 💰 Estimativa de custo:\n",
      "2025-08-11 17:15:05,276 - INFO -    📊 Total de combinações: 9\n",
      "2025-08-11 17:15:05,277 - INFO -    📋 Total de projetos: 14229\n",
      "2025-08-11 17:15:05,278 - INFO -    🔤 Tokens estimados: 4,268,700\n",
      "2025-08-11 17:15:05,279 - INFO -    💵 Custo estimado: $5.98 USD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 3 executado: API configurada e testada\n",
      "💰 Custo estimado: $5.98 USD\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 3: Configuração da API Deepseek\n",
    "Configura a conexão com a API Deepseek usando LangChain\n",
    "\"\"\"\n",
    "\n",
    "def configurar_api_deepseek():\n",
    "    \"\"\"\n",
    "    Configura o cliente da API Deepseek\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obter chave da API\n",
    "        api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"A chave da API do DeepSeek não está definida nas variáveis de ambiente.\")\n",
    "        \n",
    "        # Configurar o modelo\n",
    "        model = ChatOpenAI(\n",
    "            model=\"deepseek-chat\",\n",
    "            temperature=0.3,  # Baixa temperatura para resultados mais consistentes\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        \n",
    "        logging.info(\"✅ API Deepseek configurada com sucesso\")\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao configurar API Deepseek: {e}\")\n",
    "        return None\n",
    "\n",
    "def testar_conexao_api(model):\n",
    "    \"\"\"\n",
    "    Testa a conexão com a API Deepseek\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar mensagem de teste simples\n",
    "        mensagens_teste = [\n",
    "            SystemMessage(content=\"Você é um assistente útil.\"),\n",
    "            HumanMessage(content=\"Responda apenas 'OK' se você conseguir me ouvir.\")\n",
    "        ]\n",
    "        \n",
    "        # Fazer chamada de teste\n",
    "        resposta = model.invoke(mensagens_teste)\n",
    "        \n",
    "        if resposta and resposta.content:\n",
    "            logging.info(\"✅ Teste de conexão com API bem-sucedido\")\n",
    "            logging.info(f\"📱 Resposta do teste: {resposta.content[:50]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            logging.error(\"❌ Resposta vazia da API\")\n",
    "            return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no teste de conexão: {e}\")\n",
    "        return False\n",
    "\n",
    "def estimar_custo_processamento(combinacoes_validas):\n",
    "    \"\"\"\n",
    "    Estima o custo aproximado do processamento\n",
    "    \"\"\"\n",
    "    if combinacoes_validas is None:\n",
    "        return\n",
    "    \n",
    "    total_combinacoes = len(combinacoes_validas)\n",
    "    total_projetos = combinacoes_validas['count'].sum()\n",
    "    \n",
    "    # Estimativas (valores aproximados para Deepseek)\n",
    "    tokens_por_projeto = 300  # Média de tokens por projeto\n",
    "    tokens_totais = total_projetos * tokens_por_projeto\n",
    "    custo_por_1k_tokens = 0.0014  # USD por 1k tokens (aproximado Deepseek)\n",
    "    custo_estimado = (tokens_totais / 1000) * custo_por_1k_tokens\n",
    "    \n",
    "    logging.info(f\"💰 Estimativa de custo:\")\n",
    "    logging.info(f\"   📊 Total de combinações: {total_combinacoes}\")\n",
    "    logging.info(f\"   📋 Total de projetos: {total_projetos}\")\n",
    "    logging.info(f\"   🔤 Tokens estimados: {tokens_totais:,}\")\n",
    "    logging.info(f\"   💵 Custo estimado: ${custo_estimado:.2f} USD\")\n",
    "    \n",
    "    return custo_estimado\n",
    "\n",
    "# Executar configuração\n",
    "print(\"\\n🔄 Executando Chunk 3: Configuração da API Deepseek\")\n",
    "\n",
    "# Configurar API\n",
    "model_deepseek = configurar_api_deepseek()\n",
    "\n",
    "if model_deepseek:\n",
    "    # Testar conexão\n",
    "    conexao_ok = testar_conexao_api(model_deepseek)\n",
    "    \n",
    "    if conexao_ok and 'combinacoes_validas' in locals():\n",
    "        # Estimar custo\n",
    "        custo_estimado = estimar_custo_processamento(combinacoes_validas)\n",
    "        \n",
    "        print(f\"✅ Chunk 3 executado: API configurada e testada\")\n",
    "        print(f\"💰 Custo estimado: ${custo_estimado:.2f} USD\" if custo_estimado else \"Custo não calculado\")\n",
    "    else:\n",
    "        print(\"⚠️ Chunk 3 parcial: API configurada mas teste falhou\")\n",
    "else:\n",
    "    print(\"❌ Chunk 3 falhou: Não foi possível configurar a API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec63b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:25:41,959 - INFO - 📋 Formatados 3 projetos para análise\n",
      "2025-08-11 17:25:41,961 - INFO - ✅ Tamanho do prompt OK: 1180 tokens estimados\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executando Chunk 4: Preparação do Template de Prompt\n",
      "✅ Chunk 4 executado: Template criado e validado\n",
      "📏 Prompt válido: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 4: Preparação do Template de Prompt para IA\n",
    "Cria os templates de SystemMessage e HumanMessage para o Deepseek\n",
    "\"\"\"\n",
    "\n",
    "def criar_system_message():\n",
    "    \"\"\"\n",
    "    Cria a mensagem do sistema com instruções para agrupamento\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"Você é um especialista em análise de projetos de Pesquisa & Desenvolvimento (P&D) da Lei do Bem brasileira.\n",
    "\n",
    "Sua tarefa é analisar projetos e agrupá-los por alta similaridade técnica e temática.\n",
    "\n",
    "CRITÉRIOS DE AGRUPAMENTO:\n",
    "1. Projetos devem ter ALTA SIMILARIDADE (>75%) em:\n",
    "   - Objeto/tema principal do projeto\n",
    "   - Tecnologias utilizadas\n",
    "   - Metodologia aplicada\n",
    "   - Resultados esperados\n",
    "\n",
    "2. GRUPOS VÁLIDOS:\n",
    "   - Mínimo: 2 projetos por grupo\n",
    "   - Máximo: 8 projetos por grupo\n",
    "   - Projetos únicos ficam sem grupo (grupo_id = 0)\n",
    "\n",
    "3. CRITÉRIOS DE SIMILARIDADE:\n",
    "   - Mesmo domínio tecnológico (ex: IoT, sensores, automação)\n",
    "   - Mesma aplicação (ex: monitoramento, controle, otimização)\n",
    "   - Metodologias similares (ex: machine learning, análise de dados)\n",
    "   - Resultados comparáveis (ex: produtos, processos, softwares)\n",
    "\n",
    "FORMATO DE SAÍDA:\n",
    "Retorne APENAS um CSV com as colunas:\n",
    "grupo_id,projeto_id,similaridade_score,justificativa_agrupamento\n",
    "\n",
    "EXEMPLO:\n",
    "1,ID123,0.85,\"Ambos desenvolvem sensores IoT para automação industrial\"\n",
    "1,ID456,0.82,\"Projetos focam em sensores para controle de processos\"\n",
    "2,ID789,0.90,\"Desenvolvimento de algoritmos de machine learning\"\n",
    "2,ID012,0.88,\"Aplicação de IA para análise preditiva\"\n",
    "0,ID345,0.00,\"Projeto único sem similaridade suficiente\"\n",
    "\n",
    "IMPORTANTE:\n",
    "- Seja rigoroso na similaridade\n",
    "- Prefira menos grupos com alta qualidade\n",
    "- Justifique cada agrupamento brevemente\n",
    "- Analise todo o contexto do projeto, não apenas palavras-chave\"\"\"\n",
    "\n",
    "    return SystemMessage(content=system_prompt)\n",
    "\n",
    "def formatar_projetos_para_analise(df_subset):\n",
    "    \"\"\"\n",
    "    Formata os projetos de um subset para análise pela IA\n",
    "    \"\"\"\n",
    "    try:\n",
    "        projetos_formatados = []\n",
    "        \n",
    "        for idx, row in df_subset.iterrows():\n",
    "            # Extrair ID único do projeto da coluna 'projeto'\n",
    "            projeto_texto = str(row['projeto'])\n",
    "            \n",
    "            # Buscar ID único entre ' ID ÚNICO: ' e ' NOME: '\n",
    "            import re\n",
    "            match_id = re.search(r'ID ÚNICO:\\s*([^:]+?)\\s+NOME:', projeto_texto)\n",
    "            \n",
    "            if match_id:\n",
    "                projeto_id = match_id.group(1).strip()\n",
    "            else:\n",
    "                # Fallback caso não encontre o padrão\n",
    "                projeto_id = f\"PROJ_{row.get('id_empresa_ano', idx)}_{idx}\"\n",
    "                logging.warning(f\"⚠️ ID único não encontrado para linha {idx}, usando fallback: {projeto_id}\")\n",
    "            \n",
    "            # Formatação limpa do projeto\n",
    "            projeto_formatado = f\"\"\"\n",
    "ID: {projeto_id}\n",
    "PROJETO: {row['projeto'][:500]}...\n",
    "SETOR: {row['setor']}\n",
    "NATUREZA: {row['natureza']}\n",
    "TIPO: {row['tipo_pesquisa']}\n",
    "RESULTADOS: {row['projeto_resultados'][:300] if pd.notna(row['projeto_resultados']) else 'Não informado'}...\n",
    "\"\"\"\n",
    "            projetos_formatados.append(projeto_formatado.strip())\n",
    "        \n",
    "        logging.info(f\"📋 Formatados {len(projetos_formatados)} projetos para análise\")\n",
    "        return projetos_formatados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao formatar projetos: {e}\")\n",
    "        return []\n",
    "\n",
    "def criar_human_message(projetos_formatados, combinacao_info):\n",
    "    \"\"\"\n",
    "    Cria a mensagem humana com os projetos para análise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cabeçalho da análise\n",
    "        cabecalho = f\"\"\"Analise os projetos abaixo e agrupe-os por alta similaridade técnica.\n",
    "\n",
    "CONTEXTO DA ANÁLISE:\n",
    "- Ano: {combinacao_info['ano_referencia']}\n",
    "- Setor: {combinacao_info['setor']}\n",
    "- Tipo de Pesquisa: {combinacao_info['tipo_pesquisa']}\n",
    "- Natureza: {combinacao_info['natureza']}\n",
    "- Total de Projetos: {len(projetos_formatados)}\n",
    "\n",
    "PROJETOS PARA ANÁLISE:\n",
    "{'='*50}\"\"\"\n",
    "\n",
    "        # Adicionar projetos formatados\n",
    "        projetos_texto = '\\n\\n'.join(projetos_formatados)\n",
    "        \n",
    "        # Instrução final\n",
    "        instrucao_final = f\"\"\"\n",
    "{'='*50}\n",
    "\n",
    "Retorne APENAS o CSV com o agrupamento, seguindo o formato especificado no system prompt.\n",
    "Analise cuidadosamente a similaridade técnica entre os projetos.\"\"\"\n",
    "\n",
    "        mensagem_completa = f\"{cabecalho}\\n\\n{projetos_texto}\\n{instrucao_final}\"\n",
    "        \n",
    "        return HumanMessage(content=mensagem_completa)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao criar human message: {e}\")\n",
    "        return None\n",
    "\n",
    "def validar_tamanho_prompt(system_msg, human_msg, limite_tokens=30000):\n",
    "    \"\"\"\n",
    "    Valida se o prompt não excede o limite de tokens\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Estimativa simples: ~4 caracteres por token\n",
    "        total_chars = len(system_msg.content) + len(human_msg.content)\n",
    "        tokens_estimados = total_chars // 4\n",
    "        \n",
    "        if tokens_estimados > limite_tokens:\n",
    "            logging.warning(f\"⚠️ Prompt muito longo: {tokens_estimados} tokens estimados\")\n",
    "            return False\n",
    "        \n",
    "        logging.info(f\"✅ Tamanho do prompt OK: {tokens_estimados} tokens estimados\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao validar tamanho do prompt: {e}\")\n",
    "        return False\n",
    "\n",
    "# Executar preparação do template\n",
    "print(\"\\n🔄 Executando Chunk 4: Preparação do Template de Prompt\")\n",
    "\n",
    "# Criar system message\n",
    "system_message_template = criar_system_message()\n",
    "\n",
    "# Teste com dados dummy se disponível\n",
    "if 'df_clean' in locals() and df_clean is not None and len(df_clean) > 0:\n",
    "    # Pegar uma amostra pequena para teste\n",
    "    df_teste = df_clean.head(3)\n",
    "    projetos_teste = formatar_projetos_para_analise(df_teste)\n",
    "    \n",
    "    combinacao_teste = {\n",
    "        'ano_referencia': df_teste.iloc[0]['ano_referencia'],\n",
    "        'setor': df_teste.iloc[0]['setor'],\n",
    "        'tipo_pesquisa': df_teste.iloc[0]['tipo_pesquisa'],\n",
    "        'natureza': df_teste.iloc[0]['natureza']\n",
    "    }\n",
    "    \n",
    "    human_message_teste = criar_human_message(projetos_teste, combinacao_teste)\n",
    "    \n",
    "    if human_message_teste:\n",
    "        prompt_valido = validar_tamanho_prompt(system_message_template, human_message_teste)\n",
    "        print(f\"✅ Chunk 4 executado: Template criado e validado\")\n",
    "        print(f\"📏 Prompt válido: {prompt_valido}\")\n",
    "    else:\n",
    "        print(\"⚠️ Chunk 4 parcial: Template criado mas teste falhou\")\n",
    "else:\n",
    "    print(\"✅ Chunk 4 executado: Template criado (sem teste - dados não disponíveis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac6f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:26:00,263 - INFO - 🔍 Categoria filtrada: 1887 projetos\n",
      "2025-08-11 17:26:00,264 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,266 - INFO - 📦 Categoria dividida: 1887 projetos → 27 sub-lotes\n",
      "2025-08-11 17:26:00,266 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,304 - INFO - 🔍 Categoria filtrada: 8172 projetos\n",
      "2025-08-11 17:26:00,305 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,308 - INFO - 📦 Categoria dividida: 8172 projetos → 116 sub-lotes\n",
      "2025-08-11 17:26:00,308 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,326 - INFO - 🔍 Categoria filtrada: 165 projetos\n",
      "2025-08-11 17:26:00,327 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,328 - INFO - 📦 Categoria dividida: 165 projetos → 3 sub-lotes\n",
      "2025-08-11 17:26:00,329 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,346 - INFO - 🔍 Categoria filtrada: 797 projetos\n",
      "2025-08-11 17:26:00,347 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,348 - INFO - 📦 Categoria dividida: 797 projetos → 12 sub-lotes\n",
      "2025-08-11 17:26:00,348 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,369 - INFO - 🔍 Categoria filtrada: 2449 projetos\n",
      "2025-08-11 17:26:00,370 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,371 - INFO - 📦 Categoria dividida: 2449 projetos → 35 sub-lotes\n",
      "2025-08-11 17:26:00,371 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,388 - INFO - 🔍 Categoria filtrada: 61 projetos\n",
      "2025-08-11 17:26:00,389 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,406 - INFO - 🔍 Categoria filtrada: 81 projetos\n",
      "2025-08-11 17:26:00,406 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,407 - INFO - 📦 Categoria dividida: 81 projetos → 2 sub-lotes\n",
      "2025-08-11 17:26:00,407 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executando Chunk 5 ADAPTADO: Processamento por Categoria\n",
      "🎯 Nova estratégia: Categorias completas com sub-lotes inteligentes\n",
      "📊 Limite por sub-lote: 71 projetos (~25,000 tokens)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 17:26:00,425 - INFO - 🔍 Categoria filtrada: 575 projetos\n",
      "2025-08-11 17:26:00,426 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2021.0), np.float64(2022.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,427 - INFO - 📦 Categoria dividida: 575 projetos → 9 sub-lotes\n",
      "2025-08-11 17:26:00,427 - INFO -    🔗 Sobreposição: 10 projetos entre sub-lotes\n",
      "2025-08-11 17:26:00,444 - INFO - 🔍 Categoria filtrada: 42 projetos\n",
      "2025-08-11 17:26:00,444 - INFO - 📅 Anos encontrados: [np.float64(2018.0), np.float64(2019.0), np.float64(2020.0), np.float64(2023.0)]\n",
      "2025-08-11 17:26:00,445 - INFO - 📋 Plano por categoria criado: 206 itens\n",
      "2025-08-11 17:26:00,446 - INFO -    🟢 Categorias processadas completas: 2\n",
      "2025-08-11 17:26:00,446 - INFO -    🟡 Sub-lotes para merge posterior: 204\n",
      "2025-08-11 17:26:00,450 - ERROR - ❌ Erro ao salvar plano categoria: Cannot save file into a non-existent directory: 'resultados_agrupamento'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 5 adaptado executado:\n",
      "   📊 Total de itens para processar: 206\n",
      "   🏷️ Categorias únicas: 9\n",
      "   📋 Total de projetos: 16199\n",
      "   📄 Plano salvo: None\n",
      "   🔗 Estratégia: Comparação completa dentro de cada categoria\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 5 ADAPTADO: Processamento por Categoria com Sub-lotes Inteligentes\n",
    "Organiza processamento garantindo que todos os projetos de uma categoria sejam comparados\n",
    "\"\"\"\n",
    "\n",
    "# Novo limite baseado em tokens, não quantidade arbitrária\n",
    "LIMITE_TOKENS_SEGUROS = 25000  # Deixa margem para resposta\n",
    "TOKENS_POR_PROJETO = 350      # Estimativa conservadora\n",
    "LIMITE_PROJETOS_POR_SUBLOTE = int(LIMITE_TOKENS_SEGUROS / TOKENS_POR_PROJETO)  # ~71 projetos\n",
    "\n",
    "def dividir_categoria_em_sublotes(df_categoria, limite_projetos=LIMITE_PROJETOS_POR_SUBLOTE):\n",
    "    \"\"\"\n",
    "    Divide uma categoria grande em sub-lotes, mantendo sobreposição para merge posterior\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_projetos = len(df_categoria)\n",
    "        \n",
    "        if total_projetos <= limite_projetos:\n",
    "            # Categoria pequena: processar tudo de uma vez\n",
    "            return [{\n",
    "                'dados': df_categoria,\n",
    "                'sublote_num': 1,\n",
    "                'total_sublotes': 1,\n",
    "                'tipo': 'categoria_completa',\n",
    "                'sobreposicao': None\n",
    "            }]\n",
    "        \n",
    "        # Categoria grande: dividir com sobreposição para merge posterior\n",
    "        sublotes = []\n",
    "        overlap_size = min(10, limite_projetos // 4)  # 25% de sobreposição, máximo 10\n",
    "        \n",
    "        inicio = 0\n",
    "        sublote_num = 1\n",
    "        \n",
    "        while inicio < total_projetos:\n",
    "            fim = min(inicio + limite_projetos, total_projetos)\n",
    "            \n",
    "            # Adicionar sobreposição (exceto no primeiro sub-lote)\n",
    "            if sublote_num > 1:\n",
    "                inicio_real = max(0, inicio - overlap_size)\n",
    "            else:\n",
    "                inicio_real = inicio\n",
    "            \n",
    "            sublote_dados = df_categoria.iloc[inicio_real:fim]\n",
    "            \n",
    "            sublote = {\n",
    "                'dados': sublote_dados,\n",
    "                'sublote_num': sublote_num,\n",
    "                'total_sublotes': None,  # Será calculado depois\n",
    "                'tipo': 'sublote_categoria',\n",
    "                'sobreposicao': {\n",
    "                    'inicio_original': inicio,\n",
    "                    'fim_original': fim,\n",
    "                    'overlap_inicio': overlap_size if sublote_num > 1 else 0,\n",
    "                    'projetos_sobrepostos': overlap_size if sublote_num > 1 else 0\n",
    "                }\n",
    "            }\n",
    "            sublotes.append(sublote)\n",
    "            \n",
    "            inicio = fim\n",
    "            sublote_num += 1\n",
    "        \n",
    "        # Atualizar total de sub-lotes\n",
    "        for sublote in sublotes:\n",
    "            sublote['total_sublotes'] = len(sublotes)\n",
    "        \n",
    "        logging.info(f\"📦 Categoria dividida: {total_projetos} projetos → {len(sublotes)} sub-lotes\")\n",
    "        logging.info(f\"   🔗 Sobreposição: {overlap_size} projetos entre sub-lotes\")\n",
    "        \n",
    "        return sublotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao dividir categoria: {e}\")\n",
    "        return []\n",
    "\n",
    "def filtrar_categoria_especifica(df_clean, combinacao):\n",
    "    \"\"\"\n",
    "    Filtra TODOS os projetos de uma categoria específica (incluindo anos diferentes)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_categoria = df_clean[\n",
    "            (df_clean['setor'] == combinacao['setor']) &\n",
    "            (df_clean['tipo_pesquisa'] == combinacao['tipo_pesquisa']) &\n",
    "            (df_clean['natureza'] == combinacao['natureza'])\n",
    "        ].copy()\n",
    "        \n",
    "        # Adicionar informação de ano para controle\n",
    "        anos_encontrados = df_categoria['ano_referencia'].unique()\n",
    "        \n",
    "        logging.info(f\"🔍 Categoria filtrada: {len(df_categoria)} projetos\")\n",
    "        logging.info(f\"📅 Anos encontrados: {sorted(anos_encontrados)}\")\n",
    "        \n",
    "        return df_categoria\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao filtrar categoria: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def criar_nome_arquivo_categoria(combinacao, sublote_info=None):\n",
    "    \"\"\"\n",
    "    Cria nome padronizado para arquivos por categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Limpar caracteres especiais\n",
    "        setor = re.sub(r'[^\\w\\s-]', '', str(combinacao['setor'])).strip()[:25]\n",
    "        tipo = re.sub(r'[^\\w\\s-]', '', str(combinacao['tipo_pesquisa'])).strip()[:25]\n",
    "        natureza = re.sub(r'[^\\w\\s-]', '', str(combinacao['natureza'])).strip()[:20]\n",
    "        \n",
    "        # Substituir espaços por underscores\n",
    "        setor = setor.replace(' ', '_')\n",
    "        tipo = tipo.replace(' ', '_')\n",
    "        natureza = natureza.replace(' ', '_')\n",
    "        \n",
    "        if sublote_info and sublote_info['tipo'] == 'sublote_categoria':\n",
    "            nome = f\"grupos_categoria_{setor}_{tipo}_{natureza}_sublote{sublote_info['sublote_num']}.csv\"\n",
    "        else:\n",
    "            nome = f\"grupos_categoria_{setor}_{tipo}_{natureza}_completa.csv\"\n",
    "        \n",
    "        return nome\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao criar nome do arquivo: {e}\")\n",
    "        return f\"grupos_categoria_erro_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "def preparar_plano_processamento_categoria(df_clean, combinacoes_validas):\n",
    "    \"\"\"\n",
    "    Prepara plano de processamento focado em categorias completas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plano_processamento = []\n",
    "        \n",
    "        for idx, row in combinacoes_validas.iterrows():\n",
    "            combinacao = {\n",
    "                'setor': row['setor'],\n",
    "                'tipo_pesquisa': row['tipo_pesquisa'],\n",
    "                'natureza': row['natureza'],\n",
    "                'count': row['count']\n",
    "            }\n",
    "            \n",
    "            # Filtrar TODOS os projetos da categoria\n",
    "            df_categoria = filtrar_categoria_especifica(df_clean, combinacao)\n",
    "            \n",
    "            if len(df_categoria) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Dividir em sub-lotes se necessário\n",
    "            sublotes = dividir_categoria_em_sublotes(df_categoria)\n",
    "            \n",
    "            for sublote in sublotes:\n",
    "                plano_item = {\n",
    "                    'combinacao': combinacao,\n",
    "                    'dados': sublote['dados'],\n",
    "                    'sublote_info': sublote,\n",
    "                    'arquivo_saida': criar_nome_arquivo_categoria(combinacao, sublote),\n",
    "                    'requer_merge': sublote['tipo'] == 'sublote_categoria'\n",
    "                }\n",
    "                plano_processamento.append(plano_item)\n",
    "        \n",
    "        logging.info(f\"📋 Plano por categoria criado: {len(plano_processamento)} itens\")\n",
    "        \n",
    "        # Estatísticas do plano\n",
    "        categorias_completas = sum(1 for item in plano_processamento if not item['requer_merge'])\n",
    "        categorias_sublotes = len(plano_processamento) - categorias_completas\n",
    "        \n",
    "        logging.info(f\"   🟢 Categorias processadas completas: {categorias_completas}\")\n",
    "        logging.info(f\"   🟡 Sub-lotes para merge posterior: {categorias_sublotes}\")\n",
    "        \n",
    "        return plano_processamento\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao preparar plano por categoria: {e}\")\n",
    "        return []\n",
    "\n",
    "def salvar_plano_categoria(plano_processamento):\n",
    "    \"\"\"\n",
    "    Salva o plano de processamento por categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plano_resumo = []\n",
    "        for item in plano_processamento:\n",
    "            resumo = {\n",
    "                'setor': item['combinacao']['setor'],\n",
    "                'tipo_pesquisa': item['combinacao']['tipo_pesquisa'],\n",
    "                'natureza': item['combinacao']['natureza'],\n",
    "                'total_projetos': len(item['dados']),\n",
    "                'sublote_num': item['sublote_info']['sublote_num'],\n",
    "                'total_sublotes': item['sublote_info']['total_sublotes'],\n",
    "                'tipo_processamento': item['sublote_info']['tipo'],\n",
    "                'requer_merge': item['requer_merge'],\n",
    "                'arquivo_saida': item['arquivo_saida']\n",
    "            }\n",
    "            plano_resumo.append(resumo)\n",
    "        \n",
    "        df_plano = pd.DataFrame(plano_resumo)\n",
    "        arquivo_plano = 'resultados_agrupamento/plano_processamento_categoria.csv'\n",
    "        df_plano.to_csv(arquivo_plano, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"📄 Plano por categoria salvo: {arquivo_plano}\")\n",
    "        return arquivo_plano\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao salvar plano categoria: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar preparação por categoria\n",
    "print(\"\\n🔄 Executando Chunk 5 ADAPTADO: Processamento por Categoria\")\n",
    "\n",
    "if 'df_clean' in locals() and 'combinacoes_validas' in locals() and df_clean is not None:\n",
    "    print(f\"🎯 Nova estratégia: Categorias completas com sub-lotes inteligentes\")\n",
    "    print(f\"📊 Limite por sub-lote: {LIMITE_PROJETOS_POR_SUBLOTE} projetos (~{LIMITE_TOKENS_SEGUROS:,} tokens)\")\n",
    "    \n",
    "    # Criar plano por categoria\n",
    "    plano_processamento = preparar_plano_processamento_categoria(df_clean, combinacoes_validas)\n",
    "    \n",
    "    if plano_processamento:\n",
    "        # Salvar plano\n",
    "        arquivo_plano = salvar_plano_categoria(plano_processamento)\n",
    "        \n",
    "        # Estatísticas finais\n",
    "        total_projetos = sum(len(item['dados']) for item in plano_processamento)\n",
    "        categorias_unicas = len(set((item['combinacao']['setor'], \n",
    "                                   item['combinacao']['tipo_pesquisa'], \n",
    "                                   item['combinacao']['natureza']) \n",
    "                                  for item in plano_processamento))\n",
    "        \n",
    "        print(f\"✅ Chunk 5 adaptado executado:\")\n",
    "        print(f\"   📊 Total de itens para processar: {len(plano_processamento)}\")\n",
    "        print(f\"   🏷️ Categorias únicas: {categorias_unicas}\")\n",
    "        print(f\"   📋 Total de projetos: {total_projetos}\")\n",
    "        print(f\"   📄 Plano salvo: {arquivo_plano}\")\n",
    "        print(f\"   🔗 Estratégia: Comparação completa dentro de cada categoria\")\n",
    "    else:\n",
    "        print(\"❌ Chunk 5 adaptado falhou: Não foi possível criar plano de categoria\")\n",
    "else:\n",
    "    print(\"⚠️ Chunk 5 adaptado ignorado: Dados não disponíveis dos chunks anteriores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a9ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executando Chunk 6 ADAPTADO: Loop Principal com Processamento Assíncrono\n",
      "⚠️ Chunk 6 adaptado ignorado: Dependências não disponíveis\n",
      "🔍 Variáveis faltando: []\n",
      "\n",
      "💡 DICA: Instale nest_asyncio se houver problemas com loops de eventos:\n",
      "pip install nest-asyncio\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHUNK 6 ADAPTADO: Loop Principal de Iteração com Requisições Assíncronas\n",
    "Implementa processamento assíncrono para acelerar requisições à API\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "\n",
    "def configurar_api_deepseek_async():\n",
    "    \"\"\"\n",
    "    Configura o cliente da API Deepseek (usando ChatOpenAI normal)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obter chave da API\n",
    "        api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"A chave da API do DeepSeek não está definida nas variáveis de ambiente.\")\n",
    "        \n",
    "        # Configurar o modelo (usar o ChatOpenAI normal)\n",
    "        model = ChatOpenAI(\n",
    "            model=\"deepseek-chat\",\n",
    "            temperature=0.3,\n",
    "            base_url=\"https://api.deepseek.com\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=4000,\n",
    "            max_retries=3,\n",
    "            request_timeout=60.0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"✅ API Deepseek configurada para uso assíncrono\")\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao configurar API Deepseek: {e}\")\n",
    "        return None\n",
    "\n",
    "async def processar_item_plano_async(item_plano, model_deepseek, system_message_template, executor, semaforo):\n",
    "    \"\"\"\n",
    "    Processa um item individual do plano de processamento de forma assíncrona usando ThreadPoolExecutor\n",
    "    \"\"\"\n",
    "    async with semaforo:  # Limitar número de requisições simultâneas\n",
    "        try:\n",
    "            combinacao = item_plano['combinacao']\n",
    "            dados = item_plano['dados']\n",
    "            arquivo_saida = item_plano['arquivo_saida']\n",
    "            \n",
    "            logging.info(f\"🔄 Processando async: {combinacao['setor']} - {len(dados)} projetos\")\n",
    "            \n",
    "            # Formatar projetos para análise\n",
    "            projetos_formatados = formatar_projetos_para_analise(dados)\n",
    "            \n",
    "            if not projetos_formatados:\n",
    "                logging.error(\"❌ Falha ao formatar projetos\")\n",
    "                return None\n",
    "            \n",
    "            # Criar mensagem humana\n",
    "            human_message = criar_human_message(projetos_formatados, combinacao)\n",
    "            \n",
    "            if not human_message:\n",
    "                logging.error(\"❌ Falha ao criar human message\")\n",
    "                return None\n",
    "            \n",
    "            # Validar tamanho do prompt\n",
    "            if not validar_tamanho_prompt(system_message_template, human_message):\n",
    "                logging.error(\"❌ Prompt excede limite de tokens\")\n",
    "                return None\n",
    "            \n",
    "            # Preparar mensagens para a API\n",
    "            mensagens = [system_message_template, human_message]\n",
    "            \n",
    "            logging.info(f\"📤 Enviando para API Deepseek (async via thread)...\")\n",
    "            \n",
    "            # Executar chamada da API em thread separada para não bloquear\n",
    "            loop = asyncio.get_event_loop()\n",
    "            resposta = await loop.run_in_executor(\n",
    "                executor, \n",
    "                partial(model_deepseek.invoke, mensagens)\n",
    "            )\n",
    "            \n",
    "            if resposta and resposta.content:\n",
    "                logging.info(f\"✅ Resposta assíncrona recebida para {combinacao['setor']}\")\n",
    "                return {\n",
    "                    'resposta': resposta.content,\n",
    "                    'combinacao': combinacao,\n",
    "                    'arquivo_saida': arquivo_saida,\n",
    "                    'total_projetos': len(dados),\n",
    "                    'requer_merge': item_plano.get('requer_merge', False)\n",
    "                }\n",
    "            else:\n",
    "                logging.error(\"❌ Resposta vazia da API\")\n",
    "                return None\n",
    "        \n",
    "        except asyncio.TimeoutError:\n",
    "            logging.error(f\"⏱️ Timeout na requisição para {combinacao['setor']}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ Erro ao processar item async: {e}\")\n",
    "            return None\n",
    "\n",
    "async def executar_lote_async(lote_itens, model_deepseek, system_message_template, executor, max_concurrent=3):\n",
    "    \"\"\"\n",
    "    Executa um lote de itens de forma assíncrona\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Semáforo para limitar requisições simultâneas\n",
    "        semaforo = asyncio.Semaphore(max_concurrent)\n",
    "        \n",
    "        # Criar tarefas assíncronas\n",
    "        tarefas = []\n",
    "        for item in lote_itens:\n",
    "            tarefa = processar_item_plano_async(item, model_deepseek, system_message_template, executor, semaforo)\n",
    "            tarefas.append(tarefa)\n",
    "        \n",
    "        # Executar todas as tarefas em paralelo\n",
    "        resultados = await asyncio.gather(*tarefas, return_exceptions=True)\n",
    "        \n",
    "        # Filtrar resultados válidos\n",
    "        resultados_validos = []\n",
    "        for resultado in resultados:\n",
    "            if isinstance(resultado, Exception):\n",
    "                logging.error(f\"❌ Exceção no processamento assíncrono: {resultado}\")\n",
    "            elif resultado is not None:\n",
    "                resultados_validos.append(resultado)\n",
    "        \n",
    "        logging.info(f\"✅ Lote assíncrono concluído: {len(resultados_validos)}/{len(lote_itens)} sucessos\")\n",
    "        return resultados_validos\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no lote assíncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def dividir_em_lotes_async(plano_processamento, tamanho_lote=5):\n",
    "    \"\"\"\n",
    "    Divide o plano em lotes menores para processamento assíncrono\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lotes = []\n",
    "        total_itens = len(plano_processamento)\n",
    "        \n",
    "        for i in range(0, total_itens, tamanho_lote):\n",
    "            lote = plano_processamento[i:i+tamanho_lote]\n",
    "            lotes.append(lote)\n",
    "        \n",
    "        logging.info(f\"📦 Divisão para processamento assíncrono: {total_itens} itens → {len(lotes)} lotes\")\n",
    "        return lotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao dividir em lotes async: {e}\")\n",
    "        return [plano_processamento]  # Retorna como um lote único\n",
    "\n",
    "async def executar_loop_principal_async(plano_processamento, model_deepseek, system_message_template, \n",
    "                                       modo_teste=False, limite_teste=3, max_concurrent=3, tamanho_lote=5):\n",
    "    \"\"\"\n",
    "    Executa o loop principal de processamento de forma assíncrona\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resultados = []\n",
    "        total_itens = len(plano_processamento)\n",
    "        \n",
    "        # Limitar para teste se necessário\n",
    "        if modo_teste:\n",
    "            plano_processamento = plano_processamento[:limite_teste]\n",
    "            logging.info(f\"🧪 Modo teste ativado: processando apenas {len(plano_processamento)} itens\")\n",
    "        \n",
    "        logging.info(f\"🚀 Iniciando processamento assíncrono de {len(plano_processamento)} itens...\")\n",
    "        logging.info(f\"⚡ Configuração: {max_concurrent} requisições simultâneas, lotes de {tamanho_lote}\")\n",
    "        \n",
    "        # Criar ThreadPoolExecutor para requisições HTTP\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent) as executor:\n",
    "            # Dividir em lotes para gerenciar melhor o processamento\n",
    "            lotes = dividir_em_lotes_async(plano_processamento, tamanho_lote)\n",
    "            \n",
    "            for idx_lote, lote in enumerate(lotes, 1):\n",
    "                try:\n",
    "                    logging.info(f\"\\n{'='*60}\")\n",
    "                    logging.info(f\"📦 Processando lote {idx_lote}/{len(lotes)} ({len(lote)} itens)\")\n",
    "                    \n",
    "                    # Executar lote assíncrono\n",
    "                    resultados_lote = await executar_lote_async(\n",
    "                        lote, model_deepseek, system_message_template, executor, max_concurrent\n",
    "                    )\n",
    "                    \n",
    "                    resultados.extend(resultados_lote)\n",
    "                    \n",
    "                    logging.info(f\"✅ Lote {idx_lote} concluído: {len(resultados_lote)} sucessos\")\n",
    "                    \n",
    "                    # Pausa entre lotes (exceto no último)\n",
    "                    if idx_lote < len(lotes):\n",
    "                        pausa_entre_lotes = min(TEMPO_PAUSA_ENTRE_REQUESTS, 3)  # Máximo 3s entre lotes\n",
    "                        logging.info(f\"⏸️ Pausando {pausa_entre_lotes}s entre lotes...\")\n",
    "                        await asyncio.sleep(pausa_entre_lotes)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"❌ Erro no lote {idx_lote}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        logging.info(f\"\\n🎉 Processamento assíncrono concluído!\")\n",
    "        logging.info(f\"✅ Sucessos: {len(resultados)}/{total_itens}\")\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no loop principal assíncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def executar_processamento_sincronizado(plano_processamento, system_message_template, \n",
    "                                      modo_teste=True, limite_teste=3):\n",
    "    \"\"\"\n",
    "    Função wrapper que gerencia a execução assíncrona usando ThreadPoolExecutor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configurar cliente (ChatOpenAI normal)\n",
    "        model_deepseek = configurar_api_deepseek_async()\n",
    "        if not model_deepseek:\n",
    "            raise Exception(\"Falha na configuração da API\")\n",
    "        \n",
    "        # Verificar se já há um loop de eventos rodando\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            logging.info(\"📡 Loop de eventos já ativo, usando nest_asyncio\")\n",
    "            \n",
    "            # Se já há um loop, usar nest_asyncio\n",
    "            try:\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "            except ImportError:\n",
    "                logging.warning(\"⚠️ nest_asyncio não instalado, tentando execução alternativa\")\n",
    "                # Fallback: executar de forma síncrona\n",
    "                return executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste)\n",
    "            \n",
    "            # Executar de forma assíncrona no loop existente\n",
    "            resultado = asyncio.run(executar_loop_principal_async(\n",
    "                plano_processamento, model_deepseek, system_message_template,\n",
    "                modo_teste, limite_teste, max_concurrent=3, tamanho_lote=5\n",
    "            ))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            # Não há loop rodando, criar um novo\n",
    "            logging.info(\"📡 Criando novo loop de eventos\")\n",
    "            resultado = asyncio.run(executar_loop_principal_async(\n",
    "                plano_processamento, model_deepseek, system_message_template,\n",
    "                modo_teste, limite_teste, max_concurrent=3, tamanho_lote=5\n",
    "            ))\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro na execução sincronizada: {e}\")\n",
    "        # Fallback para processamento síncrono\n",
    "        return executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste)\n",
    "\n",
    "def executar_fallback_sincronizado(plano_processamento, model_deepseek, system_message_template, modo_teste, limite_teste):\n",
    "    \"\"\"\n",
    "    Fallback para processamento síncrono caso asyncio falhe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"🔄 Executando fallback síncrono...\")\n",
    "        resultados = []\n",
    "        \n",
    "        # Limitar para teste se necessário\n",
    "        if modo_teste:\n",
    "            plano_processamento = plano_processamento[:limite_teste]\n",
    "        \n",
    "        for idx, item in enumerate(plano_processamento, 1):\n",
    "            try:\n",
    "                logging.info(f\"📋 Processando item {idx}/{len(plano_processamento)} (síncrono)\")\n",
    "                \n",
    "                # Processar item de forma síncrona\n",
    "                combinacao = item['combinacao']\n",
    "                dados = item['dados']\n",
    "                arquivo_saida = item['arquivo_saida']\n",
    "                \n",
    "                projetos_formatados = formatar_projetos_para_analise(dados)\n",
    "                if not projetos_formatados:\n",
    "                    continue\n",
    "                \n",
    "                human_message = criar_human_message(projetos_formatados, combinacao)\n",
    "                if not human_message:\n",
    "                    continue\n",
    "                \n",
    "                mensagens = [system_message_template, human_message]\n",
    "                resposta = model_deepseek.invoke(mensagens)\n",
    "                \n",
    "                if resposta and resposta.content:\n",
    "                    resultado = {\n",
    "                        'resposta': resposta.content,\n",
    "                        'combinacao': combinacao,\n",
    "                        'arquivo_saida': arquivo_saida,\n",
    "                        'total_projetos': len(dados),\n",
    "                        'requer_merge': item.get('requer_merge', False)\n",
    "                    }\n",
    "                    resultados.append(resultado)\n",
    "                    logging.info(f\"✅ Item {idx} processado (síncrono)\")\n",
    "                \n",
    "                # Pausa entre requisições\n",
    "                if idx < len(plano_processamento):\n",
    "                    time.sleep(TEMPO_PAUSA_ENTRE_REQUESTS)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"❌ Erro no item {idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no fallback síncrono: {e}\")\n",
    "        return []\n",
    "\n",
    "def salvar_progresso_intermediario(resultados, timestamp):\n",
    "    \"\"\"\n",
    "    Salva progresso intermediário durante o processamento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        arquivo_progresso = f'resultados_agrupamento/progresso_{timestamp}.json'\n",
    "        \n",
    "        # Converter para formato serializável\n",
    "        progresso_data = []\n",
    "        for resultado in resultados:\n",
    "            item = {\n",
    "                'combinacao': resultado['combinacao'],\n",
    "                'arquivo_saida': resultado['arquivo_saida'],\n",
    "                'total_projetos': resultado['total_projetos'],\n",
    "                'resposta_length': len(resultado['resposta']),\n",
    "                'requer_merge': resultado.get('requer_merge', False),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            progresso_data.append(item)\n",
    "        \n",
    "        with open(arquivo_progresso, 'w', encoding='utf-8') as f:\n",
    "            json.dump(progresso_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"💾 Progresso salvo: {arquivo_progresso}\")\n",
    "        return arquivo_progresso\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao salvar progresso: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar loop principal assíncrono\n",
    "print(\"\\n🔄 Executando Chunk 6 ADAPTADO: Loop Principal com Processamento Assíncrono\")\n",
    "\n",
    "if all(var in locals() for var in ['plano_processamento', 'system_message_template']):\n",
    "    # Timestamp para controle\n",
    "    timestamp_execucao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    print(\"⚡ PROCESSAMENTO ASSÍNCRONO ATIVADO\")\n",
    "    print(\"🧪 Executando em MODO TESTE (3 primeiros itens)\")\n",
    "    print(\"📊 Configuração: 3 requisições simultâneas, lotes de 5 itens\")\n",
    "    print(\"Para executar completo, mude modo_teste=False\")\n",
    "    \n",
    "    # Executar processamento assíncrono\n",
    "    resultados_processamento = executar_processamento_sincronizado(\n",
    "        plano_processamento, \n",
    "        system_message_template,\n",
    "        modo_teste=True,  # Mudar para False para execução completa\n",
    "        limite_teste=3\n",
    "    )\n",
    "    \n",
    "    if resultados_processamento:\n",
    "        # Salvar progresso\n",
    "        arquivo_progresso = salvar_progresso_intermediario(resultados_processamento, timestamp_execucao)\n",
    "        \n",
    "        print(f\"✅ Chunk 6 adaptado executado: {len(resultados_processamento)} itens processados\")\n",
    "        print(f\"⚡ Vantagem assíncrona: ~3x mais rápido que processamento sequencial\")\n",
    "        print(f\"💾 Progresso salvo: {arquivo_progresso}\")\n",
    "    else:\n",
    "        print(\"❌ Chunk 6 adaptado falhou: Nenhum item foi processado com sucesso\")\n",
    "else:\n",
    "    print(\"⚠️ Chunk 6 adaptado ignorado: Dependências não disponíveis\")\n",
    "    missing_vars = [var for var in ['plano_processamento', 'system_message_template'] \n",
    "                    if var not in locals()]\n",
    "    print(f\"🔍 Variáveis faltando: {missing_vars}\")\n",
    "\n",
    "print(\"\\n💡 DICA: Instale nest_asyncio se houver problemas com loops de eventos:\")\n",
    "print(\"pip install nest-asyncio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea74cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 7: Tratamento de Erros e Controle\n",
    "Implementa retry logic, rate limiting e controle de erros\n",
    "\"\"\"\n",
    "\n",
    "def processar_item_com_retry(item_plano, model_deepseek, system_message_template, max_tentativas=MAX_TENTATIVAS):\n",
    "    \"\"\"\n",
    "    Processa um item com lógica de retry em caso de erro\n",
    "    \"\"\"\n",
    "    for tentativa in range(1, max_tentativas + 1):\n",
    "        try:\n",
    "            logging.info(f\"🔄 Tentativa {tentativa}/{max_tentativas}\")\n",
    "            \n",
    "            resultado = processar_item_plano(item_plano, model_deepseek, system_message_template)\n",
    "            \n",
    "            if resultado:\n",
    "                if tentativa > 1:\n",
    "                    logging.info(f\"✅ Sucesso na tentativa {tentativa}\")\n",
    "                return resultado\n",
    "            else:\n",
    "                logging.warning(f\"⚠️ Tentativa {tentativa} falhou - resultado vazio\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ Tentativa {tentativa} falhou: {e}\")\n",
    "            \n",
    "            # Pausa crescente entre tentativas (backoff exponencial)\n",
    "            if tentativa < max_tentativas:\n",
    "                pausa = TEMPO_PAUSA_ENTRE_REQUESTS * (2 ** (tentativa - 1))\n",
    "                logging.info(f\"⏸️ Pausando {pausa}s antes da próxima tentativa...\")\n",
    "                time.sleep(pausa)\n",
    "    \n",
    "    logging.error(f\"❌ Todas as {max_tentativas} tentativas falharam\")\n",
    "    return None\n",
    "\n",
    "def validar_resposta_api(resposta_content):\n",
    "    \"\"\"\n",
    "    Valida se a resposta da API está no formato esperado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not resposta_content:\n",
    "            return False, \"Resposta vazia\"\n",
    "        \n",
    "        # Verificar se contém formato CSV básico\n",
    "        linhas = resposta_content.strip().split('\\n')\n",
    "        \n",
    "        if len(linhas) < 2:\n",
    "            return False, \"Resposta muito curta - esperado formato CSV\"\n",
    "        \n",
    "        # Verificar se primeira linha parece um cabeçalho CSV\n",
    "        primeira_linha = linhas[0].strip()\n",
    "        if not any(campo in primeira_linha.lower() for campo in ['grupo', 'projeto', 'id']):\n",
    "            return False, \"Cabeçalho CSV não reconhecido\"\n",
    "        \n",
    "        # Verificar se há pelo menos uma linha de dados\n",
    "        segunda_linha = linhas[1].strip()\n",
    "        if len(segunda_linha.split(',')) < 3:\n",
    "            return False, \"Formato de dados inválido\"\n",
    "        \n",
    "        logging.info(f\"✅ Resposta validada: {len(linhas)} linhas encontradas\")\n",
    "        return True, \"Válida\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return False, f\"Erro na validação: {e}\"\n",
    "\n",
    "def limpar_resposta_csv(resposta_content):\n",
    "    \"\"\"\n",
    "    Limpa a resposta para extrair apenas o CSV válido\n",
    "    \"\"\"\n",
    "    try:\n",
    "        linhas = resposta_content.strip().split('\\n')\n",
    "        linhas_csv = []\n",
    "        \n",
    "        # Procurar início do CSV\n",
    "        inicio_csv = -1\n",
    "        for i, linha in enumerate(linhas):\n",
    "            if any(campo in linha.lower() for campo in ['grupo_id', 'projeto_id', 'similaridade']):\n",
    "                inicio_csv = i\n",
    "                break\n",
    "        \n",
    "        if inicio_csv == -1:\n",
    "            # Se não encontrar cabeçalho específico, usar primeira linha que parece CSV\n",
    "            for i, linha in enumerate(linhas):\n",
    "                if linha.count(',') >= 2:\n",
    "                    inicio_csv = i\n",
    "                    break\n",
    "        \n",
    "        if inicio_csv >= 0:\n",
    "            for linha in linhas[inicio_csv:]:\n",
    "                linha_limpa = linha.strip()\n",
    "                if linha_limpa and not linha_limpa.startswith('#'):\n",
    "                    linhas_csv.append(linha_limpa)\n",
    "        \n",
    "        csv_limpo = '\\n'.join(linhas_csv)\n",
    "        logging.info(f\"🧹 CSV limpo: {len(linhas_csv)} linhas\")\n",
    "        return csv_limpo\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao limpar CSV: {e}\")\n",
    "        return resposta_content\n",
    "\n",
    "def salvar_erro_detalhado(item_plano, erro, timestamp):\n",
    "    \"\"\"\n",
    "    Salva detalhes de erros para debug\n",
    "    \"\"\"\n",
    "    try:\n",
    "        arquivo_erro = f'resultados_agrupamento/logs/erro_{timestamp}.json'\n",
    "        \n",
    "        erro_data = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'combinacao': item_plano['combinacao'],\n",
    "            'arquivo_saida': item_plano['arquivo_saida'],\n",
    "            'total_projetos': len(item_plano['dados']),\n",
    "            'erro': str(erro),\n",
    "            'dados_amostra': {\n",
    "                'primeiros_3_projetos': [\n",
    "                    {\n",
    "                        'setor': row['setor'],\n",
    "                        'tipo_pesquisa': row['tipo_pesquisa'],\n",
    "                        'projeto_preview': row['projeto'][:100] + '...' if len(row['projeto']) > 100 else row['projeto']\n",
    "                    }\n",
    "                    for _, row in item_plano['dados'].head(3).iterrows()\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(arquivo_erro, 'w', encoding='utf-8') as f:\n",
    "            json.dump(erro_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"📋 Erro detalhado salvo: {arquivo_erro}\")\n",
    "        return arquivo_erro\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao salvar detalhes do erro: {e}\")\n",
    "        return None\n",
    "\n",
    "def monitorar_uso_api(resultados_processamento):\n",
    "    \"\"\"\n",
    "    Monitora uso da API e custos aproximados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_requisicoes = len(resultados_processamento)\n",
    "        total_projetos = sum(r['total_projetos'] for r in resultados_processamento)\n",
    "        \n",
    "        # Estimativas de tokens e custo\n",
    "        tokens_estimados = total_projetos * 300  # média por projeto\n",
    "        custo_estimado = (tokens_estimados / 1000) * 0.0014  # preço aproximado Deepseek\n",
    "        \n",
    "        log_uso = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_requisicoes': total_requisicoes,\n",
    "            'total_projetos': total_projetos,\n",
    "            'tokens_estimados': tokens_estimados,\n",
    "            'custo_estimado_usd': custo_estimado\n",
    "        }\n",
    "        \n",
    "        arquivo_uso = 'resultados_agrupamento/logs/uso_api.json'\n",
    "        with open(arquivo_uso, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log_uso, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"💰 Uso da API monitorado: {total_requisicoes} requests, ~${custo_estimado:.2f}\")\n",
    "        return log_uso\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao monitorar uso da API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar tratamento de erros\n",
    "print(\"\\n🔄 Executando Chunk 7: Tratamento de Erros e Controle\")\n",
    "\n",
    "# Verificar se há resultados para validar\n",
    "if 'resultados_processamento' in locals() and resultados_processamento:\n",
    "    print(f\"🔍 Validando {len(resultados_processamento)} resultados...\")\n",
    "    \n",
    "    resultados_validos = []\n",
    "    resultados_invalidos = []\n",
    "    \n",
    "    for resultado in resultados_processamento:\n",
    "        valida, motivo = validar_resposta_api(resultado['resposta'])\n",
    "        \n",
    "        if valida:\n",
    "            # Limpar CSV\n",
    "            csv_limpo = limpar_resposta_csv(resultado['resposta'])\n",
    "            resultado['resposta_limpa'] = csv_limpo\n",
    "            resultados_validos.append(resultado)\n",
    "        else:\n",
    "            logging.warning(f\"⚠️ Resposta inválida: {motivo}\")\n",
    "            resultados_invalidos.append(resultado)\n",
    "    \n",
    "    # Monitorar uso da API\n",
    "    if resultados_validos:\n",
    "        uso_api = monitorar_uso_api(resultados_validos)\n",
    "    \n",
    "    print(f\"✅ Chunk 7 executado:\")\n",
    "    print(f\"   ✅ Respostas válidas: {len(resultados_validos)}\")\n",
    "    print(f\"   ❌ Respostas inválidas: {len(resultados_invalidos)}\")\n",
    "    \n",
    "    if uso_api:\n",
    "        print(f\"   💰 Custo estimado: ${uso_api['custo_estimado_usd']:.2f}\")\n",
    "else:\n",
    "    print(\"⚠️ Chunk 7 ignorado: Nenhum resultado para validar\")\n",
    "    resultados_validos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 8: Consolidação Final integrando Multianuais + Merge de Sub-lotes\n",
    "Une os grupos automáticos (multianuais) com os grupos da LLM e faz merge inteligente\n",
    "\"\"\"\n",
    "\n",
    "def identificar_categorias_para_merge(resultados_processados):\n",
    "    \"\"\"\n",
    "    Identifica quais categorias foram divididas em sub-lotes e precisam de merge\n",
    "    \"\"\"\n",
    "    try:\n",
    "        categorias_sublotes = {}\n",
    "        \n",
    "        for resultado in resultados_processados:\n",
    "            if resultado.get('requer_merge', False):\n",
    "                combinacao = resultado['combinacao']\n",
    "                categoria_key = f\"{combinacao['setor']}_{combinacao['tipo_pesquisa']}_{combinacao['natureza']}\"\n",
    "                \n",
    "                if categoria_key not in categorias_sublotes:\n",
    "                    categorias_sublotes[categoria_key] = []\n",
    "                \n",
    "                categorias_sublotes[categoria_key].append(resultado)\n",
    "        \n",
    "        logging.info(f\"🔗 Categorias que precisam merge: {len(categorias_sublotes)}\")\n",
    "        return categorias_sublotes\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao identificar categorias para merge: {e}\")\n",
    "        return {}\n",
    "\n",
    "def processar_merge_completo(resultados_processados):\n",
    "    \"\"\"\n",
    "    Processa merge completo de todas as categorias que precisam\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Separar resultados que precisam de merge vs. categorias completas\n",
    "        resultados_finais = []\n",
    "        \n",
    "        # Identificar categorias para merge\n",
    "        categorias_sublotes = identificar_categorias_para_merge(resultados_processados)\n",
    "        \n",
    "        # Processar categorias que foram divididas em sub-lotes\n",
    "        for categoria_key, sublotes in categorias_sublotes.items():\n",
    "            resultado_merge = fazer_merge_sublotes_categoria(sublotes, categoria_key)\n",
    "            if resultado_merge:\n",
    "                resultados_finais.append(resultado_merge)\n",
    "        \n",
    "        # Adicionar categorias que foram processadas completas (sem sub-lotes)\n",
    "        for resultado in resultados_processados:\n",
    "            if not resultado.get('requer_merge', False):\n",
    "                resultados_finais.append(resultado)\n",
    "        \n",
    "        logging.info(f\"🔗 Merge completo finalizado:\")\n",
    "        logging.info(f\"   🏷️ Categorias processadas: {len(resultados_finais)}\")\n",
    "        logging.info(f\"   📦 Categorias que passaram por merge: {len(categorias_sublotes)}\")\n",
    "        \n",
    "        return resultados_finais\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no merge completo: {e}\")\n",
    "        return resultados_processados  # Retorna originais em caso de erro\n",
    "\n",
    "def fazer_merge_sublotes_categoria(sublotes_categoria, categoria_key):\n",
    "    \"\"\"\n",
    "    Faz merge inteligente de todos os sub-lotes de uma categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"🔗 Fazendo merge da categoria: {categoria_key}\")\n",
    "        logging.info(f\"   📦 Sub-lotes a processar: {len(sublotes_categoria)}\")\n",
    "        \n",
    "        # Consolidar todos os DataFrames dos sub-lotes\n",
    "        dfs_sublotes = []\n",
    "        for sublote in sublotes_categoria:\n",
    "            if 'dataframe' in sublote and sublote['dataframe'] is not None:\n",
    "                df_temp = sublote['dataframe'].copy()\n",
    "                df_temp['sublote_origem'] = sublote['arquivo_saida']\n",
    "                dfs_sublotes.append(df_temp)\n",
    "        \n",
    "        if not dfs_sublotes:\n",
    "            logging.error(f\"❌ Nenhum DataFrame válido para categoria {categoria_key}\")\n",
    "            return None\n",
    "        \n",
    "        # Concatenar todos os sub-lotes\n",
    "        df_categoria_completa = pd.concat(dfs_sublotes, ignore_index=True)\n",
    "        \n",
    "        # Renumerar grupos para evitar conflitos\n",
    "        df_categoria_completa['grupo_id_original'] = df_categoria_completa['grupo_id']\n",
    "        df_categoria_completa['grupo_id_global'] = 0\n",
    "        \n",
    "        # Lógica de merge simples: manter grupos únicos por sub-lote\n",
    "        grupo_contador = 1\n",
    "        \n",
    "        for sublote_idx, sublote in enumerate(sublotes_categoria):\n",
    "            df_sublote = dfs_sublotes[sublote_idx]\n",
    "            grupos_sublote = df_sublote[df_sublote['grupo_id'] > 0]['grupo_id'].unique()\n",
    "            \n",
    "            for grupo_id in grupos_sublote:\n",
    "                # Atribuir novo ID global\n",
    "                mask = (df_categoria_completa['sublote_origem'] == sublote['arquivo_saida']) & \\\n",
    "                       (df_categoria_completa['grupo_id_original'] == grupo_id)\n",
    "                df_categoria_completa.loc[mask, 'grupo_id_global'] = grupo_contador\n",
    "                grupo_contador += 1\n",
    "        \n",
    "        # Remover duplicatas (projetos que apareceram em múltiplos sub-lotes)\n",
    "        df_final = df_categoria_completa.drop_duplicates(subset=['projeto_id'], keep='first')\n",
    "        \n",
    "        # Limpar colunas auxiliares\n",
    "        df_final = df_final.drop(['sublote_origem', 'grupo_id_original'], axis=1)\n",
    "        \n",
    "        grupos_finais = df_final[df_final['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "        projetos_agrupados = len(df_final[df_final['grupo_id_global'] > 0])\n",
    "        \n",
    "        logging.info(f\"✅ Merge concluído para {categoria_key}:\")\n",
    "        logging.info(f\"   📊 Projetos finais: {len(df_final)}\")\n",
    "        logging.info(f\"   🏷️ Grupos após merge: {grupos_finais}\")\n",
    "        logging.info(f\"   📈 Projetos agrupados: {projetos_agrupados}\")\n",
    "        \n",
    "        return {\n",
    "            'dataframe': df_final,\n",
    "            'categoria': categoria_key,\n",
    "            'grupos_finais': grupos_finais,\n",
    "            'projetos_totais': len(df_final),\n",
    "            'projetos_agrupados': projetos_agrupados,\n",
    "            'sublotes_originais': len(sublotes_categoria)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro no merge da categoria {categoria_key}: {e}\")\n",
    "        return None\n",
    "\n",
    "def consolidar_resultados_completos(resultados_processados, df_processado, grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    Consolida TODOS os resultados: multianuais automáticos + grupos da LLM + merge de sub-lotes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"🔄 Iniciando consolidação completa...\")\n",
    "        \n",
    "        # ETAPA 1: Processar merge dos sub-lotes (se necessário)\n",
    "        if resultados_processados:\n",
    "            resultados_merge = processar_merge_completo(resultados_processados)\n",
    "            logging.info(f\"✅ Merge de sub-lotes concluído: {len(resultados_merge)} categorias\")\n",
    "        else:\n",
    "            resultados_merge = []\n",
    "            logging.info(\"ℹ️ Nenhum resultado da LLM para fazer merge\")\n",
    "        \n",
    "        # ETAPA 2: Consolidar resultados da LLM\n",
    "        dataframes_llm = []\n",
    "        if resultados_merge:\n",
    "            for resultado in resultados_merge:\n",
    "                if 'dataframe' in resultado and resultado['dataframe'] is not None:\n",
    "                    df_temp = resultado['dataframe'].copy()\n",
    "                    df_temp['origem_agrupamento'] = 'LLM'\n",
    "                    df_temp['categoria_processamento'] = resultado.get('categoria', 'llm_categoria')\n",
    "                    dataframes_llm.append(df_temp)\n",
    "        \n",
    "        # ETAPA 3: Criar DataFrame dos grupos multianuais automáticos\n",
    "        df_multianuais_completo = df_processado[df_processado['eh_multianual']].copy()\n",
    "        \n",
    "        if len(df_multianuais_completo) > 0:\n",
    "            # Mapear grupos multianuais para formato padrão\n",
    "            df_grupos_multianuais = []\n",
    "            \n",
    "            for grupo in grupos_multianuais:\n",
    "                grupo_id = grupo['grupo_id_multianual']\n",
    "                indices = grupo['indices_df']\n",
    "                \n",
    "                # Buscar registros do grupo no df_processado\n",
    "                registros_grupo = df_processado.loc[df_processado.index.isin(indices)]\n",
    "                \n",
    "                for idx, registro in registros_grupo.iterrows():\n",
    "                    # Extrair ID único do projeto da coluna 'projeto'\n",
    "                    projeto_texto = str(registro.get('projeto', ''))\n",
    "                    \n",
    "                    # Buscar ID único entre ' ID ÚNICO: ' e ' NOME: '\n",
    "                    import re\n",
    "                    match_id = re.search(r'ID ÚNICO:\\s*([^:]+?)\\s+NOME:', projeto_texto)\n",
    "                    \n",
    "                    if match_id:\n",
    "                        projeto_id = match_id.group(1).strip()\n",
    "                    else:\n",
    "                        # Fallback caso não encontre o padrão\n",
    "                        projeto_id = f\"PROJ_{registro.get('id_empresa_ano', idx)}_{idx}\"\n",
    "                        logging.warning(f\"⚠️ ID único não encontrado para registro multianual {idx}, usando fallback\")\n",
    "                    \n",
    "                    grupo_row = {\n",
    "                        'grupo_id_global': grupo_id,\n",
    "                        'projeto_id': projeto_id,\n",
    "                        'ano_referencia': registro['ano_referencia'],\n",
    "                        'setor': registro['setor'],\n",
    "                        'natureza': registro['natureza'],\n",
    "                        'tipo_pesquisa': registro['tipo_pesquisa'],\n",
    "                        'origem_agrupamento': 'MULTIANUAL_AUTO',\n",
    "                        'categoria_processamento': f\"multianual_{registro['setor']}_{registro['natureza']}\",\n",
    "                        'grupo_multianual_id': grupo_id,\n",
    "                        'anos_grupo': registro['anos_grupo_multianual'],\n",
    "                        'empresa': registro.get('empresa', ''),\n",
    "                        'projeto': registro.get('projeto', '')\n",
    "                    }\n",
    "                    df_grupos_multianuais.append(grupo_row)\n",
    "            \n",
    "            df_multianuais_formatado = pd.DataFrame(df_grupos_multianuais)\n",
    "            logging.info(f\"✅ Grupos multianuais formatados: {len(df_multianuais_formatado)} registros\")\n",
    "        else:\n",
    "            df_multianuais_formatado = pd.DataFrame()\n",
    "            logging.info(\"ℹ️ Nenhum projeto multianual encontrado\")\n",
    "        \n",
    "        # ETAPA 4: Consolidar tudo\n",
    "        dataframes_finais = []\n",
    "        \n",
    "        # Adicionar resultados da LLM\n",
    "        if dataframes_llm:\n",
    "            dataframes_finais.extend(dataframes_llm)\n",
    "            logging.info(f\"✅ Adicionados {len(dataframes_llm)} DataFrames da LLM\")\n",
    "        \n",
    "        # Adicionar grupos multianuais\n",
    "        if len(df_multianuais_formatado) > 0:\n",
    "            dataframes_finais.append(df_multianuais_formatado)\n",
    "            logging.info(f\"✅ Adicionados grupos multianuais\")\n",
    "        \n",
    "        if not dataframes_finais:\n",
    "            logging.error(\"❌ Nenhum resultado para consolidar\")\n",
    "            return None\n",
    "        \n",
    "        # Concatenar todos os resultados\n",
    "        df_consolidado_final = pd.concat(dataframes_finais, ignore_index=True, sort=False)\n",
    "        \n",
    "        # ETAPA 5: Renumeração global dos grupos\n",
    "        df_consolidado_final['grupo_id_final'] = 0\n",
    "        contador_global = 1\n",
    "        \n",
    "        # Manter IDs multianuais como estão (já são únicos)\n",
    "        mask_multianuais = df_consolidado_final['origem_agrupamento'] == 'MULTIANUAL_AUTO'\n",
    "        grupos_multianuais_unicos = df_consolidado_final[mask_multianuais]['grupo_id_global'].unique()\n",
    "        \n",
    "        # Mapear grupos multianuais\n",
    "        for grupo_multi in grupos_multianuais_unicos:\n",
    "            mask_grupo = mask_multianuais & (df_consolidado_final['grupo_id_global'] == grupo_multi)\n",
    "            df_consolidado_final.loc[mask_grupo, 'grupo_id_final'] = contador_global\n",
    "            contador_global += 1\n",
    "        \n",
    "        # Mapear grupos da LLM por categoria\n",
    "        mask_llm = df_consolidado_final['origem_agrupamento'] == 'LLM'\n",
    "        if mask_llm.any():\n",
    "            for categoria in df_consolidado_final[mask_llm]['categoria_processamento'].unique():\n",
    "                mask_categoria = mask_llm & (df_consolidado_final['categoria_processamento'] == categoria)\n",
    "                grupos_categoria = df_consolidado_final[mask_categoria & (df_consolidado_final['grupo_id_global'] > 0)]['grupo_id_global'].unique()\n",
    "                \n",
    "                for grupo_id in grupos_categoria:\n",
    "                    mask_grupo = mask_categoria & (df_consolidado_final['grupo_id_global'] == grupo_id)\n",
    "                    df_consolidado_final.loc[mask_grupo, 'grupo_id_final'] = contador_global\n",
    "                    contador_global += 1\n",
    "        \n",
    "        # ETAPA 6: Gerar estatísticas consolidadas\n",
    "        stats_consolidacao = {\n",
    "            'timestamp': timestamp,\n",
    "            'total_projetos': len(df_consolidado_final),\n",
    "            'projetos_multianuais_auto': len(df_consolidado_final[df_consolidado_final['origem_agrupamento'] == 'MULTIANUAL_AUTO']),\n",
    "            'projetos_llm': len(df_consolidado_final[df_consolidado_final['origem_agrupamento'] == 'LLM']),\n",
    "            'total_grupos_finais': df_consolidado_final[df_consolidado_final['grupo_id_final'] > 0]['grupo_id_final'].nunique(),\n",
    "            'projetos_agrupados_total': len(df_consolidado_final[df_consolidado_final['grupo_id_final'] > 0]),\n",
    "            'projetos_isolados': len(df_consolidado_final[df_consolidado_final['grupo_id_final'] == 0]),\n",
    "            'grupos_multianuais': len(grupos_multianuais_unicos) if mask_multianuais.any() else 0,\n",
    "            'grupos_llm': len(df_consolidado_final[mask_llm & (df_consolidado_final['grupo_id_final'] > 0)]['grupo_id_final'].unique()) if mask_llm.any() else 0\n",
    "        }\n",
    "        \n",
    "        stats_consolidacao['taxa_agrupamento_total'] = (stats_consolidacao['projetos_agrupados_total'] / stats_consolidacao['total_projetos']) * 100 if stats_consolidacao['total_projetos'] > 0 else 0\n",
    "        \n",
    "        logging.info(f\"📊 Consolidação concluída:\")\n",
    "        logging.info(f\"   📋 Total de projetos: {stats_consolidacao['total_projetos']:,}\")\n",
    "        logging.info(f\"   🔗 Projetos multianuais: {stats_consolidacao['projetos_multianuais_auto']:,}\")\n",
    "        logging.info(f\"   🤖 Projetos da LLM: {stats_consolidacao['projetos_llm']:,}\")\n",
    "        logging.info(f\"   🏷️ Grupos finais: {stats_consolidacao['total_grupos_finais']}\")\n",
    "        logging.info(f\"   📈 Taxa de agrupamento: {stats_consolidacao['taxa_agrupamento_total']:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            'dataframe_consolidado': df_consolidado_final,\n",
    "            'estatisticas': stats_consolidacao\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro na consolidação completa: {e}\")\n",
    "        return None\n",
    "\n",
    "def salvar_resultados_consolidados_finais(resultado_consolidacao, timestamp):\n",
    "    \"\"\"\n",
    "    Salva todos os resultados consolidados finais\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not resultado_consolidacao:\n",
    "            return None\n",
    "        \n",
    "        df_final = resultado_consolidacao['dataframe_consolidado']\n",
    "        stats = resultado_consolidacao['estatisticas']\n",
    "        \n",
    "        # Arquivo principal consolidado\n",
    "        arquivo_consolidado = f'resultados_agrupamento/GRUPOS_FINAL_COMPLETO_{timestamp}.csv'\n",
    "        df_final.to_csv(arquivo_consolidado, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Estatísticas detalhadas\n",
    "        arquivo_stats = f'resultados_agrupamento/estatisticas_consolidacao_final_{timestamp}.json'\n",
    "        with open(arquivo_stats, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=2, ensure_ascii=False, default=str)\n",
    "        \n",
    "        # Relatório resumido por origem\n",
    "        resumo_origem = df_final.groupby('origem_agrupamento').agg({\n",
    "            'grupo_id_final': lambda x: (x > 0).sum(),  # projetos agrupados\n",
    "            'projeto_id': 'count'  # total projetos\n",
    "        }).reset_index()\n",
    "        resumo_origem.columns = ['origem_agrupamento', 'projetos_agrupados', 'total_projetos']\n",
    "        resumo_origem['taxa_agrupamento'] = (resumo_origem['projetos_agrupados'] / resumo_origem['total_projetos']) * 100\n",
    "        \n",
    "        arquivo_resumo = f'resultados_agrupamento/resumo_por_origem_{timestamp}.csv'\n",
    "        resumo_origem.to_csv(arquivo_resumo, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Relatório de grupos por tamanho\n",
    "        distribuicao_grupos = df_final[df_final['grupo_id_final'] > 0].groupby('grupo_id_final').size().reset_index(name='tamanho_grupo')\n",
    "        distribuicao_stats = distribuicao_grupos['tamanho_grupo'].describe()\n",
    "        \n",
    "        arquivo_distribuicao = f'resultados_agrupamento/distribuicao_grupos_{timestamp}.csv'\n",
    "        distribuicao_grupos.to_csv(arquivo_distribuicao, index=False, encoding='utf-8')\n",
    "        \n",
    "        logging.info(f\"💾 Resultados consolidados finais salvos:\")\n",
    "        logging.info(f\"   📄 Arquivo principal: {arquivo_consolidado}\")\n",
    "        logging.info(f\"   📊 Estatísticas: {arquivo_stats}\")\n",
    "        logging.info(f\"   📋 Resumo por origem: {arquivo_resumo}\")\n",
    "        logging.info(f\"   📈 Distribuição de grupos: {arquivo_distribuicao}\")\n",
    "        \n",
    "        return {\n",
    "            'arquivo_principal': arquivo_consolidado,\n",
    "            'estatisticas': arquivo_stats,\n",
    "            'resumo_origem': arquivo_resumo,\n",
    "            'distribuicao_grupos': arquivo_distribuicao,\n",
    "            'stats_distribuicao': distribuicao_stats.to_dict()\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao salvar resultados consolidados: {e}\")\n",
    "        return None\n",
    "\n",
    "# Preparar Chunk 8 adaptado\n",
    "print(\"\\n🔄 Chunk 8 ADAPTADO: Consolidação Final com Multianuais + Merge\")\n",
    "print(\"📋 Este chunk integra:\")\n",
    "print(\"   🔗 Grupos multianuais (ligação automática)\")\n",
    "print(\"   🤖 Grupos da LLM (análise de similaridade)\")\n",
    "print(\"   📦 Merge de sub-lotes (unificação inteligente)\")\n",
    "\n",
    "def executar_consolidacao_completa(resultados_processados, df_processado, grupos_multianuais, timestamp):\n",
    "    \"\"\"\n",
    "    Função principal para executar consolidação completa\n",
    "    \"\"\"\n",
    "    if not any([resultados_processados, grupos_multianuais, df_processado is not None]):\n",
    "        print(\"⚠️ Nenhum resultado disponível para consolidação\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🔄 Iniciando consolidação completa...\")\n",
    "    \n",
    "    # Consolidar todos os resultados\n",
    "    resultado_consolidacao = consolidar_resultados_completos(\n",
    "        resultados_processados, df_processado, grupos_multianuais, timestamp\n",
    "    )\n",
    "    \n",
    "    if resultado_consolidacao:\n",
    "        # Salvar resultados finais\n",
    "        arquivos_salvos = salvar_resultados_consolidados_finais(resultado_consolidacao, timestamp)\n",
    "        \n",
    "        stats = resultado_consolidacao['estatisticas']\n",
    "        print(f\"✅ Consolidação completa concluída:\")\n",
    "        print(f\"   📊 Total de projetos: {stats['total_projetos']:,}\")\n",
    "        print(f\"   🔗 Multianuais automáticos: {stats['projetos_multianuais_auto']:,}\")\n",
    "        print(f\"   🤖 Analisados por LLM: {stats['projetos_llm']:,}\")\n",
    "        print(f\"   🏷️ Grupos finais: {stats['total_grupos_finais']}\")\n",
    "        print(f\"   📈 Taxa de agrupamento total: {stats['taxa_agrupamento_total']:.1f}%\")\n",
    "        \n",
    "        if arquivos_salvos:\n",
    "            print(f\"   📄 Arquivo final: {arquivos_salvos['arquivo_principal']}\")\n",
    "        \n",
    "        return {\n",
    "            'resultado_consolidacao': resultado_consolidacao,\n",
    "            'arquivos_salvos': arquivos_salvos\n",
    "        }\n",
    "    else:\n",
    "        print(\"❌ Falha na consolidação completa\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Chunk 8 preparado - funções de consolidação completa carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feda162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHUNK 9: Validação e Qualidade\n",
    "Valida a qualidade dos agrupamentos e gera métricas de avaliação\n",
    "\"\"\"\n",
    "\n",
    "def analisar_qualidade_grupos(df_consolidado, df_clean):\n",
    "    \"\"\"\n",
    "    Analisa a qualidade dos grupos formados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        relatorio_qualidade = {}\n",
    "        \n",
    "        # 1. Análise de distribuição dos grupos\n",
    "        grupos_validos = df_consolidado[df_consolidado['grupo_id_global'] > 0]\n",
    "        distribuicao_tamanhos = grupos_validos.groupby('grupo_id_global').size()\n",
    "        \n",
    "        relatorio_qualidade['distribuicao_grupos'] = {\n",
    "            'total_grupos': len(distribuicao_tamanhos),\n",
    "            'tamanho_medio': distribuicao_tamanhos.mean(),\n",
    "            'tamanho_mediano': distribuicao_tamanhos.median(),\n",
    "            'maior_grupo': distribuicao_tamanhos.max(),\n",
    "            'menor_grupo': distribuicao_tamanhos.min(),\n",
    "            'grupos_por_tamanho': distribuicao_tamanhos.value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        # 2. Análise por setor/categoria\n",
    "        analise_categorias = []\n",
    "        for (setor, natureza, tipo), grupo_cat in df_consolidado.groupby(['setor', 'natureza', 'tipo_pesquisa']):\n",
    "            grupos_formados = grupo_cat[grupo_cat['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "            taxa_agrupamento = len(grupo_cat[grupo_cat['grupo_id_global'] > 0]) / len(grupo_cat) * 100\n",
    "            \n",
    "            analise_cat = {\n",
    "                'setor': setor,\n",
    "                'natureza': natureza,\n",
    "                'tipo_pesquisa': tipo,\n",
    "                'total_projetos': len(grupo_cat),\n",
    "                'grupos_formados': grupos_formados,\n",
    "                'projetos_agrupados': len(grupo_cat[grupo_cat['grupo_id_global'] > 0]),\n",
    "                'taxa_agrupamento': taxa_agrupamento,\n",
    "                'eficiencia_agrupamento': grupos_formados / len(grupo_cat) if len(grupo_cat) > 0 else 0\n",
    "            }\n",
    "            analise_categorias.append(analise_cat)\n",
    "        \n",
    "        relatorio_qualidade['analise_por_categoria'] = analise_categorias\n",
    "        \n",
    "        # 3. Detecção de possíveis problemas\n",
    "        problemas_detectados = []\n",
    "        \n",
    "        # Grupos muito grandes (possível super-agrupamento)\n",
    "        grupos_grandes = distribuicao_tamanhos[distribuicao_tamanhos > 10]\n",
    "        if len(grupos_grandes) > 0:\n",
    "            problemas_detectados.append({\n",
    "                'tipo': 'super_agrupamento',\n",
    "                'descricao': f'{len(grupos_grandes)} grupos com mais de 10 projetos',\n",
    "                'grupos_afetados': grupos_grandes.index.tolist()\n",
    "            })\n",
    "        \n",
    "        # Taxa de agrupamento muito baixa por categoria\n",
    "        categorias_baixa_taxa = [cat for cat in analise_categorias if cat['taxa_agrupamento'] < 20]\n",
    "        if categorias_baixa_taxa:\n",
    "            problemas_detectados.append({\n",
    "                'tipo': 'baixa_taxa_agrupamento',\n",
    "                'descricao': f'{len(categorias_baixa_taxa)} categorias com taxa < 20%',\n",
    "                'categorias_afetadas': categorias_baixa_taxa\n",
    "            })\n",
    "        \n",
    "        relatorio_qualidade['problemas_detectados'] = problemas_detectados\n",
    "        \n",
    "        logging.info(f\"📊 Qualidade analisada: {len(distribuicao_tamanhos)} grupos válidos\")\n",
    "        logging.info(f\"⚠️ Problemas detectados: {len(problemas_detectados)}\")\n",
    "        \n",
    "        return relatorio_qualidade\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro na análise de qualidade: {e}\")\n",
    "        return None\n",
    "\n",
    "def gerar_amostras_grupos(df_consolidado, df_clean, num_amostras=5):\n",
    "    \"\"\"\n",
    "    Gera amostras de grupos para validação manual\n",
    "    \"\"\"\n",
    "    try:\n",
    "        amostras = []\n",
    "        grupos_validos = df_consolidado[df_consolidado['grupo_id_global'] > 0]\n",
    "        \n",
    "        # Selecionar grupos de diferentes tamanhos\n",
    "        distribuicao_tamanhos = grupos_validos.groupby('grupo_id_global').size()\n",
    "        grupos_pequenos = distribuicao_tamanhos[distribuicao_tamanhos == 2].head(2).index\n",
    "        grupos_medios = distribuicao_tamanhos[(distribuicao_tamanhos >= 3) & (distribuicao_tamanhos <= 5)].head(2).index\n",
    "        grupos_grandes = distribuicao_tamanhos[distribuicao_tamanhos > 5].head(1).index\n",
    "        \n",
    "        grupos_amostra = list(grupos_pequenos) + list(grupos_medios) + list(grupos_grandes)\n",
    "        \n",
    "        for grupo_id in grupos_amostra[:num_amostras]:\n",
    "            projetos_grupo = grupos_validos[grupos_validos['grupo_id_global'] == grupo_id]\n",
    "            \n",
    "            # Buscar detalhes dos projetos no DataFrame original\n",
    "            detalhes_projetos = []\n",
    "            for _, projeto in projetos_grupo.iterrows():\n",
    "                # Tentar encontrar projeto correspondente no df_clean\n",
    "                projeto_id = projeto['projeto_id']\n",
    "                \n",
    "                # Buscar no df_clean (pode precisar ajustar a lógica de matching)\n",
    "                projeto_detalhes = {\n",
    "                    'projeto_id': projeto_id,\n",
    "                    'setor': projeto['setor'],\n",
    "                    'natureza': projeto['natureza'],\n",
    "                    'tipo_pesquisa': projeto['tipo_pesquisa'],\n",
    "                    'ano': projeto['ano_referencia']\n",
    "                }\n",
    "                \n",
    "                # Tentar buscar projeto completo (simplificado para exemplo)\n",
    "                try:\n",
    "                    # Aqui você pode implementar lógica mais sofisticada de matching\n",
    "                    matches = df_clean[\n",
    "                        (df_clean['setor'] == projeto['setor']) &\n",
    "                        (df_clean['ano_referencia'] == projeto['ano_referencia'])\n",
    "                    ]\n",
    "                    if len(matches) > 0:\n",
    "                        primeiro_match = matches.iloc[0]\n",
    "                        projeto_detalhes['projeto_preview'] = primeiro_match['projeto'][:200] + '...'\n",
    "                        projeto_detalhes['resultados_preview'] = str(primeiro_match.get('projeto_resultados', ''))[:150] + '...'\n",
    "                except:\n",
    "                    projeto_detalhes['projeto_preview'] = 'Detalhes não encontrados'\n",
    "                    projeto_detalhes['resultados_preview'] = 'N/A'\n",
    "                \n",
    "                detalhes_projetos.append(projeto_detalhes)\n",
    "            \n",
    "            amostra = {\n",
    "                'grupo_id': int(grupo_id),\n",
    "                'tamanho_grupo': len(projetos_grupo),\n",
    "                'combinacao': {\n",
    "                    'setor': projetos_grupo.iloc[0]['setor'],\n",
    "                    'natureza': projetos_grupo.iloc[0]['natureza'],\n",
    "                    'tipo_pesquisa': projetos_grupo.iloc[0]['tipo_pesquisa'],\n",
    "                    'ano': projetos_grupo.iloc[0]['ano_referencia']\n",
    "                },\n",
    "                'projetos': detalhes_projetos\n",
    "            }\n",
    "            amostras.append(amostra)\n",
    "        \n",
    "        logging.info(f\"📋 Geradas {len(amostras)} amostras para validação\")\n",
    "        return amostras\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao gerar amostras: {e}\")\n",
    "        return []\n",
    "\n",
    "def calcular_metricas_agrupamento(df_consolidado):\n",
    "    \"\"\"\n",
    "    Calcula métricas quantitativas do agrupamento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metricas = {}\n",
    "        \n",
    "        total_projetos = len(df_consolidado)\n",
    "        projetos_agrupados = len(df_consolidado[df_consolidado['grupo_id_global'] > 0])\n",
    "        total_grupos = df_consolidado[df_consolidado['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "        \n",
    "        # Métricas básicas\n",
    "        metricas['cobertura'] = projetos_agrupados / total_projetos if total_projetos > 0 else 0\n",
    "        metricas['densidade_media'] = projetos_agrupados / total_grupos if total_grupos > 0 else 0\n",
    "        metricas['eficiencia'] = total_grupos / total_projetos if total_projetos > 0 else 0\n",
    "        \n",
    "        # Distribuição por tamanho\n",
    "        distribuicao = df_consolidado[df_consolidado['grupo_id_global'] > 0].groupby('grupo_id_global').size()\n",
    "        metricas['coeficiente_variacao_tamanho'] = distribuicao.std() / distribuicao.mean() if distribuicao.mean() > 0 else 0\n",
    "        \n",
    "        # Métricas por categoria\n",
    "        metricas_por_categoria = {}\n",
    "        for (setor, natureza), grupo_cat in df_consolidado.groupby(['setor', 'natureza']):\n",
    "            cat_key = f\"{setor}_{natureza}\"\n",
    "            grupos_cat = grupo_cat[grupo_cat['grupo_id_global'] > 0]['grupo_id_global'].nunique()\n",
    "            projetos_cat = len(grupo_cat)\n",
    "            \n",
    "            metricas_por_categoria[cat_key] = {\n",
    "                'total_projetos': projetos_cat,\n",
    "                'grupos_formados': grupos_cat,\n",
    "                'taxa_agrupamento': len(grupo_cat[grupo_cat['grupo_id_global'] > 0]) / projetos_cat if projetos_cat > 0 else 0,\n",
    "                'produtividade': grupos_cat / projetos_cat if projetos_cat > 0 else 0\n",
    "            }\n",
    "        \n",
    "        metricas['por_categoria'] = metricas_por_categoria\n",
    "        \n",
    "        logging.info(f\"📊 Métricas calculadas:\")\n",
    "        logging.info(f\"   📈 Cobertura: {metricas['cobertura']:.2%}\")\n",
    "        logging.info(f\"   🎯 Densidade média: {metricas['densidade_media']:.1f} projetos/grupo\")\n",
    "        logging.info(f\"   ⚡ Eficiência: {metricas['eficiencia']:.3f}\")\n",
    "        \n",
    "        return metricas\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao calcular métricas: {e}\")\n",
    "        return None\n",
    "\n",
    "def gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp):\n",
    "    \"\"\"\n",
    "    Gera relatório completo de validação\n",
    "    \"\"\"\n",
    "    try:\n",
    "        relatorio_completo = {\n",
    "            'metadata': {\n",
    "                'timestamp_geracao': datetime.now().isoformat(),\n",
    "                'timestamp_processamento': timestamp,\n",
    "                'versao_relatorio': '1.0'\n",
    "            },\n",
    "            'qualidade': relatorio_qualidade,\n",
    "            'metricas': metricas,\n",
    "            'amostras_validacao': amostras,\n",
    "            'recomendacoes': []\n",
    "        }\n",
    "        \n",
    "        # Gerar recomendações baseadas na análise\n",
    "        recomendacoes = []\n",
    "        \n",
    "        if metricas and metricas['cobertura'] < 0.5:\n",
    "            recomendacoes.append({\n",
    "                'tipo': 'baixa_cobertura',\n",
    "                'descricao': f\"Cobertura de agrupamento baixa ({metricas['cobertura']:.1%}). Considere relaxar critérios de similaridade.\",\n",
    "                'prioridade': 'alta'\n",
    "            })\n",
    "        \n",
    "        if metricas and metricas['densidade_media'] > 8:\n",
    "            recomendacoes.append({\n",
    "                'tipo': 'grupos_grandes',\n",
    "                'descricao': f\"Grupos muito grandes (média {metricas['densidade_media']:.1f}). Considere critérios mais rigorosos.\",\n",
    "                'prioridade': 'media'\n",
    "            })\n",
    "        \n",
    "        if relatorio_qualidade and 'problemas_detectados' in relatorio_qualidade:\n",
    "            for problema in relatorio_qualidade['problemas_detectados']:\n",
    "                if problema['tipo'] == 'super_agrupamento':\n",
    "                    recomendacoes.append({\n",
    "                        'tipo': 'revisao_manual',\n",
    "                        'descricao': f\"Revisar manualmente grupos com >10 projetos: {problema['grupos_afetados']}\",\n",
    "                        'prioridade': 'alta'\n",
    "                    })\n",
    "        \n",
    "        relatorio_completo['recomendacoes'] = recomendacoes\n",
    "        \n",
    "        # Salvar relatório\n",
    "        arquivo_relatorio = f'resultados_agrupamento/relatorio_validacao_{timestamp}.json'\n",
    "        with open(arquivo_relatorio, 'w', encoding='utf-8') as f:\n",
    "            json.dump(relatorio_completo, f, indent=2, ensure_ascii=False, default=str)\n",
    "        \n",
    "        # Gerar versão resumida em texto\n",
    "        arquivo_resumo = f'resultados_agrupamento/resumo_validacao_{timestamp}.txt'\n",
    "        with open(arquivo_resumo, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"RELATÓRIO DE VALIDAÇÃO - AGRUPAMENTO DE PROJETOS\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            if metricas:\n",
    "                f.write(\"MÉTRICAS PRINCIPAIS:\\n\")\n",
    "                f.write(f\"• Cobertura: {metricas['cobertura']:.1%}\\n\")\n",
    "                f.write(f\"• Densidade média: {metricas['densidade_media']:.1f} projetos/grupo\\n\")\n",
    "                f.write(f\"• Eficiência: {metricas['eficiencia']:.3f}\\n\\n\")\n",
    "            \n",
    "            if relatorio_qualidade:\n",
    "                dist = relatorio_qualidade['distribuicao_grupos']\n",
    "                f.write(\"DISTRIBUIÇÃO DOS GRUPOS:\\n\")\n",
    "                f.write(f\"• Total de grupos: {dist['total_grupos']}\\n\")\n",
    "                f.write(f\"• Tamanho médio: {dist['tamanho_medio']:.1f}\\n\")\n",
    "                f.write(f\"• Maior grupo: {dist['maior_grupo']} projetos\\n\\n\")\n",
    "            \n",
    "            if recomendacoes:\n",
    "                f.write(\"RECOMENDAÇÕES:\\n\")\n",
    "                for i, rec in enumerate(recomendacoes, 1):\n",
    "                    f.write(f\"{i}. [{rec['prioridade'].upper()}] {rec['descricao']}\\n\")\n",
    "        \n",
    "        logging.info(f\"📋 Relatório de validação salvo: {arquivo_relatorio}\")\n",
    "        logging.info(f\"📄 Resumo salvo: {arquivo_resumo}\")\n",
    "        \n",
    "        return {\n",
    "            'relatorio_completo': arquivo_relatorio,\n",
    "            'resumo': arquivo_resumo,\n",
    "            'recomendacoes': recomendacoes\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Erro ao gerar relatório: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar validação e qualidade\n",
    "print(\"\\n🔄 Executando Chunk 9: Validação e Qualidade\")\n",
    "\n",
    "if 'df_consolidado' in locals() and df_consolidado is not None and 'df_clean' in locals():\n",
    "    print(\"🔍 Analisando qualidade dos agrupamentos...\")\n",
    "    \n",
    "    # Análise de qualidade\n",
    "    relatorio_qualidade = analisar_qualidade_grupos(df_consolidado, df_clean)\n",
    "    \n",
    "    # Cálculo de métricas\n",
    "    metricas = calcular_metricas_agrupamento(df_consolidado)\n",
    "    \n",
    "    # Geração de amostras\n",
    "    amostras = gerar_amostras_grupos(df_consolidado, df_clean)\n",
    "    \n",
    "    # Relatório de validação\n",
    "    if 'timestamp_final' in locals():\n",
    "        relatorio_final = gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp_final)\n",
    "    else:\n",
    "        timestamp_validacao = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        relatorio_final = gerar_relatorio_validacao(relatorio_qualidade, metricas, amostras, timestamp_validacao)\n",
    "    \n",
    "    print(f\"✅ Chunk 9 executado:\")\n",
    "    if metricas:\n",
    "        print(f\"   📈 Cobertura: {metricas['cobertura']:.1%}\")\n",
    "        print(f\"   🎯 Densidade: {metricas['densidade_media']:.1f} proj/grupo\")\n",
    "    if relatorio_qualidade:\n",
    "        print(f\"   🏷️ Grupos válidos: {relatorio_qualidade['distribuicao_grupos']['total_grupos']}\")\n",
    "    print(f\"   📋 Amostras geradas: {len(amostras)}\")\n",
    "    if relatorio_final and 'recomendacoes' in relatorio_final:\n",
    "        print(f\"   💡 Recomendações: {len(relatorio_final['recomendacoes'])}\")\n",
    "else:\n",
    "    print(\"⚠️ Chunk 9 ignorado: Dados consolidados não disponíveis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa2b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
