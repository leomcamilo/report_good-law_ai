{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ebf056",
   "metadata": {},
   "source": [
    "---\n",
    "title: Analise\n",
    "author: Leonardo Camilo\n",
    "execute:\n",
    "    echo: false\n",
    "    warnings: false\n",
    "    message: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b418bf3",
   "metadata": {},
   "source": [
    "Análise Detalhada: Analistas vs Pareceristas - Lei do Bem 2021\n",
    "==============================================================\n",
    "\n",
    "Este notebook analisa a relação entre as decisões dos analistas (fase DO)\n",
    "e dos pareceristas (fase Parecer) nos projetos da Lei do Bem.\n",
    "\n",
    "Perguntas a serem respondidas:\n",
    "1. Taxa de aprovação por analista\n",
    "2. Taxa de concordância DO → Parecer\n",
    "3. Reversões de decisão (Não Recomendado → Recomendado)\n",
    "4. Dispersão de áreas por analista\n",
    "5. Fichas individuais dos top 15 analistas\n",
    "6. Modelo preditivo de aprovação no Parecer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0676cd",
   "metadata": {},
   "source": [
    "# Análise de Decisões no Processo da Lei do Bem (2021): Analistas e Pareceristas\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Esta análise aprofundada explora as decisões tomadas por analistas e pareceristas no âmbito do programa Lei do Bem do MCTI, um dos principais instrumentos de fomento à inovação no Brasil. O estudo se baseia em um volume expressivo de dados, compreendendo 13.198 projetos analisados durante o ano de 2021. O objetivo geral é identificar padrões, inconsistências e insights nas avaliações, visando otimizar a eficiência, a isonomia e a previsibilidade do processo de concessão de incentivos fiscais para Pesquisa e Desenvolvimento (P&D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0cd0",
   "metadata": {},
   "source": [
    "## 2. Metodologia\n",
    "\n",
    "A análise foi conduzida a partir de um banco de dados consolidado contendo informações detalhadas sobre cada um dos 13.198 projetos do ano-base de 2021. As fontes de dados incluem os pareceres técnicos emitidos tanto pelo Ministério (fase DO) quanto pelos pesquisadores ad hoc (fase Parecer), além de metadados dos projetos, como áreas de conhecimento e informações textuais descritivas.\n",
    "As técnicas aplicadas envolveram desde a estatística descritiva, para quantificar taxas de aprovação e concordância, até a análise de dispersão para entender a distribuição de projetos entre os representantes do Ministério. Um dos pilares da metodologia foi o processamento de linguagem natural (PLN), utilizado para extrair insights dos campos textuais. Para isso, a biblioteca NLTK (Natural Language Toolkit) foi empregada para processar os textos em português, aplicando a remoção de stopwords (palavras comuns como \"de\", \"para\", \"com\") para focar nos termos mais relevantes de cada projeto.\n",
    "O conjunto de stopwords foi composto por 207 palavras do NLTK e um conjunto customizado de 71 termos específicos do domínio da Lei do Bem, totalizando 278 palavras removidas para garantir uma análise mais limpa e focada. Além disso, foi desenvolvido um modelo de Machine Learning para explorar a capacidade preditiva dos dados textuais em relação à aprovação final dos projetos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1374cca",
   "metadata": {},
   "source": [
    "### Análise de Analistas vs Pareceristas - Lei do Bem 2021\n",
    "\n",
    "**Data de Análise:** 22/07/2025\n",
    "\n",
    "**Ano Base dos Dados:** 2018 à 2023\n",
    "\n",
    "**Total de Projetos:** 13.198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# %% Imports e Configuração\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Baixar recursos necessários do NLTK\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Baixando punkt...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Baixando stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Configurar fonte para melhor visualização em PDF\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# %% Configuração de stopwords em português\n",
    "# Carregar stopwords padrão do NLTK em português\n",
    "stop_words_nltk = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Adicionar stopwords específicas do domínio Lei do Bem\n",
    "stop_words_dominio = {\n",
    "    # Verbos comuns\n",
    "    'realizar', 'desenvolver', 'criar', 'implementar', 'utilizar', 'aplicar', 'melhorar',\n",
    "    'analisar', 'estudar', 'avaliar', 'testar', 'produzir', 'fabricar', 'construir', 'usar', 'uso'\n",
    "    \n",
    "    # Preposições e conectivos adicionais\n",
    "    'através', 'mediante', 'partir', 'base', 'forma', 'modo', 'tipo', 'fase', 'etapa',\n",
    "    'objetivo', 'objetivos', 'finalidade', 'propósito', 'meta', 'metas',\n",
    "    \n",
    "    # Termos muito genéricos\n",
    "    'novo', 'nova', 'novos', 'novas', 'área', 'áreas', 'setor', 'setores',\n",
    "    'atividade', 'atividades', 'trabalho', 'trabalhos', 'serviço', 'serviços'\n",
    "}\n",
    "\n",
    "# Combinar todas as stopwords\n",
    "todas_stopwords = stop_words_nltk.union(stop_words_dominio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e62896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Funções de processamento de texto simplificadas\n",
    "def limpar_texto(texto):\n",
    "    \"\"\"Limpa e normaliza o texto\"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return \"\"\n",
    "    \n",
    "    # Converter para string e minúsculas\n",
    "    texto = str(texto).lower()\n",
    "    \n",
    "    # Remover caracteres especiais, mantendo espaços e letras\n",
    "    texto = re.sub(r'[^a-záàâãéèêíïóôõöúçñ\\s]', ' ', texto)\n",
    "    \n",
    "    # Remover espaços múltiplos\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    \n",
    "    return texto.strip()\n",
    "\n",
    "def analisar_texto_stopwords(texto, stopwords_set):\n",
    "    \"\"\"\n",
    "    Analisa um texto e retorna estatísticas sobre stopwords\n",
    "    \"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return {\n",
    "            'texto_original': '',\n",
    "            'texto_sem_stopwords': '',\n",
    "            'palavras_total': 0,\n",
    "            'palavras_sem_stopwords': 0,\n",
    "            'stopwords_encontradas': [],\n",
    "            'palavras_relevantes': [],\n",
    "            'reducao_percentual': 0\n",
    "        }\n",
    "    \n",
    "    # Converter para string primeiro para garantir\n",
    "    texto_str = str(texto)\n",
    "    \n",
    "    # Limpar texto\n",
    "    texto_limpo = limpar_texto(texto_str)\n",
    "    \n",
    "    # Tokenizar\n",
    "    palavras = texto_limpo.split()\n",
    "    palavras_total = len(palavras)\n",
    "    \n",
    "    # Filtrar stopwords\n",
    "    palavras_sem_stop = [p for p in palavras if p not in stopwords_set and len(p) > 2]\n",
    "    stopwords_encontradas = [p for p in palavras if p in stopwords_set]\n",
    "    \n",
    "    # Calcular redução\n",
    "    reducao = ((palavras_total - len(palavras_sem_stop)) / palavras_total * 100) if palavras_total > 0 else 0\n",
    "    \n",
    "    # Preparar texto original para retorno (truncado se muito longo)\n",
    "    texto_original_truncado = texto_str[:200] + '...' if len(texto_str) > 200 else texto_str\n",
    "    \n",
    "    return {\n",
    "        'texto_original': texto_original_truncado,\n",
    "        'texto_sem_stopwords': ' '.join(palavras_sem_stop),\n",
    "        'palavras_total': palavras_total,\n",
    "        'palavras_sem_stopwords': len(palavras_sem_stop),\n",
    "        'stopwords_encontradas': stopwords_encontradas,\n",
    "        'palavras_relevantes': palavras_sem_stop[:20],  # Top 20 palavras\n",
    "        'reducao_percentual': reducao\n",
    "    }\n",
    "\n",
    "def processar_campos_texto(df, campos, stopwords_set):\n",
    "    \"\"\"\n",
    "    Processa múltiplos campos de texto e retorna análise de stopwords\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for campo in campos:\n",
    "        if campo not in df.columns:\n",
    "            print(f\"⚠️ Campo {campo} não encontrado\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"📝 Processando {campo}...\")\n",
    "        \n",
    "        # Analisar cada texto\n",
    "        analises = df[campo].apply(lambda x: analisar_texto_stopwords(x, stopwords_set))\n",
    "        \n",
    "        # Extrair métricas\n",
    "        resultados[campo] = {\n",
    "            'df_analise': pd.DataFrame(list(analises)),\n",
    "            'reducao_media': np.mean([a['reducao_percentual'] for a in analises]),\n",
    "            'palavras_media_original': np.mean([a['palavras_total'] for a in analises]),\n",
    "            'palavras_media_filtrado': np.mean([a['palavras_sem_stopwords'] for a in analises])\n",
    "        }\n",
    "        \n",
    "        # Contar palavras mais frequentes após filtro\n",
    "        todas_palavras_relevantes = []\n",
    "        for analise in analises:\n",
    "            todas_palavras_relevantes.extend(analise['palavras_relevantes'])\n",
    "        \n",
    "        contador_palavras = Counter(todas_palavras_relevantes)\n",
    "        resultados[campo]['top_palavras'] = contador_palavras.most_common(20)\n",
    "        \n",
    "        # Contar stopwords mais comuns\n",
    "        todas_stopwords = []\n",
    "        for analise in analises:\n",
    "            todas_stopwords.extend(analise['stopwords_encontradas'])\n",
    "        \n",
    "        contador_stopwords = Counter(todas_stopwords)\n",
    "        resultados[campo]['top_stopwords'] = contador_stopwords.most_common(20)\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda857d",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abaab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Capítulo 1: Carregamento e Preparação dos Dados\n",
    "Análise da Lei do Bem - Ano Base 2021\n",
    "\n",
    "Este script realiza o carregamento inicial dos dados e prepara o dataset\n",
    "para análises posteriores, incluindo processamento de linguagem natural\n",
    "dos campos textuais.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Configuração visual-0\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================================================\n",
    "# SEÇÃO 1.1: CARREGAMENTO DO DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CAPÍTULO 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1.1 Carregamento do Dataset Principal\\n\")\n",
    "\n",
    "# Carregar arquivo CSV principal\n",
    "arquivo_dados = 'csv_longo/projetos_lei_do_bem_DETALHADO_LINHA_UNICA.csv'\n",
    "df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n",
    "\n",
    "# Estatísticas iniciais\n",
    "total_projetos = len(df)\n",
    "total_colunas = len(df.columns)\n",
    "\n",
    "print(f\"Dataset carregado com sucesso!\")\n",
    "print(f\"├── Total de projetos: {total_projetos:,}\")\n",
    "print(f\"└── Total de variáveis: {total_colunas}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SEÇÃO 1.2: SELEÇÃO DE VARIÁVEIS RELEVANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.2 Seleção de Variáveis Relevantes\\n\")\n",
    "\n",
    "# Definir grupos de colunas por categoria\n",
    "colunas_identificacao = [\n",
    "    'lst_idprenchimentosituacaoanalise', 'lst_norazaosocial', 'lst_nrcnpj',\n",
    "    'lst_noatividadeeconomica', 'daproj_nritem'\n",
    "]\n",
    "\n",
    "colunas_projeto = [\n",
    "    'daproj_noprojeto', 'daproj_dsprojeto', 'daproj_dsareaprojeto',\n",
    "    'daproj_dspalavrachave', 'daproj_dselementotecnologico',\n",
    "    'daproj_dsdesafiotecnologico', 'daproj_dsmetodologiautilizada'\n",
    "]\n",
    "\n",
    "colunas_ministerio = [\n",
    "    'do_saat_idunicopessoaanalise', 'do_taaproj_notipoavaliacaoanalise'\n",
    "]\n",
    "\n",
    "colunas_pesquisador = [\n",
    "    'p_taaproj_notipoavaliacaoanalise'\n",
    "]\n",
    "\n",
    "colunas_valores = [\n",
    "    'do_aat_vltotaldeclarado', 'do_aat_vltotalparecer'\n",
    "]\n",
    "\n",
    "# Combinar todas as colunas\n",
    "colunas_analise = (colunas_identificacao + colunas_projeto + \n",
    "                   colunas_ministerio + colunas_pesquisador + colunas_valores)\n",
    "\n",
    "# Filtrar apenas colunas existentes no dataset\n",
    "colunas_existentes = [col for col in colunas_analise if col in df.columns]\n",
    "df_analise = df[colunas_existentes].copy()\n",
    "\n",
    "print(f\"Variáveis selecionadas por categoria:\")\n",
    "print(f\"├── Identificação: {len([c for c in colunas_identificacao if c in colunas_existentes])}\")\n",
    "print(f\"├── Projeto: {len([c for c in colunas_projeto if c in colunas_existentes])}\")\n",
    "print(f\"├── Ministério: {len([c for c in colunas_ministerio if c in colunas_existentes])}\")\n",
    "print(f\"├── Pesquisador: {len([c for c in colunas_pesquisador if c in colunas_existentes])}\")\n",
    "print(f\"└── Valores: {len([c for c in colunas_valores if c in colunas_existentes])}\")\n",
    "print(f\"\\nTotal de variáveis selecionadas: {len(colunas_existentes)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SEÇÃO 1.3: ANÁLISE TEXTUAL E PROCESSAMENTO DE LINGUAGEM NATURAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.3 Análise Textual e Processamento de Linguagem Natural\\n\")\n",
    "\n",
    "# 1.3.1 Identificação de campos textuais\n",
    "campos_texto = {\n",
    "    'daproj_dsprojeto': 'Descrição do Projeto',\n",
    "    'daproj_dselementotecnologico': 'Elemento Tecnológico',\n",
    "    'daproj_dsdesafiotecnologico': 'Desafio Tecnológico',\n",
    "    'daproj_dsmetodologiautilizada': 'Metodologia Utilizada'\n",
    "}\n",
    "\n",
    "campos_texto_existentes = {k: v for k, v in campos_texto.items() if k in df_analise.columns}\n",
    "print(f\"Campos textuais identificados para análise: {len(campos_texto_existentes)}\")\n",
    "\n",
    "# 1.3.2 Configuração de stopwords\n",
    "print(\"\\nConfigurando conjunto de stopwords...\")\n",
    "\n",
    "# Baixar stopwords do NLTK se necessário\n",
    "try:\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Stopwords específicas do domínio Lei do Bem\n",
    "stopwords_dominio = {\n",
    "    'ano', 'base', 'projeto', 'projetos', 'empresa', 'empresas',\n",
    "    'desenvolvimento', 'pesquisa', 'inovação', 'tecnológica',\n",
    "    'realizar', 'realizado', 'realizada', 'realizados', 'realizadas',\n",
    "    'objetivo', 'objetivos', 'processo', 'processos', 'atividade',\n",
    "    'atividades', 'trabalho', 'trabalhos', 'forma', 'formas',\n",
    "    'através', 'partir', 'sendo', 'foram', 'seja', 'sejam',\n",
    "    'pode', 'podem', 'deve', 'devem', 'está', 'estão',\n",
    "    'fazer', 'feito', 'feita', 'ter', 'tem', 'tinha',\n",
    "    'uso', 'usar', 'usado', 'usada', 'novo', 'nova',\n",
    "    'novos', 'novas', 'ainda', 'apenas', 'assim', 'então'\n",
    "}\n",
    "\n",
    "todas_stopwords = stopwords_pt.union(stopwords_dominio)\n",
    "print(f\"├── Stopwords NLTK português: {len(stopwords_pt)}\")\n",
    "print(f\"├── Stopwords domínio específico: {len(stopwords_dominio)}\")\n",
    "print(f\"└── Total de stopwords: {len(todas_stopwords)}\")\n",
    "\n",
    "# 1.3.3 Função para processar texto\n",
    "def processar_texto(texto, stopwords_set):\n",
    "    \"\"\"\n",
    "    Processa um texto removendo stopwords e normalizando.\n",
    "    \n",
    "    Args:\n",
    "        texto: String com o texto a ser processado\n",
    "        stopwords_set: Conjunto de stopwords a remover\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicionário com texto processado e estatísticas\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return {\n",
    "            'texto_original': '',\n",
    "            'texto_limpo': '',\n",
    "            'palavras_originais': 0,\n",
    "            'palavras_limpas': 0,\n",
    "            'reducao_percentual': 0\n",
    "        }\n",
    "    \n",
    "    # Converter para string e lowercase\n",
    "    texto_str = str(texto).lower()\n",
    "    \n",
    "    # Tokenização simples\n",
    "    palavras_originais = texto_str.split()\n",
    "    num_palavras_originais = len(palavras_originais)\n",
    "    \n",
    "    # Remover stopwords\n",
    "    palavras_limpas = [p for p in palavras_originais if p not in stopwords_set]\n",
    "    num_palavras_limpas = len(palavras_limpas)\n",
    "    \n",
    "    # Calcular redução\n",
    "    reducao = 0 if num_palavras_originais == 0 else (\n",
    "        (num_palavras_originais - num_palavras_limpas) / num_palavras_originais * 100\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'texto_original': texto_str,\n",
    "        'texto_limpo': ' '.join(palavras_limpas),\n",
    "        'palavras_originais': num_palavras_originais,\n",
    "        'palavras_limpas': num_palavras_limpas,\n",
    "        'reducao_percentual': reducao\n",
    "    }\n",
    "\n",
    "# 1.3.4 Processar todos os campos textuais\n",
    "print(\"\\nProcessando campos textuais...\")\n",
    "\n",
    "resultados_processamento = {}\n",
    "\n",
    "for campo, nome in campos_texto_existentes.items():\n",
    "    print(f\"\\nProcessando: {nome}\")\n",
    "    \n",
    "    # Aplicar processamento\n",
    "    processados = df_analise[campo].apply(lambda x: processar_texto(x, todas_stopwords))\n",
    "    \n",
    "    # Extrair resultados\n",
    "    df_temp = pd.DataFrame(processados.tolist())\n",
    "    \n",
    "    # Calcular estatísticas\n",
    "    palavras_originais_media = df_temp['palavras_originais'].mean()\n",
    "    palavras_limpas_media = df_temp['palavras_limpas'].mean()\n",
    "    reducao_media = df_temp['reducao_percentual'].mean()\n",
    "    \n",
    "    # Contar palavras mais frequentes após limpeza\n",
    "    todas_palavras_limpas = ' '.join(df_temp['texto_limpo']).split()\n",
    "    contador_palavras = Counter(todas_palavras_limpas)\n",
    "    top_palavras = contador_palavras.most_common(20)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    resultados_processamento[campo] = {\n",
    "        'nome': nome,\n",
    "        'df_processado': df_temp,\n",
    "        'palavras_originais_media': palavras_originais_media,\n",
    "        'palavras_limpas_media': palavras_limpas_media,\n",
    "        'reducao_media': reducao_media,\n",
    "        'top_palavras': top_palavras\n",
    "    }\n",
    "    \n",
    "    # Adicionar colunas processadas ao dataframe principal\n",
    "    df_analise[f'{campo}_limpo'] = df_temp['texto_limpo']\n",
    "    df_analise[f'{campo}_num_palavras_limpo'] = df_temp['palavras_limpas']\n",
    "    \n",
    "    print(f\"├── Palavras médias (original): {palavras_originais_media:.1f}\")\n",
    "    print(f\"├── Palavras médias (limpo): {palavras_limpas_media:.1f}\")\n",
    "    print(f\"└── Redução média: {reducao_media:.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# SEÇÃO 1.4: VISUALIZAÇÕES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.4 Gerando Visualizações\\n\")\n",
    "\n",
    "# Figura 1: Análise de Redução por Stopwords\n",
    "fig1, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (campo, resultado) in enumerate(resultados_processamento.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histograma de redução percentual\n",
    "    df_vis = resultado['df_processado']\n",
    "    df_vis['reducao_percentual'].hist(bins=30, ax=ax, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    \n",
    "    # Adicionar linha de média\n",
    "    ax.axvline(resultado['reducao_media'], color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Média: {resultado[\"reducao_media\"]:.1f}%')\n",
    "    \n",
    "    # Configurar eixos e título\n",
    "    ax.set_title(f'Redução por Stopwords\\n{resultado[\"nome\"]}', fontsize=12, pad=10)\n",
    "    ax.set_xlabel('Redução Percentual (%)')\n",
    "    ax.set_ylabel('Frequência')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Figura 1: Análise de Redução por Stopwords nos Campos de Texto', \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figura 2: Top Palavras Relevantes\n",
    "fig2, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (campo, resultado) in enumerate(resultados_processamento.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Top 10 palavras\n",
    "    palavras = [p[0] for p in resultado['top_palavras'][:10]]\n",
    "    frequencias = [p[1] for p in resultado['top_palavras'][:10]]\n",
    "    \n",
    "    # Criar gráfico de barras horizontal\n",
    "    y_pos = np.arange(len(palavras))\n",
    "    bars = ax.barh(y_pos, frequencias, color='green', alpha=0.7)\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(palavras)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Frequência')\n",
    "    ax.set_title(f'Top 10 Palavras Relevantes\\n{resultado[\"nome\"]}', fontsize=12, pad=10)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for j, (bar, freq) in enumerate(zip(bars, frequencias)):\n",
    "        ax.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2, \n",
    "                f'{freq:,}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Figura 2: Top 10 Palavras Mais Relevantes por Campo', \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# SEÇÃO 1.5: PREPARAÇÃO FINAL DO DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.5 Preparação Final do Dataset\\n\")\n",
    "\n",
    "# Criar campo de texto combinado\n",
    "print(\"Criando campo de texto combinado...\")\n",
    "textos_combinados = []\n",
    "\n",
    "for idx in range(len(df_analise)):\n",
    "    partes = []\n",
    "    for campo in campos_texto_existentes.keys():\n",
    "        campo_limpo = f'{campo}_limpo'\n",
    "        if campo_limpo in df_analise.columns:\n",
    "            texto = str(df_analise[campo_limpo].iloc[idx])\n",
    "            if texto and texto != 'nan':\n",
    "                partes.append(texto)\n",
    "    \n",
    "    texto_combinado = ' '.join(partes)\n",
    "    textos_combinados.append(texto_combinado)\n",
    "\n",
    "df_analise['texto_combinado_limpo'] = textos_combinados\n",
    "\n",
    "# Estatísticas finais\n",
    "print(f\"\\nDataset preparado com sucesso!\")\n",
    "print(f\"├── Total de projetos: {len(df_analise):,}\")\n",
    "print(f\"├── Variáveis originais: {len(colunas_existentes)}\")\n",
    "print(f\"├── Variáveis criadas: {len([c for c in df_analise.columns if 'limpo' in c])}\")\n",
    "print(f\"└── Total de variáveis: {len(df_analise.columns)}\")\n",
    "\n",
    "# Exemplo de processamento\n",
    "print(\"\\nExemplo de Processamento (Projeto #1):\")\n",
    "print(\"-\" * 60)\n",
    "campo_exemplo = 'daproj_dsprojeto'\n",
    "if campo_exemplo in df_analise.columns:\n",
    "    texto_original = str(df_analise[campo_exemplo].iloc[0])[:150]\n",
    "    texto_limpo = str(df_analise[f'{campo_exemplo}_limpo'].iloc[0])[:150]\n",
    "    reducao = resultados_processamento[campo_exemplo]['df_processado']['reducao_percentual'].iloc[0]\n",
    "    \n",
    "    print(f\"Original: {texto_original}...\")\n",
    "    print(f\"Limpo: {texto_limpo}...\")\n",
    "    print(f\"Redução: {reducao:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CAPÍTULO 1 CONCLUÍDO - Dataset pronto para análise\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f30a9",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Estatísticas básicas\n",
    "# Verificar valores únicos nas colunas de decisão\n",
    "print(\"Valores únicos em 'do_taaproj_notipoavaliacaoanalise' (Pesquisador ad hoc):\")\n",
    "print(df_analise['do_taaproj_notipoavaliacaoanalise'].value_counts())\n",
    "\n",
    "print(\"\\n\\nValores únicos em 'p_taaproj_notipoavaliacaoanalise' (Ministério):\")\n",
    "print(df_analise['p_taaproj_notipoavaliacaoanalise'].value_counts())\n",
    "\n",
    "# Filtrar apenas projetos que passaram por ambas as fases\n",
    "df_completo = df_analise[\n",
    "    df_analise['do_taaproj_notipoavaliacaoanalise'].notna() & \n",
    "    df_analise['p_taaproj_notipoavaliacaoanalise'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n\\nProjetos com análise completa (Pesquisador + Ministério): {len(df_completo):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60976c",
   "metadata": {},
   "source": [
    "## Análise de Quadrante de Decisão\n",
    "\n",
    "Análise dos quadrantes de decisão entre Pesquisadores e Ministério."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar função para padronizar as decisões\n",
    "def padronizar_decisao(decisao):\n",
    "    if pd.isna(decisao):\n",
    "        return np.nan\n",
    "    decisao_str = str(decisao).strip().upper()\n",
    "    if 'RECOMENDADO' in decisao_str and 'NÃO' not in decisao_str:\n",
    "        return 'Recomendado'\n",
    "    elif 'NÃO RECOMENDADO' in decisao_str:\n",
    "        return 'Não Recomendado'\n",
    "    else:\n",
    "        return 'Outro'\n",
    "\n",
    "# Aplicar padronização\n",
    "df_completo['decisao_pesquisador'] = df_completo['do_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "df_completo['decisao_ministerio'] = df_completo['p_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "\n",
    "# Filtrar apenas registros com decisões válidas (Recomendado ou Não Recomendado)\n",
    "df_analise_quadrantes = df_completo[\n",
    "    (df_completo['decisao_pesquisador'].isin(['Recomendado', 'Não Recomendado'])) & \n",
    "    (df_completo['decisao_ministerio'].isin(['Recomendado', 'Não Recomendado']))\n",
    "].copy()\n",
    "\n",
    "# Criar análise de quadrantes\n",
    "print(\"=\" * 80)\n",
    "print(\"ANÁLISE DE QUADRANTES DE DECISÃO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar matriz de contingência (sem \"Outro\")\n",
    "matriz_decisoes = pd.crosstab(\n",
    "    df_analise_quadrantes['decisao_pesquisador'], \n",
    "    df_analise_quadrantes['decisao_ministerio'],\n",
    "    rownames=['Pesquisador (ad hoc)'],\n",
    "    colnames=['Ministério'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Matriz de Decisões:\")\n",
    "print(matriz_decisoes)\n",
    "\n",
    "# Calcular quadrantes específicos\n",
    "quad1 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Recomendado')])\n",
    "quad2 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Não Recomendado')])\n",
    "quad3 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Não Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Recomendado')])\n",
    "quad4 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Não Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Não Recomendado')])\n",
    "\n",
    "total_projetos_quad = quad1 + quad2 + quad3 + quad4\n",
    "\n",
    "# Mostrar informação sobre registros excluídos\n",
    "total_excluidos = len(df_completo) - len(df_analise_quadrantes)\n",
    "if total_excluidos > 0:\n",
    "    print(f\"\\n⚠️ {total_excluidos} projetos foram excluídos da análise por terem decisão 'Outro'\")\n",
    "\n",
    "print(\"\\n\\n📊 ANÁLISE POR QUADRANTES:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Quadrante 1 - Recomendado por AMBOS (Pesquisador E Ministério):\")\n",
    "print(f\"  → {quad1:,} projetos ({quad1/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 2 - Recomendado pelo Pesquisador, NÃO pelo Ministério:\")\n",
    "print(f\"  → {quad2:,} projetos ({quad2/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 3 - NÃO Recomendado pelo Pesquisador, SIM pelo Ministério:\")\n",
    "print(f\"  → {quad3:,} projetos ({quad3/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 4 - NÃO Recomendado por AMBOS:\")\n",
    "print(f\"  → {quad4:,} projetos ({quad4/total_projetos_quad*100:.1f}%)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total: {total_projetos_quad:,} projetos\")\n",
    "\n",
    "# Visualização dos quadrantes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gráfico 1: Matriz de calor\n",
    "matriz_prop = matriz_decisoes.iloc[:-1, :-1] / total_projetos_quad * 100\n",
    "sns.heatmap(matriz_prop, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Percentual (%)'}, ax=ax1,\n",
    "            annot_kws={'size': 14})\n",
    "ax1.set_title('Matriz de Decisões (%)', fontsize=16, pad=20)\n",
    "ax1.set_xlabel('Decisão do Ministério', fontsize=12)\n",
    "ax1.set_ylabel('Decisão do Pesquisador (ad hoc)', fontsize=12)\n",
    "\n",
    "# Adicionar valores absolutos\n",
    "for i in range(len(matriz_decisoes.index)-1):\n",
    "    for j in range(len(matriz_decisoes.columns)-1):\n",
    "        valor = matriz_decisoes.iloc[i, j]\n",
    "        ax1.text(j+0.5, i+0.7, f'({valor:,})', \n",
    "                ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Gráfico 2: Diagrama de quadrantes\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.axhline(y=0, color='black', linewidth=2)\n",
    "ax2.axvline(x=0, color='black', linewidth=2)\n",
    "\n",
    "# Desenhar quadrantes\n",
    "cores_quad = ['#2ecc71', '#e74c3c', '#f39c12', '#95a5a6']\n",
    "labels_quad = [\n",
    "    f'Q1: Ambos\\nRecomendam\\n{quad1:,}\\n({quad1/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q2: Pesq. Sim\\nMin. Não\\n{quad2:,}\\n({quad2/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q3: Pesq. Não\\nMin. Sim\\n{quad3:,}\\n({quad3/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q4: Ambos\\nNão Recomendam\\n{quad4:,}\\n({quad4/total_projetos_quad*100:.1f}%)'\n",
    "]\n",
    "\n",
    "# Posições dos quadrantes\n",
    "positions = [(0.6, 0.6), (-0.6, 0.6), (-0.6, -0.6), (0.6, -0.6)]\n",
    "quadrantes = [quad1, quad2, quad3, quad4]\n",
    "\n",
    "for i, (pos, label, cor, valor) in enumerate(zip(positions, labels_quad, cores_quad, quadrantes)):\n",
    "    # Calcular tamanho do círculo proporcional ao valor\n",
    "    size = (valor / total_projetos_quad) * 5000 + 500\n",
    "    ax2.scatter(pos[0], pos[1], s=size, c=cor, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "    ax2.text(pos[0], pos[1], label, ha='center', va='center', fontsize=11, \n",
    "             fontweight='bold', bbox=dict(boxstyle='round,pad=0.3', facecolor=cor, alpha=0.3))\n",
    "\n",
    "ax2.set_xlabel('← Não Recomendado pelo Ministério | Recomendado pelo Ministério →', fontsize=12)\n",
    "ax2.set_ylabel('← Não Recomendado pelo Pesquisador | Recomendado pelo Pesquisador →', fontsize=12)\n",
    "ax2.set_title('Visualização dos Quadrantes de Decisão', fontsize=16, pad=20)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Remover ticks\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Taxa de concordância\n",
    "concordancia = (quad1 + quad4) / total_projetos_quad * 100\n",
    "discordancia = (quad2 + quad3) / total_projetos_quad * 100\n",
    "\n",
    "print(f\"\\n📊 MÉTRICAS DE CONCORDÂNCIA:\")\n",
    "print(f\"Taxa de Concordância Total: {concordancia:.1f}%\")\n",
    "print(f\"Taxa de Discordância Total: {discordancia:.1f}%\")\n",
    "print(f\"\\nDentro das discordâncias:\")\n",
    "print(f\"  - Pesquisador mais rigoroso (Q2): {quad3/(quad2+quad3)*100:.1f}%\")\n",
    "print(f\"  - Ministério mais rigoroso (Q3): {quad2/(quad2+quad3)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3f7dc",
   "metadata": {},
   "source": [
    "## 10. Análise de Aprovação por Setor\n",
    "\n",
    "Análise das taxas de aprovação por setor nas fases DO e Parecer, identificando padrões setoriais e diferenças entre as fases de avaliação.\n",
    "\n",
    "### Análise por Setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de aprovação por área do projeto\n",
    "print(\"\\n📊 ANÁLISE DE APROVAÇÃO POR ÁREA DO PROJETO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Função para padronizar decisões (mantém a mesma)\n",
    "def padronizar_decisao(decisao):\n",
    "    if pd.isna(decisao):\n",
    "        return np.nan\n",
    "    decisao_str = str(decisao).strip().upper()\n",
    "    if 'RECOMENDADO' in decisao_str and 'NÃO' not in decisao_str:\n",
    "        return 'Recomendado'\n",
    "    elif 'NÃO RECOMENDADO' in decisao_str:\n",
    "        return 'Não Recomendado'\n",
    "    else:\n",
    "        return 'Outro'\n",
    "\n",
    "# Aplicar padronização\n",
    "df_completo['decisao_analista'] = df_completo['do_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "df_completo['decisao_parecerista'] = df_completo['p_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "\n",
    "# Verificar se a coluna de área do projeto existe\n",
    "if 'daproj_dsareaprojeto' in df_completo.columns:\n",
    "    print(\"✅ Usando coluna 'daproj_dsareaprojeto' (Área do Projeto)\")\n",
    "    \n",
    "    # Filtrar registros com área definida\n",
    "    df_com_area = df_completo[df_completo['daproj_dsareaprojeto'].notna()].copy()\n",
    "    print(f\"📊 Projetos com área definida: {len(df_com_area):,}\")\n",
    "    \n",
    "    # Mostrar distribuição das áreas\n",
    "    print(\"\\n📊 Distribuição das Áreas de Projeto:\")\n",
    "    dist_areas = df_com_area['daproj_dsareaprojeto'].value_counts()\n",
    "    print(f\"Total de áreas únicas: {len(dist_areas)}\")\n",
    "    print(\"\\nTop 15 áreas por volume:\")\n",
    "    for i, (area, count) in enumerate(dist_areas.head(15).items()):\n",
    "        print(f\"{i+1:2d}. {area}: {count:,} projetos\")\n",
    "    \n",
    "    # Calcular estatísticas por área\n",
    "    analise_por_area = []\n",
    "    \n",
    "    for area in df_com_area['daproj_dsareaprojeto'].unique():\n",
    "        if pd.notna(area):\n",
    "            projetos_area = df_com_area[df_com_area['daproj_dsareaprojeto'] == area]\n",
    "            \n",
    "            # Estatísticas DO (Analista)\n",
    "            total_do = len(projetos_area[projetos_area['decisao_analista'].notna()])\n",
    "            aprovados_do = len(projetos_area[projetos_area['decisao_analista'] == 'Recomendado'])\n",
    "            taxa_do = (aprovados_do / total_do * 100) if total_do > 0 else 0\n",
    "            \n",
    "            # Estatísticas Parecer (Parecerista)\n",
    "            total_parecer = len(projetos_area[projetos_area['decisao_parecerista'].notna()])\n",
    "            aprovados_parecer = len(projetos_area[projetos_area['decisao_parecerista'] == 'Recomendado'])\n",
    "            taxa_parecer = (aprovados_parecer / total_parecer * 100) if total_parecer > 0 else 0\n",
    "            \n",
    "            # Projetos que mudaram de decisão\n",
    "            projetos_duas_fases = projetos_area[\n",
    "                (projetos_area['decisao_analista'].notna()) & \n",
    "                (projetos_area['decisao_parecerista'].notna())\n",
    "            ]\n",
    "            \n",
    "            mudou_decisao = 0\n",
    "            if len(projetos_duas_fases) > 0:\n",
    "                mudou_decisao = len(projetos_duas_fases[\n",
    "                    projetos_duas_fases['decisao_analista'] != projetos_duas_fases['decisao_parecerista']\n",
    "                ])\n",
    "            \n",
    "            analise_por_area.append({\n",
    "                'Area_Projeto': area,\n",
    "                'Total_Projetos': len(projetos_area),\n",
    "                'Total_DO': total_do,\n",
    "                'Aprovados_DO': aprovados_do,\n",
    "                'Taxa_Aprovacao_DO_%': taxa_do,\n",
    "                'Total_Parecer': total_parecer,\n",
    "                'Aprovados_Parecer': aprovados_parecer,\n",
    "                'Taxa_Aprovacao_Parecer_%': taxa_parecer,\n",
    "                'Diferenca_Taxa_%': taxa_parecer - taxa_do,\n",
    "                'Projetos_Mudaram_Decisao': mudou_decisao,\n",
    "                'Taxa_Mudanca_%': (mudou_decisao / len(projetos_duas_fases) * 100) if len(projetos_duas_fases) > 0 else 0\n",
    "            })\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "    df_areas = pd.DataFrame(analise_por_area)\n",
    "    df_areas = df_areas.sort_values('Total_Projetos', ascending=False)\n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    print(f\"\\n📊 ESTATÍSTICAS GERAIS:\")\n",
    "    print(f\"Total de áreas analisadas: {len(df_areas)}\")\n",
    "    print(f\"Taxa média de aprovação DO: {df_areas['Taxa_Aprovacao_DO_%'].mean():.1f}%\")\n",
    "    print(f\"Taxa média de aprovação Parecer: {df_areas['Taxa_Aprovacao_Parecer_%'].mean():.1f}%\")\n",
    "    print(f\"Diferença média (Parecer - DO): {df_areas['Diferenca_Taxa_%'].mean():.1f}%\")\n",
    "    \n",
    "    # Tabela resumo\n",
    "    print(\"\\n📋 TABELA DE APROVAÇÃO POR ÁREA DO PROJETO (Top 20 por volume)\")\n",
    "    print(\"=\" * 130)\n",
    "    print(f\"{'Área do Projeto':<40} {'Projetos':>10} {'Taxa DO':>12} {'Taxa Parecer':>12} {'Diferença':>12} {'Mudaram':>10}\")\n",
    "    print(\"-\" * 130)\n",
    "    \n",
    "    for _, row in df_areas.head(20).iterrows():\n",
    "        area = row['Area_Projeto'][:38] + '..' if len(row['Area_Projeto']) > 40 else row['Area_Projeto']\n",
    "        print(f\"{area:<40} {row['Total_Projetos']:>10} \"\n",
    "              f\"{row['Taxa_Aprovacao_DO_%']:>11.1f}% {row['Taxa_Aprovacao_Parecer_%']:>11.1f}% \"\n",
    "              f\"{row['Diferenca_Taxa_%']:>11.1f}% {row['Projetos_Mudaram_Decisao']:>10}\")\n",
    "    \n",
    "    print(\"=\" * 130)\n",
    "    \n",
    "    # Destaques\n",
    "    print(\"\\n🔍 DESTAQUES DA ANÁLISE POR ÁREA DO PROJETO:\")\n",
    "    \n",
    "    print(f\"\\nÁreas com MAIOR taxa de aprovação no DO:\")\n",
    "    top_do = df_areas.nlargest(5, 'Taxa_Aprovacao_DO_%')\n",
    "    for _, row in top_do.iterrows():\n",
    "        print(f\"  - {row['Area_Projeto']}: {row['Taxa_Aprovacao_DO_%']:.1f}% ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\nÁreas com MAIOR taxa de aprovação no Parecer:\")\n",
    "    top_parecer = df_areas.nlargest(5, 'Taxa_Aprovacao_Parecer_%')\n",
    "    for _, row in top_parecer.iterrows():\n",
    "        print(f\"  - {row['Area_Projeto']}: {row['Taxa_Aprovacao_Parecer_%']:.1f}% ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\nÁreas com MAIOR QUEDA entre DO e Parecer:\")\n",
    "    maior_queda = df_areas.nsmallest(5, 'Diferenca_Taxa_%')\n",
    "    for _, row in maior_queda.iterrows():\n",
    "        if row['Diferenca_Taxa_%'] < 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: {row['Diferenca_Taxa_%']:.1f}% de queda ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\nÁreas com MAIOR AUMENTO entre DO e Parecer:\")\n",
    "    maior_aumento = df_areas.nlargest(5, 'Diferenca_Taxa_%')\n",
    "    for _, row in maior_aumento.iterrows():\n",
    "        if row['Diferenca_Taxa_%'] > 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: +{row['Diferenca_Taxa_%']:.1f}% de aumento ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\nÁreas com MAIOR taxa de mudança de decisão:\")\n",
    "    maior_mudanca = df_areas.nlargest(5, 'Taxa_Mudanca_%')\n",
    "    for _, row in maior_mudanca.iterrows():\n",
    "        if row['Taxa_Mudanca_%'] > 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: {row['Taxa_Mudanca_%']:.1f}% mudaram decisão ({row['Projetos_Mudaram_Decisao']} de {row['Total_Projetos']} projetos)\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Coluna 'daproj_dsareaprojeto' não encontrada no dataset\")\n",
    "    # Lista alternativas disponíveis\n",
    "    print(\"Colunas disponíveis que podem conter informação de categoria:\")\n",
    "    for col in df_completo.columns:\n",
    "        if 'area' in col.lower() or 'setor' in col.lower() or 'atividade' in col.lower():\n",
    "            print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4054d",
   "metadata": {},
   "source": [
    "### Visualização por Setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88899f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações para análise por área\n",
    "if 'df_areas' in locals() and len(df_areas) > 0:\n",
    "    \n",
    "    # Visualização 1: Gráfico de barras comparativo DO vs Parecer\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    \n",
    "    # Preparar dados (top 15 áreas por volume)\n",
    "    top_areas = df_areas.head(15)\n",
    "    x = np.arange(len(top_areas))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Barras\n",
    "    bars1 = ax.bar(x - width/2, top_areas['Taxa_Aprovacao_DO_%'], width, \n",
    "                   label='Fase DO', color='#3498db', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, top_areas['Taxa_Aprovacao_Parecer_%'], width,\n",
    "                   label='Fase Parecer', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_xlabel('Área do Projeto', fontsize=12)\n",
    "    ax.set_ylabel('Taxa de Aprovação (%)', fontsize=12)\n",
    "    ax.set_title('Taxa de Aprovação por Área do Projeto: Comparação DO vs Parecer (Top 15)', fontsize=16, pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    # Labels das áreas (truncar se muito longo)\n",
    "    labels_areas = [area[:20] + '...' if len(area) > 20 else area for area in top_areas['Area_Projeto']]\n",
    "    ax.set_xticklabels(labels_areas, rotation=45, ha='right')\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    ax.grid(True, axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualização 2: Scatter plot - Taxa DO vs Taxa Parecer\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Filtrar áreas com pelo menos 20 projetos para melhor visualização\n",
    "    df_scatter = df_areas[df_areas['Total_Projetos'] >= 20]\n",
    "    \n",
    "    if len(df_scatter) > 0:\n",
    "        scatter = ax.scatter(df_scatter['Taxa_Aprovacao_DO_%'], \n",
    "                           df_scatter['Taxa_Aprovacao_Parecer_%'],\n",
    "                           s=df_scatter['Total_Projetos']*3,  # Tamanho proporcional\n",
    "                           c=df_scatter['Diferenca_Taxa_%'],\n",
    "                           cmap='RdYlBu', alpha=0.6, edgecolors='black', linewidth=1)\n",
    "        \n",
    "        # Linha de referência (y = x)\n",
    "        ax.plot([0, 100], [0, 100], 'k--', alpha=0.5, label='Linha de Igualdade')\n",
    "        \n",
    "        # Adicionar labels para áreas extremas\n",
    "        for _, row in df_scatter.iterrows():\n",
    "            if abs(row['Diferenca_Taxa_%']) > 25 or row['Total_Projetos'] > df_scatter['Total_Projetos'].quantile(0.8):\n",
    "                label_area = row['Area_Projeto'][:15] + '...' if len(row['Area_Projeto']) > 15 else row['Area_Projeto']\n",
    "                ax.annotate(label_area, \n",
    "                          (row['Taxa_Aprovacao_DO_%'], row['Taxa_Aprovacao_Parecer_%']),\n",
    "                          fontsize=9, alpha=0.7, \n",
    "                          bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.set_xlabel('Taxa de Aprovação DO (%)', fontsize=12)\n",
    "        ax.set_ylabel('Taxa de Aprovação Parecer (%)', fontsize=12)\n",
    "        ax.set_title('Correlação entre Taxas de Aprovação DO e Parecer por Área do Projeto', fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim(0, 105)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Diferença (Parecer - DO) %', rotation=270, labelpad=20)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Visualização 3: Heatmap de análise por área\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Preparar dados para heatmap (top 20 áreas)\n",
    "    heatmap_data = df_areas.head(20)[['Taxa_Aprovacao_DO_%', 'Taxa_Aprovacao_Parecer_%', \n",
    "                                      'Taxa_Mudanca_%', 'Diferenca_Taxa_%']]\n",
    "    \n",
    "    # Truncar nomes das áreas para o heatmap\n",
    "    areas_truncadas = [area[:25] + '...' if len(area) > 25 else area for area in df_areas.head(20)['Area_Projeto']]\n",
    "    heatmap_data.index = areas_truncadas\n",
    "    \n",
    "    sns.heatmap(heatmap_data.T, annot=True, fmt='.1f', cmap='coolwarm', center=0,\n",
    "               cbar_kws={'label': 'Percentual (%)'}, linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_xlabel('Área do Projeto', fontsize=12)\n",
    "    ax.set_yticklabels(['Taxa Aprovação DO', 'Taxa Aprovação Parecer', \n",
    "                      'Taxa Mudança Decisão', 'Diferença (Parecer-DO)'], rotation=0)\n",
    "    ax.set_title('Análise Detalhada por Área do Projeto - Top 20 por Volume', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualização 4: Top e Bottom performers\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Filtrar áreas com pelo menos 50 projetos para análise mais robusta\n",
    "    df_robustas = df_areas[df_areas['Total_Projetos'] >= 50]\n",
    "    \n",
    "    if len(df_robustas) >= 10:\n",
    "        # Top performers (maior taxa no Parecer)\n",
    "        top_performers = df_robustas.nlargest(10, 'Taxa_Aprovacao_Parecer_%')\n",
    "        \n",
    "        y_pos = np.arange(len(top_performers))\n",
    "        bars1 = ax1.barh(y_pos, top_performers['Taxa_Aprovacao_Parecer_%'], \n",
    "                         color='#2ecc71', alpha=0.7)\n",
    "        \n",
    "        ax1.set_yticks(y_pos)\n",
    "        areas_top = [area[:20] + '...' if len(area) > 20 else area for area in top_performers['Area_Projeto']]\n",
    "        ax1.set_yticklabels(areas_top)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_xlabel('Taxa de Aprovação no Parecer (%)')\n",
    "        ax1.set_title('Top 10 Áreas - Maior Taxa de Aprovação no Parecer\\n(≥50 projetos)', fontsize=12)\n",
    "        ax1.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (bar, valor) in enumerate(zip(bars1, top_performers['Taxa_Aprovacao_Parecer_%'])):\n",
    "            ax1.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{valor:.1f}%', va='center', fontsize=10)\n",
    "        \n",
    "        # Bottom performers (menor taxa no Parecer)\n",
    "        bottom_performers = df_robustas.nsmallest(10, 'Taxa_Aprovacao_Parecer_%')\n",
    "        \n",
    "        y_pos2 = np.arange(len(bottom_performers))\n",
    "        bars2 = ax2.barh(y_pos2, bottom_performers['Taxa_Aprovacao_Parecer_%'], \n",
    "                         color='#e74c3c', alpha=0.7)\n",
    "        \n",
    "        ax2.set_yticks(y_pos2)\n",
    "        areas_bottom = [area[:20] + '...' if len(area) > 20 else area for area in bottom_performers['Area_Projeto']]\n",
    "        ax2.set_yticklabels(areas_bottom)\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_xlabel('Taxa de Aprovação no Parecer (%)')\n",
    "        ax2.set_title('Bottom 10 Áreas - Menor Taxa de Aprovação no Parecer\\n(≥50 projetos)', fontsize=12)\n",
    "        ax2.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (bar, valor) in enumerate(zip(bars2, bottom_performers['Taxa_Aprovacao_Parecer_%'])):\n",
    "            ax2.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{valor:.1f}%', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar resultados\n",
    "    df_areas.to_csv('analise_aprovacao_por_area_projeto.csv', index=False, sep=';', encoding='utf-8')\n",
    "    print(\"\\n💾 Resultados exportados para 'analise_aprovacao_por_area_projeto.csv'\")\n",
    "    \n",
    "    # Estatísticas adicionais\n",
    "    print(f\"\\n📊 ESTATÍSTICAS ADICIONAIS:\")\n",
    "    print(f\"Áreas com 100% aprovação no Parecer: {len(df_areas[df_areas['Taxa_Aprovacao_Parecer_%'] == 100])}\")\n",
    "    print(f\"Áreas com 0% aprovação no Parecer: {len(df_areas[df_areas['Taxa_Aprovacao_Parecer_%'] == 0])}\")\n",
    "    print(f\"Área com maior volume: {df_areas.iloc[0]['Area_Projeto']} ({df_areas.iloc[0]['Total_Projetos']} projetos)\")\n",
    "    print(f\"Diferença máxima (Parecer-DO): {df_areas['Diferenca_Taxa_%'].max():.1f}%\")\n",
    "    print(f\"Diferença mínima (Parecer-DO): {df_areas['Diferenca_Taxa_%'].min():.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n❌ Não foi possível realizar a análise por área do projeto\")\n",
    "    print(\"Verifique se a coluna 'daproj_dsareaprojeto' existe e contém dados válidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b1b3e",
   "metadata": {},
   "source": [
    "### Análise e Insights por Setor\n",
    "\n",
    "**O que foi investigado:**\n",
    "\n",
    "Esta análise focou em identificar padrões de aprovação por setor nas duas fases principais do processo (DO e Parecer), quantificando as diferenças entre as decisões dos analistas técnicos e dos pareceristas para cada setor de atividade.\n",
    "\n",
    "**Principais Descobertas:**\n",
    "\n",
    "A análise setorial revela significativas disparidades nas taxas de aprovação entre diferentes setores e entre as fases do processo:\n",
    "\n",
    "- **Variação Setorial**: As taxas de aprovação variam drasticamente entre setores, tanto na fase DO quanto no Parecer\n",
    "- **Tendência Geral**: A maioria dos setores apresenta queda na taxa de aprovação entre DO e Parecer, confirmando que os pareceristas aplicam critérios mais rigorosos\n",
    "- **Setores Favorecidos**: Alguns setores mantêm altas taxas de aprovação em ambas as fases\n",
    "- **Setores Penalizados**: Certos setores sofrem quedas dramáticas entre as fases\n",
    "\n",
    "**Padrões Identificados:**\n",
    "\n",
    "1. **Setores de Alta Performance**: Setores com taxas superiores a 80% em ambas as fases\n",
    "2. **Setores de Queda Acentuada**: Setores que perdem mais de 20 pontos percentuais entre DO e Parecer\n",
    "3. **Setores de Reversão**: Raros casos onde a taxa no Parecer supera a do DO\n",
    "4. **Setores Voláteis**: Alta taxa de mudança de decisão entre fases\n",
    "\n",
    "**Insights e Implicações Práticas:**\n",
    "\n",
    "1. **Especialização Setorial**: A variação nas taxas sugere que diferentes setores requerem expertise específica para avaliação adequada\n",
    "\n",
    "2. **Necessidade de Padronização**: As grandes diferenças entre setores podem indicar falta de critérios uniformes ou vieses setoriais\n",
    "\n",
    "3. **Oportunidade de Capacitação**: Setores com altas taxas de mudança entre fases podem se beneficiar de treinamento específico para analistas\n",
    "\n",
    "4. **Revisão de Critérios**: Setores com quedas sistemáticas merecem revisão dos critérios de avaliação aplicados\n",
    "\n",
    "**Recomendações Específicas:**\n",
    "\n",
    "- **Criar grupos de trabalho setoriais** para padronizar critérios de avaliação\n",
    "- **Desenvolver checklists específicos** para cada setor baseados em suas particularidades\n",
    "- **Implementar revisão cruzada** entre analistas de diferentes setores\n",
    "- **Monitorar indicadores setoriais** continuamente para identificar tendências\n",
    "- **Capacitar analistas** nas especificidades técnicas de cada setor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
