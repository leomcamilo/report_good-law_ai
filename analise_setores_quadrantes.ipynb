{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ebf056",
   "metadata": {},
   "source": [
    "---\n",
    "title: Analise\n",
    "author: Leonardo Camilo\n",
    "execute:\n",
    "    echo: false\n",
    "    warnings: false\n",
    "    message: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b418bf3",
   "metadata": {},
   "source": [
    "An√°lise Detalhada: Analistas vs Pareceristas - Lei do Bem 2021\n",
    "==============================================================\n",
    "\n",
    "Este notebook analisa a rela√ß√£o entre as decis√µes dos analistas (fase DO)\n",
    "e dos pareceristas (fase Parecer) nos projetos da Lei do Bem.\n",
    "\n",
    "Perguntas a serem respondidas:\n",
    "1. Taxa de aprova√ß√£o por analista\n",
    "2. Taxa de concord√¢ncia DO ‚Üí Parecer\n",
    "3. Revers√µes de decis√£o (N√£o Recomendado ‚Üí Recomendado)\n",
    "4. Dispers√£o de √°reas por analista\n",
    "5. Fichas individuais dos top 15 analistas\n",
    "6. Modelo preditivo de aprova√ß√£o no Parecer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0676cd",
   "metadata": {},
   "source": [
    "# An√°lise de Decis√µes no Processo da Lei do Bem (2021): Analistas e Pareceristas\n",
    "\n",
    "## 1. Introdu√ß√£o\n",
    "\n",
    "Esta an√°lise aprofundada explora as decis√µes tomadas por analistas e pareceristas no √¢mbito do programa Lei do Bem do MCTI, um dos principais instrumentos de fomento √† inova√ß√£o no Brasil. O estudo se baseia em um volume expressivo de dados, compreendendo 13.198 projetos analisados durante o ano de 2021. O objetivo geral √© identificar padr√µes, inconsist√™ncias e insights nas avalia√ß√µes, visando otimizar a efici√™ncia, a isonomia e a previsibilidade do processo de concess√£o de incentivos fiscais para Pesquisa e Desenvolvimento (P&D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0cd0",
   "metadata": {},
   "source": [
    "## 2. Metodologia\n",
    "\n",
    "A an√°lise foi conduzida a partir de um banco de dados consolidado contendo informa√ß√µes detalhadas sobre cada um dos 13.198 projetos do ano-base de 2021. As fontes de dados incluem os pareceres t√©cnicos emitidos tanto pelo Minist√©rio (fase DO) quanto pelos pesquisadores ad hoc (fase Parecer), al√©m de metadados dos projetos, como √°reas de conhecimento e informa√ß√µes textuais descritivas.\n",
    "As t√©cnicas aplicadas envolveram desde a estat√≠stica descritiva, para quantificar taxas de aprova√ß√£o e concord√¢ncia, at√© a an√°lise de dispers√£o para entender a distribui√ß√£o de projetos entre os representantes do Minist√©rio. Um dos pilares da metodologia foi o processamento de linguagem natural (PLN), utilizado para extrair insights dos campos textuais. Para isso, a biblioteca NLTK (Natural Language Toolkit) foi empregada para processar os textos em portugu√™s, aplicando a remo√ß√£o de stopwords (palavras comuns como \"de\", \"para\", \"com\") para focar nos termos mais relevantes de cada projeto.\n",
    "O conjunto de stopwords foi composto por 207 palavras do NLTK e um conjunto customizado de 71 termos espec√≠ficos do dom√≠nio da Lei do Bem, totalizando 278 palavras removidas para garantir uma an√°lise mais limpa e focada. Al√©m disso, foi desenvolvido um modelo de Machine Learning para explorar a capacidade preditiva dos dados textuais em rela√ß√£o √† aprova√ß√£o final dos projetos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1374cca",
   "metadata": {},
   "source": [
    "### An√°lise de Analistas vs Pareceristas - Lei do Bem 2021\n",
    "\n",
    "**Data de An√°lise:** 22/07/2025\n",
    "\n",
    "**Ano Base dos Dados:** 2018 √† 2023\n",
    "\n",
    "**Total de Projetos:** 13.198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# %% Imports e Configura√ß√£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Baixar recursos necess√°rios do NLTK\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Baixando punkt...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Baixando stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Configurar fonte para melhor visualiza√ß√£o em PDF\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# %% Configura√ß√£o de stopwords em portugu√™s\n",
    "# Carregar stopwords padr√£o do NLTK em portugu√™s\n",
    "stop_words_nltk = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Adicionar stopwords espec√≠ficas do dom√≠nio Lei do Bem\n",
    "stop_words_dominio = {\n",
    "    # Verbos comuns\n",
    "    'realizar', 'desenvolver', 'criar', 'implementar', 'utilizar', 'aplicar', 'melhorar',\n",
    "    'analisar', 'estudar', 'avaliar', 'testar', 'produzir', 'fabricar', 'construir', 'usar', 'uso'\n",
    "    \n",
    "    # Preposi√ß√µes e conectivos adicionais\n",
    "    'atrav√©s', 'mediante', 'partir', 'base', 'forma', 'modo', 'tipo', 'fase', 'etapa',\n",
    "    'objetivo', 'objetivos', 'finalidade', 'prop√≥sito', 'meta', 'metas',\n",
    "    \n",
    "    # Termos muito gen√©ricos\n",
    "    'novo', 'nova', 'novos', 'novas', '√°rea', '√°reas', 'setor', 'setores',\n",
    "    'atividade', 'atividades', 'trabalho', 'trabalhos', 'servi√ßo', 'servi√ßos'\n",
    "}\n",
    "\n",
    "# Combinar todas as stopwords\n",
    "todas_stopwords = stop_words_nltk.union(stop_words_dominio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e62896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fun√ß√µes de processamento de texto simplificadas\n",
    "def limpar_texto(texto):\n",
    "    \"\"\"Limpa e normaliza o texto\"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return \"\"\n",
    "    \n",
    "    # Converter para string e min√∫sculas\n",
    "    texto = str(texto).lower()\n",
    "    \n",
    "    # Remover caracteres especiais, mantendo espa√ßos e letras\n",
    "    texto = re.sub(r'[^a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±\\s]', ' ', texto)\n",
    "    \n",
    "    # Remover espa√ßos m√∫ltiplos\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    \n",
    "    return texto.strip()\n",
    "\n",
    "def analisar_texto_stopwords(texto, stopwords_set):\n",
    "    \"\"\"\n",
    "    Analisa um texto e retorna estat√≠sticas sobre stopwords\n",
    "    \"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return {\n",
    "            'texto_original': '',\n",
    "            'texto_sem_stopwords': '',\n",
    "            'palavras_total': 0,\n",
    "            'palavras_sem_stopwords': 0,\n",
    "            'stopwords_encontradas': [],\n",
    "            'palavras_relevantes': [],\n",
    "            'reducao_percentual': 0\n",
    "        }\n",
    "    \n",
    "    # Converter para string primeiro para garantir\n",
    "    texto_str = str(texto)\n",
    "    \n",
    "    # Limpar texto\n",
    "    texto_limpo = limpar_texto(texto_str)\n",
    "    \n",
    "    # Tokenizar\n",
    "    palavras = texto_limpo.split()\n",
    "    palavras_total = len(palavras)\n",
    "    \n",
    "    # Filtrar stopwords\n",
    "    palavras_sem_stop = [p for p in palavras if p not in stopwords_set and len(p) > 2]\n",
    "    stopwords_encontradas = [p for p in palavras if p in stopwords_set]\n",
    "    \n",
    "    # Calcular redu√ß√£o\n",
    "    reducao = ((palavras_total - len(palavras_sem_stop)) / palavras_total * 100) if palavras_total > 0 else 0\n",
    "    \n",
    "    # Preparar texto original para retorno (truncado se muito longo)\n",
    "    texto_original_truncado = texto_str[:200] + '...' if len(texto_str) > 200 else texto_str\n",
    "    \n",
    "    return {\n",
    "        'texto_original': texto_original_truncado,\n",
    "        'texto_sem_stopwords': ' '.join(palavras_sem_stop),\n",
    "        'palavras_total': palavras_total,\n",
    "        'palavras_sem_stopwords': len(palavras_sem_stop),\n",
    "        'stopwords_encontradas': stopwords_encontradas,\n",
    "        'palavras_relevantes': palavras_sem_stop[:20],  # Top 20 palavras\n",
    "        'reducao_percentual': reducao\n",
    "    }\n",
    "\n",
    "def processar_campos_texto(df, campos, stopwords_set):\n",
    "    \"\"\"\n",
    "    Processa m√∫ltiplos campos de texto e retorna an√°lise de stopwords\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    for campo in campos:\n",
    "        if campo not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Campo {campo} n√£o encontrado\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"üìù Processando {campo}...\")\n",
    "        \n",
    "        # Analisar cada texto\n",
    "        analises = df[campo].apply(lambda x: analisar_texto_stopwords(x, stopwords_set))\n",
    "        \n",
    "        # Extrair m√©tricas\n",
    "        resultados[campo] = {\n",
    "            'df_analise': pd.DataFrame(list(analises)),\n",
    "            'reducao_media': np.mean([a['reducao_percentual'] for a in analises]),\n",
    "            'palavras_media_original': np.mean([a['palavras_total'] for a in analises]),\n",
    "            'palavras_media_filtrado': np.mean([a['palavras_sem_stopwords'] for a in analises])\n",
    "        }\n",
    "        \n",
    "        # Contar palavras mais frequentes ap√≥s filtro\n",
    "        todas_palavras_relevantes = []\n",
    "        for analise in analises:\n",
    "            todas_palavras_relevantes.extend(analise['palavras_relevantes'])\n",
    "        \n",
    "        contador_palavras = Counter(todas_palavras_relevantes)\n",
    "        resultados[campo]['top_palavras'] = contador_palavras.most_common(20)\n",
    "        \n",
    "        # Contar stopwords mais comuns\n",
    "        todas_stopwords = []\n",
    "        for analise in analises:\n",
    "            todas_stopwords.extend(analise['stopwords_encontradas'])\n",
    "        \n",
    "        contador_stopwords = Counter(todas_stopwords)\n",
    "        resultados[campo]['top_stopwords'] = contador_stopwords.most_common(20)\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda857d",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abaab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cap√≠tulo 1: Carregamento e Prepara√ß√£o dos Dados\n",
    "An√°lise da Lei do Bem - Ano Base 2021\n",
    "\n",
    "Este script realiza o carregamento inicial dos dados e prepara o dataset\n",
    "para an√°lises posteriores, incluindo processamento de linguagem natural\n",
    "dos campos textuais.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Configura√ß√£o visual-0\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================================================\n",
    "# SE√á√ÉO 1.1: CARREGAMENTO DO DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CAP√çTULO 1: CARREGAMENTO E PREPARA√á√ÉO DOS DADOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1.1 Carregamento do Dataset Principal\\n\")\n",
    "\n",
    "# Carregar arquivo CSV principal\n",
    "arquivo_dados = 'csv_longo/projetos_lei_do_bem_DETALHADO_LINHA_UNICA.csv'\n",
    "df = pd.read_csv(arquivo_dados, sep=';', encoding='utf-8')\n",
    "\n",
    "# Estat√≠sticas iniciais\n",
    "total_projetos = len(df)\n",
    "total_colunas = len(df.columns)\n",
    "\n",
    "print(f\"Dataset carregado com sucesso!\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Total de projetos: {total_projetos:,}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Total de vari√°veis: {total_colunas}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SE√á√ÉO 1.2: SELE√á√ÉO DE VARI√ÅVEIS RELEVANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.2 Sele√ß√£o de Vari√°veis Relevantes\\n\")\n",
    "\n",
    "# Definir grupos de colunas por categoria\n",
    "colunas_identificacao = [\n",
    "    'lst_idprenchimentosituacaoanalise', 'lst_norazaosocial', 'lst_nrcnpj',\n",
    "    'lst_noatividadeeconomica', 'daproj_nritem'\n",
    "]\n",
    "\n",
    "colunas_projeto = [\n",
    "    'daproj_noprojeto', 'daproj_dsprojeto', 'daproj_dsareaprojeto',\n",
    "    'daproj_dspalavrachave', 'daproj_dselementotecnologico',\n",
    "    'daproj_dsdesafiotecnologico', 'daproj_dsmetodologiautilizada'\n",
    "]\n",
    "\n",
    "colunas_ministerio = [\n",
    "    'do_saat_idunicopessoaanalise', 'do_taaproj_notipoavaliacaoanalise'\n",
    "]\n",
    "\n",
    "colunas_pesquisador = [\n",
    "    'p_taaproj_notipoavaliacaoanalise'\n",
    "]\n",
    "\n",
    "colunas_valores = [\n",
    "    'do_aat_vltotaldeclarado', 'do_aat_vltotalparecer'\n",
    "]\n",
    "\n",
    "# Combinar todas as colunas\n",
    "colunas_analise = (colunas_identificacao + colunas_projeto + \n",
    "                   colunas_ministerio + colunas_pesquisador + colunas_valores)\n",
    "\n",
    "# Filtrar apenas colunas existentes no dataset\n",
    "colunas_existentes = [col for col in colunas_analise if col in df.columns]\n",
    "df_analise = df[colunas_existentes].copy()\n",
    "\n",
    "print(f\"Vari√°veis selecionadas por categoria:\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Identifica√ß√£o: {len([c for c in colunas_identificacao if c in colunas_existentes])}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Projeto: {len([c for c in colunas_projeto if c in colunas_existentes])}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Minist√©rio: {len([c for c in colunas_ministerio if c in colunas_existentes])}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Pesquisador: {len([c for c in colunas_pesquisador if c in colunas_existentes])}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Valores: {len([c for c in colunas_valores if c in colunas_existentes])}\")\n",
    "print(f\"\\nTotal de vari√°veis selecionadas: {len(colunas_existentes)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SE√á√ÉO 1.3: AN√ÅLISE TEXTUAL E PROCESSAMENTO DE LINGUAGEM NATURAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.3 An√°lise Textual e Processamento de Linguagem Natural\\n\")\n",
    "\n",
    "# 1.3.1 Identifica√ß√£o de campos textuais\n",
    "campos_texto = {\n",
    "    'daproj_dsprojeto': 'Descri√ß√£o do Projeto',\n",
    "    'daproj_dselementotecnologico': 'Elemento Tecnol√≥gico',\n",
    "    'daproj_dsdesafiotecnologico': 'Desafio Tecnol√≥gico',\n",
    "    'daproj_dsmetodologiautilizada': 'Metodologia Utilizada'\n",
    "}\n",
    "\n",
    "campos_texto_existentes = {k: v for k, v in campos_texto.items() if k in df_analise.columns}\n",
    "print(f\"Campos textuais identificados para an√°lise: {len(campos_texto_existentes)}\")\n",
    "\n",
    "# 1.3.2 Configura√ß√£o de stopwords\n",
    "print(\"\\nConfigurando conjunto de stopwords...\")\n",
    "\n",
    "# Baixar stopwords do NLTK se necess√°rio\n",
    "try:\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Stopwords espec√≠ficas do dom√≠nio Lei do Bem\n",
    "stopwords_dominio = {\n",
    "    'ano', 'base', 'projeto', 'projetos', 'empresa', 'empresas',\n",
    "    'desenvolvimento', 'pesquisa', 'inova√ß√£o', 'tecnol√≥gica',\n",
    "    'realizar', 'realizado', 'realizada', 'realizados', 'realizadas',\n",
    "    'objetivo', 'objetivos', 'processo', 'processos', 'atividade',\n",
    "    'atividades', 'trabalho', 'trabalhos', 'forma', 'formas',\n",
    "    'atrav√©s', 'partir', 'sendo', 'foram', 'seja', 'sejam',\n",
    "    'pode', 'podem', 'deve', 'devem', 'est√°', 'est√£o',\n",
    "    'fazer', 'feito', 'feita', 'ter', 'tem', 'tinha',\n",
    "    'uso', 'usar', 'usado', 'usada', 'novo', 'nova',\n",
    "    'novos', 'novas', 'ainda', 'apenas', 'assim', 'ent√£o'\n",
    "}\n",
    "\n",
    "todas_stopwords = stopwords_pt.union(stopwords_dominio)\n",
    "print(f\"‚îú‚îÄ‚îÄ Stopwords NLTK portugu√™s: {len(stopwords_pt)}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Stopwords dom√≠nio espec√≠fico: {len(stopwords_dominio)}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Total de stopwords: {len(todas_stopwords)}\")\n",
    "\n",
    "# 1.3.3 Fun√ß√£o para processar texto\n",
    "def processar_texto(texto, stopwords_set):\n",
    "    \"\"\"\n",
    "    Processa um texto removendo stopwords e normalizando.\n",
    "    \n",
    "    Args:\n",
    "        texto: String com o texto a ser processado\n",
    "        stopwords_set: Conjunto de stopwords a remover\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicion√°rio com texto processado e estat√≠sticas\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return {\n",
    "            'texto_original': '',\n",
    "            'texto_limpo': '',\n",
    "            'palavras_originais': 0,\n",
    "            'palavras_limpas': 0,\n",
    "            'reducao_percentual': 0\n",
    "        }\n",
    "    \n",
    "    # Converter para string e lowercase\n",
    "    texto_str = str(texto).lower()\n",
    "    \n",
    "    # Tokeniza√ß√£o simples\n",
    "    palavras_originais = texto_str.split()\n",
    "    num_palavras_originais = len(palavras_originais)\n",
    "    \n",
    "    # Remover stopwords\n",
    "    palavras_limpas = [p for p in palavras_originais if p not in stopwords_set]\n",
    "    num_palavras_limpas = len(palavras_limpas)\n",
    "    \n",
    "    # Calcular redu√ß√£o\n",
    "    reducao = 0 if num_palavras_originais == 0 else (\n",
    "        (num_palavras_originais - num_palavras_limpas) / num_palavras_originais * 100\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'texto_original': texto_str,\n",
    "        'texto_limpo': ' '.join(palavras_limpas),\n",
    "        'palavras_originais': num_palavras_originais,\n",
    "        'palavras_limpas': num_palavras_limpas,\n",
    "        'reducao_percentual': reducao\n",
    "    }\n",
    "\n",
    "# 1.3.4 Processar todos os campos textuais\n",
    "print(\"\\nProcessando campos textuais...\")\n",
    "\n",
    "resultados_processamento = {}\n",
    "\n",
    "for campo, nome in campos_texto_existentes.items():\n",
    "    print(f\"\\nProcessando: {nome}\")\n",
    "    \n",
    "    # Aplicar processamento\n",
    "    processados = df_analise[campo].apply(lambda x: processar_texto(x, todas_stopwords))\n",
    "    \n",
    "    # Extrair resultados\n",
    "    df_temp = pd.DataFrame(processados.tolist())\n",
    "    \n",
    "    # Calcular estat√≠sticas\n",
    "    palavras_originais_media = df_temp['palavras_originais'].mean()\n",
    "    palavras_limpas_media = df_temp['palavras_limpas'].mean()\n",
    "    reducao_media = df_temp['reducao_percentual'].mean()\n",
    "    \n",
    "    # Contar palavras mais frequentes ap√≥s limpeza\n",
    "    todas_palavras_limpas = ' '.join(df_temp['texto_limpo']).split()\n",
    "    contador_palavras = Counter(todas_palavras_limpas)\n",
    "    top_palavras = contador_palavras.most_common(20)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    resultados_processamento[campo] = {\n",
    "        'nome': nome,\n",
    "        'df_processado': df_temp,\n",
    "        'palavras_originais_media': palavras_originais_media,\n",
    "        'palavras_limpas_media': palavras_limpas_media,\n",
    "        'reducao_media': reducao_media,\n",
    "        'top_palavras': top_palavras\n",
    "    }\n",
    "    \n",
    "    # Adicionar colunas processadas ao dataframe principal\n",
    "    df_analise[f'{campo}_limpo'] = df_temp['texto_limpo']\n",
    "    df_analise[f'{campo}_num_palavras_limpo'] = df_temp['palavras_limpas']\n",
    "    \n",
    "    print(f\"‚îú‚îÄ‚îÄ Palavras m√©dias (original): {palavras_originais_media:.1f}\")\n",
    "    print(f\"‚îú‚îÄ‚îÄ Palavras m√©dias (limpo): {palavras_limpas_media:.1f}\")\n",
    "    print(f\"‚îî‚îÄ‚îÄ Redu√ß√£o m√©dia: {reducao_media:.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# SE√á√ÉO 1.4: VISUALIZA√á√ïES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.4 Gerando Visualiza√ß√µes\\n\")\n",
    "\n",
    "# Figura 1: An√°lise de Redu√ß√£o por Stopwords\n",
    "fig1, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (campo, resultado) in enumerate(resultados_processamento.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histograma de redu√ß√£o percentual\n",
    "    df_vis = resultado['df_processado']\n",
    "    df_vis['reducao_percentual'].hist(bins=30, ax=ax, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    \n",
    "    # Adicionar linha de m√©dia\n",
    "    ax.axvline(resultado['reducao_media'], color='red', linestyle='--', linewidth=2,\n",
    "               label=f'M√©dia: {resultado[\"reducao_media\"]:.1f}%')\n",
    "    \n",
    "    # Configurar eixos e t√≠tulo\n",
    "    ax.set_title(f'Redu√ß√£o por Stopwords\\n{resultado[\"nome\"]}', fontsize=12, pad=10)\n",
    "    ax.set_xlabel('Redu√ß√£o Percentual (%)')\n",
    "    ax.set_ylabel('Frequ√™ncia')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Figura 1: An√°lise de Redu√ß√£o por Stopwords nos Campos de Texto', \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figura 2: Top Palavras Relevantes\n",
    "fig2, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (campo, resultado) in enumerate(resultados_processamento.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Top 10 palavras\n",
    "    palavras = [p[0] for p in resultado['top_palavras'][:10]]\n",
    "    frequencias = [p[1] for p in resultado['top_palavras'][:10]]\n",
    "    \n",
    "    # Criar gr√°fico de barras horizontal\n",
    "    y_pos = np.arange(len(palavras))\n",
    "    bars = ax.barh(y_pos, frequencias, color='green', alpha=0.7)\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(palavras)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Frequ√™ncia')\n",
    "    ax.set_title(f'Top 10 Palavras Relevantes\\n{resultado[\"nome\"]}', fontsize=12, pad=10)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for j, (bar, freq) in enumerate(zip(bars, frequencias)):\n",
    "        ax.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2, \n",
    "                f'{freq:,}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Figura 2: Top 10 Palavras Mais Relevantes por Campo', \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# SE√á√ÉO 1.5: PREPARA√á√ÉO FINAL DO DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1.5 Prepara√ß√£o Final do Dataset\\n\")\n",
    "\n",
    "# Criar campo de texto combinado\n",
    "print(\"Criando campo de texto combinado...\")\n",
    "textos_combinados = []\n",
    "\n",
    "for idx in range(len(df_analise)):\n",
    "    partes = []\n",
    "    for campo in campos_texto_existentes.keys():\n",
    "        campo_limpo = f'{campo}_limpo'\n",
    "        if campo_limpo in df_analise.columns:\n",
    "            texto = str(df_analise[campo_limpo].iloc[idx])\n",
    "            if texto and texto != 'nan':\n",
    "                partes.append(texto)\n",
    "    \n",
    "    texto_combinado = ' '.join(partes)\n",
    "    textos_combinados.append(texto_combinado)\n",
    "\n",
    "df_analise['texto_combinado_limpo'] = textos_combinados\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(f\"\\nDataset preparado com sucesso!\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Total de projetos: {len(df_analise):,}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Vari√°veis originais: {len(colunas_existentes)}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Vari√°veis criadas: {len([c for c in df_analise.columns if 'limpo' in c])}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Total de vari√°veis: {len(df_analise.columns)}\")\n",
    "\n",
    "# Exemplo de processamento\n",
    "print(\"\\nExemplo de Processamento (Projeto #1):\")\n",
    "print(\"-\" * 60)\n",
    "campo_exemplo = 'daproj_dsprojeto'\n",
    "if campo_exemplo in df_analise.columns:\n",
    "    texto_original = str(df_analise[campo_exemplo].iloc[0])[:150]\n",
    "    texto_limpo = str(df_analise[f'{campo_exemplo}_limpo'].iloc[0])[:150]\n",
    "    reducao = resultados_processamento[campo_exemplo]['df_processado']['reducao_percentual'].iloc[0]\n",
    "    \n",
    "    print(f\"Original: {texto_original}...\")\n",
    "    print(f\"Limpo: {texto_limpo}...\")\n",
    "    print(f\"Redu√ß√£o: {reducao:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CAP√çTULO 1 CONCLU√çDO - Dataset pronto para an√°lise\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f30a9",
   "metadata": {},
   "source": [
    "## 2. An√°lise Explorat√≥ria Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Estat√≠sticas b√°sicas\n",
    "# Verificar valores √∫nicos nas colunas de decis√£o\n",
    "print(\"Valores √∫nicos em 'do_taaproj_notipoavaliacaoanalise' (Pesquisador ad hoc):\")\n",
    "print(df_analise['do_taaproj_notipoavaliacaoanalise'].value_counts())\n",
    "\n",
    "print(\"\\n\\nValores √∫nicos em 'p_taaproj_notipoavaliacaoanalise' (Minist√©rio):\")\n",
    "print(df_analise['p_taaproj_notipoavaliacaoanalise'].value_counts())\n",
    "\n",
    "# Filtrar apenas projetos que passaram por ambas as fases\n",
    "df_completo = df_analise[\n",
    "    df_analise['do_taaproj_notipoavaliacaoanalise'].notna() & \n",
    "    df_analise['p_taaproj_notipoavaliacaoanalise'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n\\nProjetos com an√°lise completa (Pesquisador + Minist√©rio): {len(df_completo):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60976c",
   "metadata": {},
   "source": [
    "## An√°lise de Quadrante de Decis√£o\n",
    "\n",
    "An√°lise dos quadrantes de decis√£o entre Pesquisadores e Minist√©rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar fun√ß√£o para padronizar as decis√µes\n",
    "def padronizar_decisao(decisao):\n",
    "    if pd.isna(decisao):\n",
    "        return np.nan\n",
    "    decisao_str = str(decisao).strip().upper()\n",
    "    if 'RECOMENDADO' in decisao_str and 'N√ÉO' not in decisao_str:\n",
    "        return 'Recomendado'\n",
    "    elif 'N√ÉO RECOMENDADO' in decisao_str:\n",
    "        return 'N√£o Recomendado'\n",
    "    else:\n",
    "        return 'Outro'\n",
    "\n",
    "# Aplicar padroniza√ß√£o\n",
    "df_completo['decisao_pesquisador'] = df_completo['do_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "df_completo['decisao_ministerio'] = df_completo['p_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "\n",
    "# Filtrar apenas registros com decis√µes v√°lidas (Recomendado ou N√£o Recomendado)\n",
    "df_analise_quadrantes = df_completo[\n",
    "    (df_completo['decisao_pesquisador'].isin(['Recomendado', 'N√£o Recomendado'])) & \n",
    "    (df_completo['decisao_ministerio'].isin(['Recomendado', 'N√£o Recomendado']))\n",
    "].copy()\n",
    "\n",
    "# Criar an√°lise de quadrantes\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISE DE QUADRANTES DE DECIS√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar matriz de conting√™ncia (sem \"Outro\")\n",
    "matriz_decisoes = pd.crosstab(\n",
    "    df_analise_quadrantes['decisao_pesquisador'], \n",
    "    df_analise_quadrantes['decisao_ministerio'],\n",
    "    rownames=['Pesquisador (ad hoc)'],\n",
    "    colnames=['Minist√©rio'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Matriz de Decis√µes:\")\n",
    "print(matriz_decisoes)\n",
    "\n",
    "# Calcular quadrantes espec√≠ficos\n",
    "quad1 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Recomendado')])\n",
    "quad2 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'N√£o Recomendado')])\n",
    "quad3 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'N√£o Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'Recomendado')])\n",
    "quad4 = len(df_analise_quadrantes[(df_analise_quadrantes['decisao_pesquisador'] == 'N√£o Recomendado') & \n",
    "                                   (df_analise_quadrantes['decisao_ministerio'] == 'N√£o Recomendado')])\n",
    "\n",
    "total_projetos_quad = quad1 + quad2 + quad3 + quad4\n",
    "\n",
    "# Mostrar informa√ß√£o sobre registros exclu√≠dos\n",
    "total_excluidos = len(df_completo) - len(df_analise_quadrantes)\n",
    "if total_excluidos > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è {total_excluidos} projetos foram exclu√≠dos da an√°lise por terem decis√£o 'Outro'\")\n",
    "\n",
    "print(\"\\n\\nüìä AN√ÅLISE POR QUADRANTES:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Quadrante 1 - Recomendado por AMBOS (Pesquisador E Minist√©rio):\")\n",
    "print(f\"  ‚Üí {quad1:,} projetos ({quad1/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 2 - Recomendado pelo Pesquisador, N√ÉO pelo Minist√©rio:\")\n",
    "print(f\"  ‚Üí {quad2:,} projetos ({quad2/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 3 - N√ÉO Recomendado pelo Pesquisador, SIM pelo Minist√©rio:\")\n",
    "print(f\"  ‚Üí {quad3:,} projetos ({quad3/total_projetos_quad*100:.1f}%)\")\n",
    "print(f\"\\nQuadrante 4 - N√ÉO Recomendado por AMBOS:\")\n",
    "print(f\"  ‚Üí {quad4:,} projetos ({quad4/total_projetos_quad*100:.1f}%)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total: {total_projetos_quad:,} projetos\")\n",
    "\n",
    "# Visualiza√ß√£o dos quadrantes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr√°fico 1: Matriz de calor\n",
    "matriz_prop = matriz_decisoes.iloc[:-1, :-1] / total_projetos_quad * 100\n",
    "sns.heatmap(matriz_prop, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Percentual (%)'}, ax=ax1,\n",
    "            annot_kws={'size': 14})\n",
    "ax1.set_title('Matriz de Decis√µes (%)', fontsize=16, pad=20)\n",
    "ax1.set_xlabel('Decis√£o do Minist√©rio', fontsize=12)\n",
    "ax1.set_ylabel('Decis√£o do Pesquisador (ad hoc)', fontsize=12)\n",
    "\n",
    "# Adicionar valores absolutos\n",
    "for i in range(len(matriz_decisoes.index)-1):\n",
    "    for j in range(len(matriz_decisoes.columns)-1):\n",
    "        valor = matriz_decisoes.iloc[i, j]\n",
    "        ax1.text(j+0.5, i+0.7, f'({valor:,})', \n",
    "                ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Gr√°fico 2: Diagrama de quadrantes\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.axhline(y=0, color='black', linewidth=2)\n",
    "ax2.axvline(x=0, color='black', linewidth=2)\n",
    "\n",
    "# Desenhar quadrantes\n",
    "cores_quad = ['#2ecc71', '#e74c3c', '#f39c12', '#95a5a6']\n",
    "labels_quad = [\n",
    "    f'Q1: Ambos\\nRecomendam\\n{quad1:,}\\n({quad1/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q2: Pesq. Sim\\nMin. N√£o\\n{quad2:,}\\n({quad2/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q3: Pesq. N√£o\\nMin. Sim\\n{quad3:,}\\n({quad3/total_projetos_quad*100:.1f}%)',\n",
    "    f'Q4: Ambos\\nN√£o Recomendam\\n{quad4:,}\\n({quad4/total_projetos_quad*100:.1f}%)'\n",
    "]\n",
    "\n",
    "# Posi√ß√µes dos quadrantes\n",
    "positions = [(0.6, 0.6), (-0.6, 0.6), (-0.6, -0.6), (0.6, -0.6)]\n",
    "quadrantes = [quad1, quad2, quad3, quad4]\n",
    "\n",
    "for i, (pos, label, cor, valor) in enumerate(zip(positions, labels_quad, cores_quad, quadrantes)):\n",
    "    # Calcular tamanho do c√≠rculo proporcional ao valor\n",
    "    size = (valor / total_projetos_quad) * 5000 + 500\n",
    "    ax2.scatter(pos[0], pos[1], s=size, c=cor, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "    ax2.text(pos[0], pos[1], label, ha='center', va='center', fontsize=11, \n",
    "             fontweight='bold', bbox=dict(boxstyle='round,pad=0.3', facecolor=cor, alpha=0.3))\n",
    "\n",
    "ax2.set_xlabel('‚Üê N√£o Recomendado pelo Minist√©rio | Recomendado pelo Minist√©rio ‚Üí', fontsize=12)\n",
    "ax2.set_ylabel('‚Üê N√£o Recomendado pelo Pesquisador | Recomendado pelo Pesquisador ‚Üí', fontsize=12)\n",
    "ax2.set_title('Visualiza√ß√£o dos Quadrantes de Decis√£o', fontsize=16, pad=20)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Remover ticks\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Taxa de concord√¢ncia\n",
    "concordancia = (quad1 + quad4) / total_projetos_quad * 100\n",
    "discordancia = (quad2 + quad3) / total_projetos_quad * 100\n",
    "\n",
    "print(f\"\\nüìä M√âTRICAS DE CONCORD√ÇNCIA:\")\n",
    "print(f\"Taxa de Concord√¢ncia Total: {concordancia:.1f}%\")\n",
    "print(f\"Taxa de Discord√¢ncia Total: {discordancia:.1f}%\")\n",
    "print(f\"\\nDentro das discord√¢ncias:\")\n",
    "print(f\"  - Pesquisador mais rigoroso (Q2): {quad3/(quad2+quad3)*100:.1f}%\")\n",
    "print(f\"  - Minist√©rio mais rigoroso (Q3): {quad2/(quad2+quad3)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3f7dc",
   "metadata": {},
   "source": [
    "## 10. An√°lise de Aprova√ß√£o por Setor\n",
    "\n",
    "An√°lise das taxas de aprova√ß√£o por setor nas fases DO e Parecer, identificando padr√µes setoriais e diferen√ßas entre as fases de avalia√ß√£o.\n",
    "\n",
    "### An√°lise por Setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de aprova√ß√£o por √°rea do projeto\n",
    "print(\"\\nüìä AN√ÅLISE DE APROVA√á√ÉO POR √ÅREA DO PROJETO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fun√ß√£o para padronizar decis√µes (mant√©m a mesma)\n",
    "def padronizar_decisao(decisao):\n",
    "    if pd.isna(decisao):\n",
    "        return np.nan\n",
    "    decisao_str = str(decisao).strip().upper()\n",
    "    if 'RECOMENDADO' in decisao_str and 'N√ÉO' not in decisao_str:\n",
    "        return 'Recomendado'\n",
    "    elif 'N√ÉO RECOMENDADO' in decisao_str:\n",
    "        return 'N√£o Recomendado'\n",
    "    else:\n",
    "        return 'Outro'\n",
    "\n",
    "# Aplicar padroniza√ß√£o\n",
    "df_completo['decisao_analista'] = df_completo['do_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "df_completo['decisao_parecerista'] = df_completo['p_taaproj_notipoavaliacaoanalise'].apply(padronizar_decisao)\n",
    "\n",
    "# Verificar se a coluna de √°rea do projeto existe\n",
    "if 'daproj_dsareaprojeto' in df_completo.columns:\n",
    "    print(\"‚úÖ Usando coluna 'daproj_dsareaprojeto' (√Årea do Projeto)\")\n",
    "    \n",
    "    # Filtrar registros com √°rea definida\n",
    "    df_com_area = df_completo[df_completo['daproj_dsareaprojeto'].notna()].copy()\n",
    "    print(f\"üìä Projetos com √°rea definida: {len(df_com_area):,}\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o das √°reas\n",
    "    print(\"\\nüìä Distribui√ß√£o das √Åreas de Projeto:\")\n",
    "    dist_areas = df_com_area['daproj_dsareaprojeto'].value_counts()\n",
    "    print(f\"Total de √°reas √∫nicas: {len(dist_areas)}\")\n",
    "    print(\"\\nTop 15 √°reas por volume:\")\n",
    "    for i, (area, count) in enumerate(dist_areas.head(15).items()):\n",
    "        print(f\"{i+1:2d}. {area}: {count:,} projetos\")\n",
    "    \n",
    "    # Calcular estat√≠sticas por √°rea\n",
    "    analise_por_area = []\n",
    "    \n",
    "    for area in df_com_area['daproj_dsareaprojeto'].unique():\n",
    "        if pd.notna(area):\n",
    "            projetos_area = df_com_area[df_com_area['daproj_dsareaprojeto'] == area]\n",
    "            \n",
    "            # Estat√≠sticas DO (Analista)\n",
    "            total_do = len(projetos_area[projetos_area['decisao_analista'].notna()])\n",
    "            aprovados_do = len(projetos_area[projetos_area['decisao_analista'] == 'Recomendado'])\n",
    "            taxa_do = (aprovados_do / total_do * 100) if total_do > 0 else 0\n",
    "            \n",
    "            # Estat√≠sticas Parecer (Parecerista)\n",
    "            total_parecer = len(projetos_area[projetos_area['decisao_parecerista'].notna()])\n",
    "            aprovados_parecer = len(projetos_area[projetos_area['decisao_parecerista'] == 'Recomendado'])\n",
    "            taxa_parecer = (aprovados_parecer / total_parecer * 100) if total_parecer > 0 else 0\n",
    "            \n",
    "            # Projetos que mudaram de decis√£o\n",
    "            projetos_duas_fases = projetos_area[\n",
    "                (projetos_area['decisao_analista'].notna()) & \n",
    "                (projetos_area['decisao_parecerista'].notna())\n",
    "            ]\n",
    "            \n",
    "            mudou_decisao = 0\n",
    "            if len(projetos_duas_fases) > 0:\n",
    "                mudou_decisao = len(projetos_duas_fases[\n",
    "                    projetos_duas_fases['decisao_analista'] != projetos_duas_fases['decisao_parecerista']\n",
    "                ])\n",
    "            \n",
    "            analise_por_area.append({\n",
    "                'Area_Projeto': area,\n",
    "                'Total_Projetos': len(projetos_area),\n",
    "                'Total_DO': total_do,\n",
    "                'Aprovados_DO': aprovados_do,\n",
    "                'Taxa_Aprovacao_DO_%': taxa_do,\n",
    "                'Total_Parecer': total_parecer,\n",
    "                'Aprovados_Parecer': aprovados_parecer,\n",
    "                'Taxa_Aprovacao_Parecer_%': taxa_parecer,\n",
    "                'Diferenca_Taxa_%': taxa_parecer - taxa_do,\n",
    "                'Projetos_Mudaram_Decisao': mudou_decisao,\n",
    "                'Taxa_Mudanca_%': (mudou_decisao / len(projetos_duas_fases) * 100) if len(projetos_duas_fases) > 0 else 0\n",
    "            })\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "    df_areas = pd.DataFrame(analise_por_area)\n",
    "    df_areas = df_areas.sort_values('Total_Projetos', ascending=False)\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS GERAIS:\")\n",
    "    print(f\"Total de √°reas analisadas: {len(df_areas)}\")\n",
    "    print(f\"Taxa m√©dia de aprova√ß√£o DO: {df_areas['Taxa_Aprovacao_DO_%'].mean():.1f}%\")\n",
    "    print(f\"Taxa m√©dia de aprova√ß√£o Parecer: {df_areas['Taxa_Aprovacao_Parecer_%'].mean():.1f}%\")\n",
    "    print(f\"Diferen√ßa m√©dia (Parecer - DO): {df_areas['Diferenca_Taxa_%'].mean():.1f}%\")\n",
    "    \n",
    "    # Tabela resumo\n",
    "    print(\"\\nüìã TABELA DE APROVA√á√ÉO POR √ÅREA DO PROJETO (Top 20 por volume)\")\n",
    "    print(\"=\" * 130)\n",
    "    print(f\"{'√Årea do Projeto':<40} {'Projetos':>10} {'Taxa DO':>12} {'Taxa Parecer':>12} {'Diferen√ßa':>12} {'Mudaram':>10}\")\n",
    "    print(\"-\" * 130)\n",
    "    \n",
    "    for _, row in df_areas.head(20).iterrows():\n",
    "        area = row['Area_Projeto'][:38] + '..' if len(row['Area_Projeto']) > 40 else row['Area_Projeto']\n",
    "        print(f\"{area:<40} {row['Total_Projetos']:>10} \"\n",
    "              f\"{row['Taxa_Aprovacao_DO_%']:>11.1f}% {row['Taxa_Aprovacao_Parecer_%']:>11.1f}% \"\n",
    "              f\"{row['Diferenca_Taxa_%']:>11.1f}% {row['Projetos_Mudaram_Decisao']:>10}\")\n",
    "    \n",
    "    print(\"=\" * 130)\n",
    "    \n",
    "    # Destaques\n",
    "    print(\"\\nüîç DESTAQUES DA AN√ÅLISE POR √ÅREA DO PROJETO:\")\n",
    "    \n",
    "    print(f\"\\n√Åreas com MAIOR taxa de aprova√ß√£o no DO:\")\n",
    "    top_do = df_areas.nlargest(5, 'Taxa_Aprovacao_DO_%')\n",
    "    for _, row in top_do.iterrows():\n",
    "        print(f\"  - {row['Area_Projeto']}: {row['Taxa_Aprovacao_DO_%']:.1f}% ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\n√Åreas com MAIOR taxa de aprova√ß√£o no Parecer:\")\n",
    "    top_parecer = df_areas.nlargest(5, 'Taxa_Aprovacao_Parecer_%')\n",
    "    for _, row in top_parecer.iterrows():\n",
    "        print(f\"  - {row['Area_Projeto']}: {row['Taxa_Aprovacao_Parecer_%']:.1f}% ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\n√Åreas com MAIOR QUEDA entre DO e Parecer:\")\n",
    "    maior_queda = df_areas.nsmallest(5, 'Diferenca_Taxa_%')\n",
    "    for _, row in maior_queda.iterrows():\n",
    "        if row['Diferenca_Taxa_%'] < 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: {row['Diferenca_Taxa_%']:.1f}% de queda ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\n√Åreas com MAIOR AUMENTO entre DO e Parecer:\")\n",
    "    maior_aumento = df_areas.nlargest(5, 'Diferenca_Taxa_%')\n",
    "    for _, row in maior_aumento.iterrows():\n",
    "        if row['Diferenca_Taxa_%'] > 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: +{row['Diferenca_Taxa_%']:.1f}% de aumento ({row['Total_Projetos']} projetos)\")\n",
    "    \n",
    "    print(f\"\\n√Åreas com MAIOR taxa de mudan√ßa de decis√£o:\")\n",
    "    maior_mudanca = df_areas.nlargest(5, 'Taxa_Mudanca_%')\n",
    "    for _, row in maior_mudanca.iterrows():\n",
    "        if row['Taxa_Mudanca_%'] > 0:\n",
    "            print(f\"  - {row['Area_Projeto']}: {row['Taxa_Mudanca_%']:.1f}% mudaram decis√£o ({row['Projetos_Mudaram_Decisao']} de {row['Total_Projetos']} projetos)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Coluna 'daproj_dsareaprojeto' n√£o encontrada no dataset\")\n",
    "    # Lista alternativas dispon√≠veis\n",
    "    print(\"Colunas dispon√≠veis que podem conter informa√ß√£o de categoria:\")\n",
    "    for col in df_completo.columns:\n",
    "        if 'area' in col.lower() or 'setor' in col.lower() or 'atividade' in col.lower():\n",
    "            print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4054d",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o por Setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88899f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes para an√°lise por √°rea\n",
    "if 'df_areas' in locals() and len(df_areas) > 0:\n",
    "    \n",
    "    # Visualiza√ß√£o 1: Gr√°fico de barras comparativo DO vs Parecer\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    \n",
    "    # Preparar dados (top 15 √°reas por volume)\n",
    "    top_areas = df_areas.head(15)\n",
    "    x = np.arange(len(top_areas))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Barras\n",
    "    bars1 = ax.bar(x - width/2, top_areas['Taxa_Aprovacao_DO_%'], width, \n",
    "                   label='Fase DO', color='#3498db', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, top_areas['Taxa_Aprovacao_Parecer_%'], width,\n",
    "                   label='Fase Parecer', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_xlabel('√Årea do Projeto', fontsize=12)\n",
    "    ax.set_ylabel('Taxa de Aprova√ß√£o (%)', fontsize=12)\n",
    "    ax.set_title('Taxa de Aprova√ß√£o por √Årea do Projeto: Compara√ß√£o DO vs Parecer (Top 15)', fontsize=16, pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    # Labels das √°reas (truncar se muito longo)\n",
    "    labels_areas = [area[:20] + '...' if len(area) > 20 else area for area in top_areas['Area_Projeto']]\n",
    "    ax.set_xticklabels(labels_areas, rotation=45, ha='right')\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    ax.grid(True, axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualiza√ß√£o 2: Scatter plot - Taxa DO vs Taxa Parecer\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Filtrar √°reas com pelo menos 20 projetos para melhor visualiza√ß√£o\n",
    "    df_scatter = df_areas[df_areas['Total_Projetos'] >= 20]\n",
    "    \n",
    "    if len(df_scatter) > 0:\n",
    "        scatter = ax.scatter(df_scatter['Taxa_Aprovacao_DO_%'], \n",
    "                           df_scatter['Taxa_Aprovacao_Parecer_%'],\n",
    "                           s=df_scatter['Total_Projetos']*3,  # Tamanho proporcional\n",
    "                           c=df_scatter['Diferenca_Taxa_%'],\n",
    "                           cmap='RdYlBu', alpha=0.6, edgecolors='black', linewidth=1)\n",
    "        \n",
    "        # Linha de refer√™ncia (y = x)\n",
    "        ax.plot([0, 100], [0, 100], 'k--', alpha=0.5, label='Linha de Igualdade')\n",
    "        \n",
    "        # Adicionar labels para √°reas extremas\n",
    "        for _, row in df_scatter.iterrows():\n",
    "            if abs(row['Diferenca_Taxa_%']) > 25 or row['Total_Projetos'] > df_scatter['Total_Projetos'].quantile(0.8):\n",
    "                label_area = row['Area_Projeto'][:15] + '...' if len(row['Area_Projeto']) > 15 else row['Area_Projeto']\n",
    "                ax.annotate(label_area, \n",
    "                          (row['Taxa_Aprovacao_DO_%'], row['Taxa_Aprovacao_Parecer_%']),\n",
    "                          fontsize=9, alpha=0.7, \n",
    "                          bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.set_xlabel('Taxa de Aprova√ß√£o DO (%)', fontsize=12)\n",
    "        ax.set_ylabel('Taxa de Aprova√ß√£o Parecer (%)', fontsize=12)\n",
    "        ax.set_title('Correla√ß√£o entre Taxas de Aprova√ß√£o DO e Parecer por √Årea do Projeto', fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim(0, 105)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Diferen√ßa (Parecer - DO) %', rotation=270, labelpad=20)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Visualiza√ß√£o 3: Heatmap de an√°lise por √°rea\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Preparar dados para heatmap (top 20 √°reas)\n",
    "    heatmap_data = df_areas.head(20)[['Taxa_Aprovacao_DO_%', 'Taxa_Aprovacao_Parecer_%', \n",
    "                                      'Taxa_Mudanca_%', 'Diferenca_Taxa_%']]\n",
    "    \n",
    "    # Truncar nomes das √°reas para o heatmap\n",
    "    areas_truncadas = [area[:25] + '...' if len(area) > 25 else area for area in df_areas.head(20)['Area_Projeto']]\n",
    "    heatmap_data.index = areas_truncadas\n",
    "    \n",
    "    sns.heatmap(heatmap_data.T, annot=True, fmt='.1f', cmap='coolwarm', center=0,\n",
    "               cbar_kws={'label': 'Percentual (%)'}, linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_xlabel('√Årea do Projeto', fontsize=12)\n",
    "    ax.set_yticklabels(['Taxa Aprova√ß√£o DO', 'Taxa Aprova√ß√£o Parecer', \n",
    "                      'Taxa Mudan√ßa Decis√£o', 'Diferen√ßa (Parecer-DO)'], rotation=0)\n",
    "    ax.set_title('An√°lise Detalhada por √Årea do Projeto - Top 20 por Volume', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualiza√ß√£o 4: Top e Bottom performers\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Filtrar √°reas com pelo menos 50 projetos para an√°lise mais robusta\n",
    "    df_robustas = df_areas[df_areas['Total_Projetos'] >= 50]\n",
    "    \n",
    "    if len(df_robustas) >= 10:\n",
    "        # Top performers (maior taxa no Parecer)\n",
    "        top_performers = df_robustas.nlargest(10, 'Taxa_Aprovacao_Parecer_%')\n",
    "        \n",
    "        y_pos = np.arange(len(top_performers))\n",
    "        bars1 = ax1.barh(y_pos, top_performers['Taxa_Aprovacao_Parecer_%'], \n",
    "                         color='#2ecc71', alpha=0.7)\n",
    "        \n",
    "        ax1.set_yticks(y_pos)\n",
    "        areas_top = [area[:20] + '...' if len(area) > 20 else area for area in top_performers['Area_Projeto']]\n",
    "        ax1.set_yticklabels(areas_top)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_xlabel('Taxa de Aprova√ß√£o no Parecer (%)')\n",
    "        ax1.set_title('Top 10 √Åreas - Maior Taxa de Aprova√ß√£o no Parecer\\n(‚â•50 projetos)', fontsize=12)\n",
    "        ax1.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (bar, valor) in enumerate(zip(bars1, top_performers['Taxa_Aprovacao_Parecer_%'])):\n",
    "            ax1.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{valor:.1f}%', va='center', fontsize=10)\n",
    "        \n",
    "        # Bottom performers (menor taxa no Parecer)\n",
    "        bottom_performers = df_robustas.nsmallest(10, 'Taxa_Aprovacao_Parecer_%')\n",
    "        \n",
    "        y_pos2 = np.arange(len(bottom_performers))\n",
    "        bars2 = ax2.barh(y_pos2, bottom_performers['Taxa_Aprovacao_Parecer_%'], \n",
    "                         color='#e74c3c', alpha=0.7)\n",
    "        \n",
    "        ax2.set_yticks(y_pos2)\n",
    "        areas_bottom = [area[:20] + '...' if len(area) > 20 else area for area in bottom_performers['Area_Projeto']]\n",
    "        ax2.set_yticklabels(areas_bottom)\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_xlabel('Taxa de Aprova√ß√£o no Parecer (%)')\n",
    "        ax2.set_title('Bottom 10 √Åreas - Menor Taxa de Aprova√ß√£o no Parecer\\n(‚â•50 projetos)', fontsize=12)\n",
    "        ax2.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (bar, valor) in enumerate(zip(bars2, bottom_performers['Taxa_Aprovacao_Parecer_%'])):\n",
    "            ax2.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{valor:.1f}%', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar resultados\n",
    "    df_areas.to_csv('analise_aprovacao_por_area_projeto.csv', index=False, sep=';', encoding='utf-8')\n",
    "    print(\"\\nüíæ Resultados exportados para 'analise_aprovacao_por_area_projeto.csv'\")\n",
    "    \n",
    "    # Estat√≠sticas adicionais\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS ADICIONAIS:\")\n",
    "    print(f\"√Åreas com 100% aprova√ß√£o no Parecer: {len(df_areas[df_areas['Taxa_Aprovacao_Parecer_%'] == 100])}\")\n",
    "    print(f\"√Åreas com 0% aprova√ß√£o no Parecer: {len(df_areas[df_areas['Taxa_Aprovacao_Parecer_%'] == 0])}\")\n",
    "    print(f\"√Årea com maior volume: {df_areas.iloc[0]['Area_Projeto']} ({df_areas.iloc[0]['Total_Projetos']} projetos)\")\n",
    "    print(f\"Diferen√ßa m√°xima (Parecer-DO): {df_areas['Diferenca_Taxa_%'].max():.1f}%\")\n",
    "    print(f\"Diferen√ßa m√≠nima (Parecer-DO): {df_areas['Diferenca_Taxa_%'].min():.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå N√£o foi poss√≠vel realizar a an√°lise por √°rea do projeto\")\n",
    "    print(\"Verifique se a coluna 'daproj_dsareaprojeto' existe e cont√©m dados v√°lidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b1b3e",
   "metadata": {},
   "source": [
    "### An√°lise e Insights por Setor\n",
    "\n",
    "**O que foi investigado:**\n",
    "\n",
    "Esta an√°lise focou em identificar padr√µes de aprova√ß√£o por setor nas duas fases principais do processo (DO e Parecer), quantificando as diferen√ßas entre as decis√µes dos analistas t√©cnicos e dos pareceristas para cada setor de atividade.\n",
    "\n",
    "**Principais Descobertas:**\n",
    "\n",
    "A an√°lise setorial revela significativas disparidades nas taxas de aprova√ß√£o entre diferentes setores e entre as fases do processo:\n",
    "\n",
    "- **Varia√ß√£o Setorial**: As taxas de aprova√ß√£o variam drasticamente entre setores, tanto na fase DO quanto no Parecer\n",
    "- **Tend√™ncia Geral**: A maioria dos setores apresenta queda na taxa de aprova√ß√£o entre DO e Parecer, confirmando que os pareceristas aplicam crit√©rios mais rigorosos\n",
    "- **Setores Favorecidos**: Alguns setores mant√™m altas taxas de aprova√ß√£o em ambas as fases\n",
    "- **Setores Penalizados**: Certos setores sofrem quedas dram√°ticas entre as fases\n",
    "\n",
    "**Padr√µes Identificados:**\n",
    "\n",
    "1. **Setores de Alta Performance**: Setores com taxas superiores a 80% em ambas as fases\n",
    "2. **Setores de Queda Acentuada**: Setores que perdem mais de 20 pontos percentuais entre DO e Parecer\n",
    "3. **Setores de Revers√£o**: Raros casos onde a taxa no Parecer supera a do DO\n",
    "4. **Setores Vol√°teis**: Alta taxa de mudan√ßa de decis√£o entre fases\n",
    "\n",
    "**Insights e Implica√ß√µes Pr√°ticas:**\n",
    "\n",
    "1. **Especializa√ß√£o Setorial**: A varia√ß√£o nas taxas sugere que diferentes setores requerem expertise espec√≠fica para avalia√ß√£o adequada\n",
    "\n",
    "2. **Necessidade de Padroniza√ß√£o**: As grandes diferen√ßas entre setores podem indicar falta de crit√©rios uniformes ou vieses setoriais\n",
    "\n",
    "3. **Oportunidade de Capacita√ß√£o**: Setores com altas taxas de mudan√ßa entre fases podem se beneficiar de treinamento espec√≠fico para analistas\n",
    "\n",
    "4. **Revis√£o de Crit√©rios**: Setores com quedas sistem√°ticas merecem revis√£o dos crit√©rios de avalia√ß√£o aplicados\n",
    "\n",
    "**Recomenda√ß√µes Espec√≠ficas:**\n",
    "\n",
    "- **Criar grupos de trabalho setoriais** para padronizar crit√©rios de avalia√ß√£o\n",
    "- **Desenvolver checklists espec√≠ficos** para cada setor baseados em suas particularidades\n",
    "- **Implementar revis√£o cruzada** entre analistas de diferentes setores\n",
    "- **Monitorar indicadores setoriais** continuamente para identificar tend√™ncias\n",
    "- **Capacitar analistas** nas especificidades t√©cnicas de cada setor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-lei-do-bem (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
